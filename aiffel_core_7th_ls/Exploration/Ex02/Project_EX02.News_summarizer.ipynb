{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc185764",
   "metadata": {},
   "source": [
    "## Exploration 2. 뉴스 요약봇 만들기\n",
    "\n",
    "# Project 'News Summarizer'\n",
    "- **뉴스기사 요약**\n",
    "- 추상적 요약 Abstractive Summarization과 추출적 요약 Extractive Summarization을 모두 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756ea3cb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**[진행 과정]**\n",
    "1. 데이터 수집\n",
    "    - 뉴스기사 데이터 사용 \n",
    "2. 데이터 전처리(추상적 요약)\n",
    "    - 불용어 제거, 정규화, 정수인코딩 등의 데이터 전처리\n",
    "3. 모델 설계(추상적 요약)\n",
    "    - 인코더, 디코더, 어텐션 설계하고 코드로 구현\n",
    "4. 모델 훈련(추상적 요약)\n",
    "    - EarlyStopping 적용해서 훈련\n",
    "    1) 인퍼런스 모델 구현\n",
    "        - 정수 인덱스 행렬로 나온 결과값을 실제 데이터로 복원하는 인퍼런스 모델 구현\n",
    "5. 모델 테스트(추상적 요약) \n",
    "    - 모델을 통해 얻은 요약문과 실제 요약문 비교\n",
    "6. 추출적 요약\n",
    "    - summa 패키지를 사용해서 추출적 요약 시도\n",
    "    \n",
    "**참고 : 추가로 찾거나 공부한 자료에 대해서는 💡 표시를 붙임**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986d69e1",
   "metadata": {},
   "source": [
    "💡\n",
    "# 텍스트 요약\n",
    "- 요약 전후에 정보 손실 발생이 최소화되어야 함 = 정보 압축\n",
    "\n",
    "**1. 추출적 요약 Extractive Summarization**\n",
    "\n",
    "- 전통 머신러닝 `TextRank` 알고리즘 사용\n",
    "- 원문에서 문장 추출 => 문장분류(text classification)\n",
    "- 결과로 나온 문장들 간의 호응이 자연스럽지 않을수 있음<br>\n",
    "    [적용]\n",
    "네이버뉴스 요약봇\n",
    "\n",
    "**2. 추상적 요약 Abstractive Summarization**\n",
    "\n",
    "- 새로운 문장을 생성 => 자연서 생성(Natural Language Generation, NGL)\n",
    "- RNN 활용\n",
    "\n",
    "---\n",
    "\n",
    "# RNN\n",
    "- Long term dependencies 장기의존성 문제 => 해결하기위해 LSTM -> GRU -> Attention 등장\n",
    "\n",
    "**Google Brain team - [Text summarization with TensorFlow](https://research.googleblog.com/2016/08/text-summarization-with-tensorflow.html)**\n",
    "- DistBelief\n",
    "- 역문서빈도 IDF\n",
    "- seq2seq (sequence-to-sequence)\n",
    "\n",
    "---\n",
    "\n",
    "# seq2seq\n",
    "- 두 개의 RNN 아키텍처를 사용해서 입력시퀀스로부터 출력시퀀스를 생성하는 자연어생성모델\n",
    "<a href=\"https://medium.com/dl-for-product-and-service/abstractive-text-summary-with-reinforcement-learning-ab2458ab29d5\"><img src='https://miro.medium.com/v2/resize:fit:1360/format:webp/1*Cu49wPEpWJPoI0a5AV9Q1Q.png' ></a>\n",
    "    1. RNN encoder : 원문 입력 -> 하나의 고정된 벡터로 변환\n",
    "        - context vector : 문맥을 가진 벡터\n",
    "    2. RNN decoder : 컨텍스트 벡터를 입력받아 한 단어씩 생성하고 요약 문장 완성\n",
    "\n",
    "\n",
    "- 학습에서는 vanila RNN 대신 LSTM 사용\n",
    "<a href='https://colah.github.io/posts/2015-08-Understanding-LSTMs/'><img src='https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png' width=70% height=70%></a>   \n",
    "\n",
    "\n",
    "- 인코더 마지막 time step의 hidden state를 context vector로 사용\n",
    "\n",
    "\n",
    "\n",
    "## LSTM vs Vanila RNN\n",
    "- 다음 time step 셀에 hidden state(h) + cell state(c)\n",
    "- 인코더가 디코더에 전달하는 context vector에 h, c 둘다 존재\n",
    "\n",
    "\n",
    "## Attentional seq2seq\n",
    "<a href='https://arxiv.org/pdf/1812.02303.pdf'><img src='./img/attention.png' width=60% height=60%></a>\n",
    "- seq2seq + attention mechanism\n",
    "- 인코더의 **모든 step**의 hidden state 정보를 context vector로 사용\n",
    "- 인코더 hidden state 가중치는 **디코더의 현재 스텝이 어디**냐에 따라 계속 달라짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7de75fc",
   "metadata": {},
   "source": [
    "# 👉 정리\n",
    "\n",
    "1. **seq2seq + LSTM + attention 사용**\n",
    "    - 2개 LSTM을 붙여서 사용\n",
    "    - encoder의 hidden state의 중요도(가중치)를 취합한 context vector는 decoder 스텝별로 계산\n",
    "    - 계산된 context vector를 이용해서 decoder는 다음 등장할 단어를 예측\n",
    "2. **hidden state + cell state 모두 사용**\n",
    "    - cell state?\n",
    "3. **decoder 앞: SOS start token / 뒤 : EOS end token 추가**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "310ba5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.5\n",
      "2.6.0\n",
      "1.3.3\n",
      "1.2.0\n"
     ]
    }
   ],
   "source": [
    "# library version check\n",
    "from importlib.metadata import version\n",
    "import nltk\n",
    "import tensorflow\n",
    "import summa\n",
    "import pandas\n",
    "\n",
    "print(nltk.__version__)\n",
    "print(tensorflow.__version__)\n",
    "print(pandas.__version__)\n",
    "print(version('summa'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695058e6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 💡 NLTK\n",
    "- Natural Language Toolkit\n",
    "- 영어 기호, 통계, 자연어처리를 위한 라이브러리\n",
    "\n",
    "\n",
    "`stopwords` \n",
    "- I, my, me, over, 조사, 접미사 등 불용어 정리\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2edada6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*\n"
     ]
    }
   ],
   "source": [
    "# necessary library \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='bs4')\n",
    "\n",
    "print(\"*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7038726d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# `추상적 요약 Abstractive Summarization`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3ff1d6",
   "metadata": {},
   "source": [
    "# Step 1. 데이터 준비\n",
    "- 뉴스 기사 데이터 : [news_summary_more.csv](https://github.com/sunnysai12345/News_Summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a472c533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb3af040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86639</th>\n",
       "      <td>NASA to launch first-ever mission to study neu...</td>\n",
       "      <td>NASA is launching the world's first mission to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67439</th>\n",
       "      <td>International Chole Bhature Day celebrated on ...</td>\n",
       "      <td>The annual International Chole Bhature Day was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95307</th>\n",
       "      <td>Ayodhya issue cannot be resolved by talks: Mul...</td>\n",
       "      <td>Samajwadi Party Founder Mulayam Singh Yadav ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87925</th>\n",
       "      <td>Russian helicopters' 'Make in India' cost 250%...</td>\n",
       "      <td>The cost of Russian Kamov light-utility choppe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7359</th>\n",
       "      <td>Come on, kill me: Owaisi after BJP leader dare...</td>\n",
       "      <td>After Telangana BJP leader T Raja Singh dared ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>Cow dung thrown at National Award-winning dire...</td>\n",
       "      <td>National Award-winning Malayali filmmaker Priy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3124</th>\n",
       "      <td>Raise parliamentarians' salary to reduce corru...</td>\n",
       "      <td>BJP MP Harish Dwivedi has urged PM Narendra Mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23260</th>\n",
       "      <td>Student sodomised by 6 seniors in Ajmer's Mayo...</td>\n",
       "      <td>A grade 11 student from Ajmer's Mayo College w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95753</th>\n",
       "      <td>Air India body slams promoting pilot who misse...</td>\n",
       "      <td>The Air India pilots' association has proteste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56443</th>\n",
       "      <td>2 teachers suspended for spelling errors in En...</td>\n",
       "      <td>Two Rajasthan government school teachers have ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headlines  \\\n",
       "86639  NASA to launch first-ever mission to study neu...   \n",
       "67439  International Chole Bhature Day celebrated on ...   \n",
       "95307  Ayodhya issue cannot be resolved by talks: Mul...   \n",
       "87925  Russian helicopters' 'Make in India' cost 250%...   \n",
       "7359   Come on, kill me: Owaisi after BJP leader dare...   \n",
       "805    Cow dung thrown at National Award-winning dire...   \n",
       "3124   Raise parliamentarians' salary to reduce corru...   \n",
       "23260  Student sodomised by 6 seniors in Ajmer's Mayo...   \n",
       "95753  Air India body slams promoting pilot who misse...   \n",
       "56443  2 teachers suspended for spelling errors in En...   \n",
       "\n",
       "                                                    text  \n",
       "86639  NASA is launching the world's first mission to...  \n",
       "67439  The annual International Chole Bhature Day was...  \n",
       "95307  Samajwadi Party Founder Mulayam Singh Yadav ha...  \n",
       "87925  The cost of Russian Kamov light-utility choppe...  \n",
       "7359   After Telangana BJP leader T Raja Singh dared ...  \n",
       "805    National Award-winning Malayali filmmaker Priy...  \n",
       "3124   BJP MP Harish Dwivedi has urged PM Narendra Mo...  \n",
       "23260  A grade 11 student from Ajmer's Mayo College w...  \n",
       "95753  The Air India pilots' association has proteste...  \n",
       "56443  Two Rajasthan government school teachers have ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data check\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a7cc1f",
   "metadata": {},
   "source": [
    "- 데이터는 `text` `headlines` 두가지 열로 구성되어있다\n",
    "- 추상적 요약에서는 아래와 같이 데이터를 활용\n",
    "    - `text`: 원문\n",
    "    - `headlines`: 요약 데이터\n",
    "- 추출적 요약에서는 text 데이터만 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecc0243c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98401"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fb289d",
   "metadata": {},
   "source": [
    "- data 총 98,401개"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8351a6f",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 2. Data preprocessing\n",
    "## 1) Remove duplicate & Null values\n",
    "\n",
    "- `df.nunique()` : 중복데이터 제외한 데이터 수 확인 \n",
    "- `df.drop_duplicates()` : 중복데이터 삭제\n",
    "    - `subset` : 특정 열에 대한 중복데이터를 삭제하고 싶을때 설정 \n",
    "    > **subset : column label or sequence of labels, optional**<br>\n",
    "      Only consider certain columns for identifying duplicates, by default use all of the columns. [ref](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html)\n",
    "    - `inplace=True` : 데이터프레임 내부를 직접 수정\n",
    "    \n",
    "\n",
    "- `df.isnull().sum()` : df에 Null 값이 총 몇개 있는지 확인\n",
    "- `df.dropna()` : 데이터프레임 Null 제거\n",
    "    - `axis=` : 삭제할 방향 정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f133873c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 열에서 중복을 배제한 유일한 샘플의 수 : 98360\n",
      "headlines 열에서 중복을 배제한 유일한 샘플의 수 : 98280\n"
     ]
    }
   ],
   "source": [
    "print('text 열에서 중복을 배제한 유일한 샘플의 수 :', data['text'].nunique())\n",
    "print('headlines 열에서 중복을 배제한 유일한 샘플의 수 :', data['headlines'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c146b378",
   "metadata": {},
   "source": [
    "- 총 데이터 수는 98401이라 각 열에 중복된 데이터들이 있는걸 확인할수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6ef45e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total samples: 98360\n"
     ]
    }
   ],
   "source": [
    "# 중복 샘플 제거\n",
    "data.drop_duplicates(subset=['text'], inplace=True)\n",
    "print('total samples:', len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39a498d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines    0\n",
      "text         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 데이터에 null 있는지 다시 확인\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dc9b1a",
   "metadata": {},
   "source": [
    "- null 데이터도 없이 깔끔하게 정리완료"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870e0d45",
   "metadata": {},
   "source": [
    "## 2) Text normalization\n",
    "- `it'll` `it will` / `mustn't` `must not` 같은 표현 서로 같은거라고 설정해주기\n",
    "- [텍스트 정규화 사전](https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python) 데이터를 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce971ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 정규화 사전\n",
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \", len(contractions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d020c12",
   "metadata": {},
   "source": [
    "## 3) Remove `Stopwords` + etc\n",
    "`stopwords` 불용어\n",
    "- 텍스트에는 자주 등장하지만 자연어 처리할때 도움이 되지 않는 단어들\n",
    "\n",
    "**etc**\n",
    "- text to lowercase\n",
    "- remove html tag\n",
    "- remove special characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "080455bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /aiffel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f946430d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of stopwords:  179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print('# of stopwords: ', len(stopwords.words('english')))\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b08b05",
   "metadata": {},
   "source": [
    "- stopwords는 모두 179개가 있다\n",
    "\n",
    "### `preprocess_sentence()` 데이터 전처리 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d09d618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*\n"
     ]
    }
   ],
   "source": [
    "# data preprocessing function - stopwords + etc\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # html 태그 제거 : <br />, <a href = ...> 등 \n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 : e.g. my husband (and myself!) for => my husband\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\", sentence) # 소유격 제거 : e.g. roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경 : e.g. ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    # 불용어 제거 (text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    # 불용어 미제거 (headlines)\n",
    "    # 짧은 텍스트의 경우 불용어가 있어야 자연스럽기때문\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens\n",
    "\n",
    "print('*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3db07175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  everything bought great infact ordered twice third ordered wasfor mother father\n",
      "headlines: great way to start the day\n"
     ]
    }
   ],
   "source": [
    "# test fucntion\n",
    "temp_text = 'Everything I bought was great, infact I ordered twice and the third ordered was<br />for my mother and father.'\n",
    "temp_headlines = 'Great way to start (or finish) the day!!!'\n",
    "\n",
    "print(\"text: \", preprocess_sentence(temp_text))\n",
    "print(\"headlines:\", preprocess_sentence(temp_headlines, False))  # 불용어를 제거하지 않는다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a03c103",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "💡\n",
    "###  `preprocess_data()` 데이터 전처리 속도 개선 함수\n",
    "- 데이터 전처리 시간이 매우 오래걸렸는데 [지난 기수 그루의 코드](https://github.com/jangjs1103/laboratory/blob/main/AIFFEL/LMS/Exploration_10/Exploration_10_%EC%9A%94%EC%95%BD%EB%AC%B8.ipynb)를 참고해서 속도를 높이는 시도를 해본다\n",
    "- 자세한 진행방법은 이해하기 어려웠지만, **멀티프로세싱을 할수 있도록 cpu 코어수에 맞춰서 데이터를 배분**하는 방식이었다.\n",
    "- 또 **map 함수에 여러 인자를 넣어줄수 있는 라이브러리**가 따로 있다는걸 알게되어 신기했다!\n",
    "    - [`partial` 참고 자료](https://tempdev.tistory.com/36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1e11bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of cores:  4\n",
      "372.938499212265  seconds\n",
      "['saurav kant alumnus upgrad iiit pg program machine learning artificial intelligence sr systems engineer infosys almost years work experience program upgrad degree career support helped transition data scientist tech mahindra salary hike upgrad online power learning powered lakh careers'\n",
      " 'kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year pranav kaushik delhi techie bagged reward spending cred coins users get one cred coin per rupee bill paid used avail rewards brands like ixigo bookmyshow ubereats cult fit'\n",
      " 'new zealand defeated india wickets fourth odi hamilton thursday win first match five match odi series india lost international match rohit sharma captaincy consecutive victories dating back march match witnessed india getting seventh lowest total odi cricket history'\n",
      " ...\n",
      " 'according reports new version science fiction film matrix development michael jordan reportedly play lead role film screenwriter zak penn talks write script film reports added actor keanu reeves starred original film followed two sequels'\n",
      " 'new music video shows rapper snoop dogg aiming toy gun clown character parodying us president donald trump video also shows tv airing news conference headline ronald klump wants deport doggs airing live clown house video remixed version song lavender'\n",
      " 'madhesi morcha alliance seven political parties withdrawn support pm pushpa kamal dahal led nepal government failed meet seven day ultimatum fulfil demands including endorsement revised constitution amendment bill morcha seats parliament despite withdrawal support immediate threat government']\n",
      "# of cores:  4\n",
      "9.747351169586182  seconds\n",
      "['upgrad learner switches to career in ml al with salary hike'\n",
      " 'delhi techie wins free food from swiggy for one year on cred'\n",
      " 'new zealand end rohit sharma led india match winning streak' ...\n",
      " 'the matrix film to get reboot reports'\n",
      " 'snoop dogg aims gun at clown dressed as trump in new video'\n",
      " 'madhesi morcha withdraws support to nepalese government']\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp   # 전처리 속도를 획기적으로 줄여줄 멀티 프로세싱\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import time\n",
    "from functools import partial  # multiprocessing.Pool의 map()에 여러 인자를 넣어줄 수 있게 해줌\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# num_cores 만큼 쪼개진 데이터를 전처리하여 반환\n",
    "def appendTexts(sentences, remove_stopwords):\n",
    "    texts = []\n",
    "    for s in sentences:\n",
    "        texts += preprocess_sentence(s, remove_stopwords),\n",
    "    return texts\n",
    "\n",
    "# 속도개선 함수\n",
    "def preprocess_data(data, remove_stopwords=True):\n",
    "    start_time = time.time()\n",
    "    num_cores = mp.cpu_count()  # 컴퓨터의 코어 수를 확인\n",
    "    print(\"# of cores: \", num_cores)\n",
    "\n",
    "    text_data_split = np.array_split(data, num_cores)  # 코어 수만큼 데이터를 배분하여 병렬적으로 처리\n",
    "    \n",
    "    pool = Pool(num_cores)\n",
    "    \n",
    "    # partial을 이용해서 map 함수에 여러 인자 전달\n",
    "    processed_data = np.concatenate(pool.map(partial(appendTexts, remove_stopwords=remove_stopwords), text_data_split)) # 각자 작업한 데이터를 하나로 연결\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    print(time.time() - start_time, \" seconds\")\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "# text 전처리\n",
    "clean_text = preprocess_data(data['text'])\n",
    "print(clean_text)\n",
    "\n",
    "# headlines 전처리\n",
    "clean_headlines = preprocess_data(data['headlines'], remove_stopwords=False) # 불용어 제거하지 않음\n",
    "print(clean_headlines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d8ca99",
   "metadata": {},
   "source": [
    "- text 데이터 전처리 시간이 370초=**6분**이 소요되었다\n",
    "- 이전 노드에서 진행한 데이터 양과 비교했을때 비슷하니 조금 더 빨라진게 아닐까..? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4db7ca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중간과정 데이터 복사 - 불용어 삭제 전 데이터\n",
    "origin_data = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a76eb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 데이터를 전처리된 데이터로 변환\n",
    "data['text'] = clean_text\n",
    "data['headlines'] = clean_headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4416839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "headlines    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 빈 데이터 있는지 확인\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce4d5aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total samples: 98360\n"
     ]
    }
   ],
   "source": [
    "# 전처리 후의 데이터 수 확인\n",
    "print('total samples:', len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c903972",
   "metadata": {},
   "source": [
    "- 최종 데이터 수는 98360개"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c741a610",
   "metadata": {},
   "source": [
    "## 4) 데이터 샘플의 분포 시각화\n",
    "- Text, Summary의 최소, 최대, 평균 길이를 구하고, 길이 분포 시각화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1746ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[text]의 최소 길이 : 1\n",
      "[text]의 최대 길이 : 60\n",
      "[text]의 평균 길이 : 35.09968483123221\n",
      "[headlines]의 최소 길이 : 1\n",
      "[headlines]의 최대 길이 : 16\n",
      "[headlines]의 평균 길이 : 9.299532330215534\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 길이 분포 출력\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# data length in each row\n",
    "text_len = [len(s.split()) for s in data['text']]\n",
    "headlines_len = [len(s.split()) for s in data['headlines']]\n",
    "\n",
    "print('[text]의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('[text]의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('[text]의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('[headlines]의 최소 길이 : {}'.format(np.min(headlines_len)))\n",
    "print('[headlines]의 최대 길이 : {}'.format(np.max(headlines_len)))\n",
    "print('[headlines]의 평균 길이 : {}'.format(np.mean(headlines_len)))\n",
    "\n",
    "# boxplot\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('Text')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(headlines_len)\n",
    "plt.title('Headlines')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# histogram\n",
    "plt.title('Text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Headlines')\n",
    "plt.hist(headlines_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e58953",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "💡\n",
    "[`Series.str.split()`](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html)\n",
    "- ()안에 넣은 인자를 중심으로 str을 분리하는 메서드인데, 여기에서는 아무 값도 넣지 않았기 때문에 전체 str을 추출하게 된다.\n",
    "> Pandas `str.split()` method can be applied to a whole series.\n",
    "- python의 `split()` 메서드는 `str`만 적용이 가능하고, 지금 데이터는 series이기 때문에 pandas의 `str.split()`을 사용한다. \n",
    "    - 위 코드를 보면 `[len(s.split()) for s in df['Text']` lambda형태로 작성했는데, `s`:str을 꺼내서 s.split()을 한다. \n",
    "> Return value :Series of list or Data frame depending on expand Parameter\n",
    "- 우리는 리스트로 만들었기때문에 아래와 같은 형태의 데이터가 만들어진다.\n",
    "\n",
    "- *그런데, str 을 붙이지 않고 사용해도되는건가? 위에 코드에서 s 는 series 그 자체의 값 같은데, 확인을 해봐야겠다.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16b1cef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([39,\n",
       "  45,\n",
       "  38,\n",
       "  34,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  35,\n",
       "  27,\n",
       "  34,\n",
       "  33,\n",
       "  42,\n",
       "  32,\n",
       "  38,\n",
       "  35,\n",
       "  39,\n",
       "  36,\n",
       "  32,\n",
       "  34,\n",
       "  36,\n",
       "  34,\n",
       "  40,\n",
       "  32,\n",
       "  36,\n",
       "  39,\n",
       "  35,\n",
       "  29,\n",
       "  34,\n",
       "  38,\n",
       "  39,\n",
       "  38,\n",
       "  36,\n",
       "  43,\n",
       "  42,\n",
       "  34,\n",
       "  40,\n",
       "  36,\n",
       "  35,\n",
       "  38,\n",
       "  31,\n",
       "  38,\n",
       "  40,\n",
       "  35,\n",
       "  38,\n",
       "  38,\n",
       "  32,\n",
       "  33,\n",
       "  35,\n",
       "  36,\n",
       "  36,\n",
       "  39,\n",
       "  35,\n",
       "  1,\n",
       "  24,\n",
       "  32,\n",
       "  36,\n",
       "  38,\n",
       "  34,\n",
       "  40,\n",
       "  40,\n",
       "  35,\n",
       "  43,\n",
       "  30,\n",
       "  38,\n",
       "  41,\n",
       "  41,\n",
       "  37,\n",
       "  34,\n",
       "  34,\n",
       "  44,\n",
       "  37,\n",
       "  40,\n",
       "  40,\n",
       "  34,\n",
       "  38,\n",
       "  36,\n",
       "  34,\n",
       "  34,\n",
       "  40,\n",
       "  35,\n",
       "  39,\n",
       "  37,\n",
       "  45,\n",
       "  37,\n",
       "  33,\n",
       "  35,\n",
       "  36,\n",
       "  38,\n",
       "  37,\n",
       "  36,\n",
       "  35,\n",
       "  32,\n",
       "  32,\n",
       "  31,\n",
       "  27,\n",
       "  28,\n",
       "  34,\n",
       "  33,\n",
       "  33,\n",
       "  36,\n",
       "  39,\n",
       "  42,\n",
       "  35,\n",
       "  40,\n",
       "  42,\n",
       "  36,\n",
       "  39,\n",
       "  33,\n",
       "  35,\n",
       "  33,\n",
       "  45,\n",
       "  34,\n",
       "  34,\n",
       "  36,\n",
       "  35,\n",
       "  37,\n",
       "  32,\n",
       "  36,\n",
       "  34,\n",
       "  36,\n",
       "  38,\n",
       "  38,\n",
       "  39,\n",
       "  35,\n",
       "  36,\n",
       "  31,\n",
       "  39,\n",
       "  44,\n",
       "  40,\n",
       "  41,\n",
       "  36,\n",
       "  33,\n",
       "  35,\n",
       "  36,\n",
       "  32,\n",
       "  33,\n",
       "  27,\n",
       "  43,\n",
       "  38,\n",
       "  37,\n",
       "  34,\n",
       "  33,\n",
       "  37,\n",
       "  31,\n",
       "  41,\n",
       "  34,\n",
       "  36,\n",
       "  35,\n",
       "  36,\n",
       "  31,\n",
       "  34,\n",
       "  35,\n",
       "  39,\n",
       "  41,\n",
       "  38,\n",
       "  41,\n",
       "  32,\n",
       "  38,\n",
       "  35,\n",
       "  32,\n",
       "  33,\n",
       "  36,\n",
       "  38,\n",
       "  39,\n",
       "  33,\n",
       "  34,\n",
       "  38,\n",
       "  34,\n",
       "  35,\n",
       "  37,\n",
       "  32,\n",
       "  38,\n",
       "  31,\n",
       "  33,\n",
       "  31,\n",
       "  37,\n",
       "  35,\n",
       "  39,\n",
       "  38,\n",
       "  25,\n",
       "  36,\n",
       "  35,\n",
       "  38,\n",
       "  33,\n",
       "  27,\n",
       "  39,\n",
       "  39,\n",
       "  31,\n",
       "  34,\n",
       "  37,\n",
       "  37,\n",
       "  37,\n",
       "  34,\n",
       "  37,\n",
       "  29,\n",
       "  35,\n",
       "  38,\n",
       "  41,\n",
       "  36,\n",
       "  34,\n",
       "  37,\n",
       "  34,\n",
       "  32,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  35,\n",
       "  39,\n",
       "  38,\n",
       "  32,\n",
       "  40,\n",
       "  35,\n",
       "  41,\n",
       "  34,\n",
       "  38,\n",
       "  35,\n",
       "  36,\n",
       "  40,\n",
       "  38,\n",
       "  34,\n",
       "  27,\n",
       "  33,\n",
       "  35,\n",
       "  35,\n",
       "  33,\n",
       "  37,\n",
       "  38,\n",
       "  38,\n",
       "  34,\n",
       "  38,\n",
       "  32,\n",
       "  41,\n",
       "  34,\n",
       "  36,\n",
       "  28,\n",
       "  31,\n",
       "  35,\n",
       "  36,\n",
       "  37,\n",
       "  32,\n",
       "  40,\n",
       "  33,\n",
       "  41,\n",
       "  33,\n",
       "  36,\n",
       "  38,\n",
       "  35,\n",
       "  37,\n",
       "  45,\n",
       "  36,\n",
       "  42,\n",
       "  38,\n",
       "  32,\n",
       "  33,\n",
       "  36,\n",
       "  35,\n",
       "  46,\n",
       "  40,\n",
       "  37,\n",
       "  28,\n",
       "  33,\n",
       "  34,\n",
       "  37,\n",
       "  39,\n",
       "  34,\n",
       "  32,\n",
       "  36,\n",
       "  40,\n",
       "  30,\n",
       "  33,\n",
       "  36,\n",
       "  30,\n",
       "  36,\n",
       "  32,\n",
       "  38,\n",
       "  34,\n",
       "  28,\n",
       "  38,\n",
       "  33,\n",
       "  28,\n",
       "  40,\n",
       "  43,\n",
       "  29,\n",
       "  36,\n",
       "  41,\n",
       "  38,\n",
       "  41,\n",
       "  30,\n",
       "  40,\n",
       "  41,\n",
       "  32,\n",
       "  35,\n",
       "  34,\n",
       "  31,\n",
       "  38,\n",
       "  28,\n",
       "  32,\n",
       "  33,\n",
       "  43,\n",
       "  35,\n",
       "  38,\n",
       "  31,\n",
       "  35,\n",
       "  42,\n",
       "  39,\n",
       "  35,\n",
       "  38,\n",
       "  31,\n",
       "  32,\n",
       "  35,\n",
       "  31,\n",
       "  35,\n",
       "  36,\n",
       "  39,\n",
       "  39,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  29,\n",
       "  36,\n",
       "  37,\n",
       "  32,\n",
       "  30,\n",
       "  31,\n",
       "  36,\n",
       "  37,\n",
       "  39,\n",
       "  36,\n",
       "  27,\n",
       "  41,\n",
       "  31,\n",
       "  41,\n",
       "  33,\n",
       "  33,\n",
       "  36,\n",
       "  36,\n",
       "  34,\n",
       "  33,\n",
       "  36,\n",
       "  39,\n",
       "  37,\n",
       "  24,\n",
       "  34,\n",
       "  38,\n",
       "  34,\n",
       "  35,\n",
       "  37,\n",
       "  40,\n",
       "  30,\n",
       "  32,\n",
       "  38,\n",
       "  34,\n",
       "  33,\n",
       "  30,\n",
       "  34,\n",
       "  34,\n",
       "  38,\n",
       "  35,\n",
       "  38,\n",
       "  35,\n",
       "  34,\n",
       "  39,\n",
       "  36,\n",
       "  39,\n",
       "  38,\n",
       "  38,\n",
       "  37,\n",
       "  33,\n",
       "  35,\n",
       "  36,\n",
       "  36,\n",
       "  35,\n",
       "  33,\n",
       "  33,\n",
       "  37,\n",
       "  36,\n",
       "  31,\n",
       "  42,\n",
       "  38,\n",
       "  42,\n",
       "  37,\n",
       "  44,\n",
       "  36,\n",
       "  32,\n",
       "  32,\n",
       "  34,\n",
       "  32,\n",
       "  33,\n",
       "  37,\n",
       "  32,\n",
       "  32,\n",
       "  42,\n",
       "  43,\n",
       "  35,\n",
       "  34,\n",
       "  33,\n",
       "  31,\n",
       "  41,\n",
       "  33,\n",
       "  36,\n",
       "  33,\n",
       "  40,\n",
       "  36,\n",
       "  35,\n",
       "  36,\n",
       "  28,\n",
       "  35,\n",
       "  33,\n",
       "  36,\n",
       "  35,\n",
       "  32,\n",
       "  33,\n",
       "  30,\n",
       "  37,\n",
       "  37,\n",
       "  36,\n",
       "  31,\n",
       "  38,\n",
       "  33,\n",
       "  39,\n",
       "  39,\n",
       "  38,\n",
       "  26,\n",
       "  35,\n",
       "  35,\n",
       "  31,\n",
       "  36,\n",
       "  38,\n",
       "  46,\n",
       "  35,\n",
       "  37,\n",
       "  41,\n",
       "  38,\n",
       "  35,\n",
       "  34,\n",
       "  32,\n",
       "  37,\n",
       "  35,\n",
       "  35,\n",
       "  34,\n",
       "  29,\n",
       "  27,\n",
       "  31,\n",
       "  36,\n",
       "  37,\n",
       "  37,\n",
       "  28,\n",
       "  29,\n",
       "  42,\n",
       "  30,\n",
       "  37,\n",
       "  30,\n",
       "  37,\n",
       "  32,\n",
       "  36,\n",
       "  37,\n",
       "  41,\n",
       "  34,\n",
       "  36,\n",
       "  37,\n",
       "  25,\n",
       "  49,\n",
       "  37,\n",
       "  38,\n",
       "  26,\n",
       "  36,\n",
       "  35,\n",
       "  40,\n",
       "  35,\n",
       "  40,\n",
       "  43,\n",
       "  27,\n",
       "  28,\n",
       "  37,\n",
       "  42,\n",
       "  32,\n",
       "  42,\n",
       "  39,\n",
       "  41,\n",
       "  36,\n",
       "  41,\n",
       "  29,\n",
       "  35,\n",
       "  32,\n",
       "  39,\n",
       "  38,\n",
       "  29,\n",
       "  32,\n",
       "  32,\n",
       "  34,\n",
       "  41,\n",
       "  35,\n",
       "  41,\n",
       "  33,\n",
       "  33,\n",
       "  36,\n",
       "  36,\n",
       "  34,\n",
       "  28,\n",
       "  33,\n",
       "  38,\n",
       "  35,\n",
       "  39,\n",
       "  32,\n",
       "  36,\n",
       "  37,\n",
       "  27,\n",
       "  41,\n",
       "  40,\n",
       "  36,\n",
       "  40,\n",
       "  27,\n",
       "  35,\n",
       "  32,\n",
       "  32,\n",
       "  35,\n",
       "  38,\n",
       "  32,\n",
       "  37,\n",
       "  35,\n",
       "  32,\n",
       "  34,\n",
       "  32,\n",
       "  41,\n",
       "  37,\n",
       "  37,\n",
       "  33,\n",
       "  36,\n",
       "  36,\n",
       "  34,\n",
       "  34,\n",
       "  35,\n",
       "  34,\n",
       "  36,\n",
       "  33,\n",
       "  32,\n",
       "  43,\n",
       "  33,\n",
       "  32,\n",
       "  39,\n",
       "  37,\n",
       "  36,\n",
       "  33,\n",
       "  38,\n",
       "  35,\n",
       "  35,\n",
       "  38,\n",
       "  37,\n",
       "  33,\n",
       "  35,\n",
       "  33,\n",
       "  36,\n",
       "  39,\n",
       "  40,\n",
       "  32,\n",
       "  34,\n",
       "  34,\n",
       "  35,\n",
       "  37,\n",
       "  32,\n",
       "  36,\n",
       "  41,\n",
       "  35,\n",
       "  35,\n",
       "  33,\n",
       "  39,\n",
       "  37,\n",
       "  33,\n",
       "  35,\n",
       "  33,\n",
       "  34,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  36,\n",
       "  34,\n",
       "  37,\n",
       "  33,\n",
       "  30,\n",
       "  34,\n",
       "  32,\n",
       "  40,\n",
       "  38,\n",
       "  31,\n",
       "  36,\n",
       "  31,\n",
       "  36,\n",
       "  33,\n",
       "  38,\n",
       "  42,\n",
       "  38,\n",
       "  33,\n",
       "  33,\n",
       "  36,\n",
       "  35,\n",
       "  44,\n",
       "  36,\n",
       "  37,\n",
       "  35,\n",
       "  35,\n",
       "  31,\n",
       "  32,\n",
       "  28,\n",
       "  40,\n",
       "  33,\n",
       "  31,\n",
       "  45,\n",
       "  34,\n",
       "  38,\n",
       "  38,\n",
       "  31,\n",
       "  38,\n",
       "  35,\n",
       "  33,\n",
       "  36,\n",
       "  31,\n",
       "  34,\n",
       "  31,\n",
       "  35,\n",
       "  41,\n",
       "  42,\n",
       "  35,\n",
       "  35,\n",
       "  34,\n",
       "  35,\n",
       "  35,\n",
       "  40,\n",
       "  39,\n",
       "  29,\n",
       "  34,\n",
       "  39,\n",
       "  38,\n",
       "  33,\n",
       "  33,\n",
       "  40,\n",
       "  37,\n",
       "  37,\n",
       "  38,\n",
       "  32,\n",
       "  39,\n",
       "  40,\n",
       "  41,\n",
       "  45,\n",
       "  33,\n",
       "  38,\n",
       "  39,\n",
       "  39,\n",
       "  37,\n",
       "  32,\n",
       "  39,\n",
       "  36,\n",
       "  32,\n",
       "  32,\n",
       "  31,\n",
       "  31,\n",
       "  41,\n",
       "  38,\n",
       "  34,\n",
       "  40,\n",
       "  37,\n",
       "  41,\n",
       "  40,\n",
       "  42,\n",
       "  34,\n",
       "  38,\n",
       "  41,\n",
       "  37,\n",
       "  38,\n",
       "  37,\n",
       "  25,\n",
       "  32,\n",
       "  29,\n",
       "  31,\n",
       "  39,\n",
       "  35,\n",
       "  37,\n",
       "  36,\n",
       "  42,\n",
       "  35,\n",
       "  35,\n",
       "  38,\n",
       "  33,\n",
       "  37,\n",
       "  32,\n",
       "  34,\n",
       "  34,\n",
       "  36,\n",
       "  41,\n",
       "  36,\n",
       "  43,\n",
       "  34,\n",
       "  35,\n",
       "  34,\n",
       "  37,\n",
       "  34,\n",
       "  42,\n",
       "  32,\n",
       "  36,\n",
       "  32,\n",
       "  40,\n",
       "  38,\n",
       "  34,\n",
       "  35,\n",
       "  40,\n",
       "  36,\n",
       "  48,\n",
       "  36,\n",
       "  37,\n",
       "  37,\n",
       "  40,\n",
       "  33,\n",
       "  38,\n",
       "  35,\n",
       "  42,\n",
       "  40,\n",
       "  28,\n",
       "  31,\n",
       "  28,\n",
       "  36,\n",
       "  38,\n",
       "  44,\n",
       "  40,\n",
       "  38,\n",
       "  50,\n",
       "  36,\n",
       "  45,\n",
       "  26,\n",
       "  37,\n",
       "  45,\n",
       "  33,\n",
       "  31,\n",
       "  35,\n",
       "  41,\n",
       "  38,\n",
       "  40,\n",
       "  33,\n",
       "  32,\n",
       "  30,\n",
       "  38,\n",
       "  29,\n",
       "  36,\n",
       "  38,\n",
       "  39,\n",
       "  41,\n",
       "  29,\n",
       "  32,\n",
       "  33,\n",
       "  36,\n",
       "  44,\n",
       "  35,\n",
       "  35,\n",
       "  35,\n",
       "  30,\n",
       "  36,\n",
       "  28,\n",
       "  32,\n",
       "  35,\n",
       "  36,\n",
       "  32,\n",
       "  33,\n",
       "  32,\n",
       "  36,\n",
       "  38,\n",
       "  33,\n",
       "  35,\n",
       "  41,\n",
       "  33,\n",
       "  31,\n",
       "  41,\n",
       "  36,\n",
       "  32,\n",
       "  33,\n",
       "  41,\n",
       "  38,\n",
       "  42,\n",
       "  31,\n",
       "  34,\n",
       "  37,\n",
       "  34,\n",
       "  40,\n",
       "  31,\n",
       "  46,\n",
       "  37,\n",
       "  33,\n",
       "  39,\n",
       "  34,\n",
       "  41,\n",
       "  32,\n",
       "  32,\n",
       "  39,\n",
       "  34,\n",
       "  32,\n",
       "  32,\n",
       "  33,\n",
       "  27,\n",
       "  31,\n",
       "  35,\n",
       "  34,\n",
       "  33,\n",
       "  29,\n",
       "  41,\n",
       "  34,\n",
       "  31,\n",
       "  31,\n",
       "  28,\n",
       "  33,\n",
       "  34,\n",
       "  32,\n",
       "  35,\n",
       "  39,\n",
       "  43,\n",
       "  30,\n",
       "  27,\n",
       "  33,\n",
       "  39,\n",
       "  28,\n",
       "  33,\n",
       "  37,\n",
       "  28,\n",
       "  32,\n",
       "  37,\n",
       "  28,\n",
       "  34,\n",
       "  33,\n",
       "  36,\n",
       "  31,\n",
       "  40,\n",
       "  37,\n",
       "  32,\n",
       "  37,\n",
       "  35,\n",
       "  38,\n",
       "  37,\n",
       "  40,\n",
       "  35,\n",
       "  38,\n",
       "  33,\n",
       "  32,\n",
       "  35,\n",
       "  32,\n",
       "  34,\n",
       "  43,\n",
       "  41,\n",
       "  34,\n",
       "  38,\n",
       "  36,\n",
       "  46,\n",
       "  36,\n",
       "  35,\n",
       "  37,\n",
       "  37,\n",
       "  34,\n",
       "  30,\n",
       "  39,\n",
       "  32,\n",
       "  32,\n",
       "  34,\n",
       "  36,\n",
       "  37,\n",
       "  32,\n",
       "  37,\n",
       "  37,\n",
       "  28,\n",
       "  34,\n",
       "  35,\n",
       "  37,\n",
       "  40,\n",
       "  35,\n",
       "  33,\n",
       "  36,\n",
       "  36,\n",
       "  38,\n",
       "  33,\n",
       "  39,\n",
       "  34,\n",
       "  28,\n",
       "  37,\n",
       "  31,\n",
       "  37,\n",
       "  33,\n",
       "  31,\n",
       "  33,\n",
       "  34,\n",
       "  40,\n",
       "  33,\n",
       "  25,\n",
       "  34,\n",
       "  38,\n",
       "  36,\n",
       "  38,\n",
       "  35,\n",
       "  28,\n",
       "  35,\n",
       "  33,\n",
       "  39,\n",
       "  38,\n",
       "  38,\n",
       "  40,\n",
       "  33,\n",
       "  39,\n",
       "  43,\n",
       "  35,\n",
       "  40,\n",
       "  35,\n",
       "  34,\n",
       "  41,\n",
       "  36,\n",
       "  31,\n",
       "  35,\n",
       "  40,\n",
       "  38,\n",
       "  38,\n",
       "  38,\n",
       "  37,\n",
       "  40,\n",
       "  36,\n",
       "  31,\n",
       "  36,\n",
       "  43,\n",
       "  33,\n",
       "  44,\n",
       "  35,\n",
       "  41,\n",
       "  40,\n",
       "  34,\n",
       "  31,\n",
       "  37,\n",
       "  31,\n",
       "  36,\n",
       "  40,\n",
       "  40,\n",
       "  39,\n",
       "  43,\n",
       "  40,\n",
       "  41,\n",
       "  29,\n",
       "  33,\n",
       "  30,\n",
       "  32,\n",
       "  34,\n",
       "  41,\n",
       "  37,\n",
       "  38,\n",
       "  34,\n",
       "  37,\n",
       "  34,\n",
       "  31,\n",
       "  41,\n",
       "  34,\n",
       "  43,\n",
       "  38,\n",
       "  39,\n",
       "  32,\n",
       "  38,\n",
       "  34,\n",
       "  33,\n",
       "  41,\n",
       "  43,\n",
       "  36,\n",
       "  43,\n",
       "  43,\n",
       "  35,\n",
       "  39,\n",
       "  35,\n",
       "  35,\n",
       "  42,\n",
       "  38,\n",
       "  28,\n",
       "  31,\n",
       "  33,\n",
       "  38,\n",
       "  36,\n",
       "  37,\n",
       "  36,\n",
       "  33,\n",
       "  32,\n",
       "  42,\n",
       "  38,\n",
       "  41,\n",
       "  40,\n",
       "  42,\n",
       "  39,\n",
       "  35,\n",
       "  31,\n",
       "  31,\n",
       "  36,\n",
       "  35,\n",
       "  35,\n",
       "  42,\n",
       "  41,\n",
       "  27,\n",
       "  37,\n",
       "  40,\n",
       "  29,\n",
       "  33,\n",
       "  39,\n",
       "  33,\n",
       "  31,\n",
       "  40,\n",
       "  28,\n",
       "  ...],\n",
       " [11,\n",
       "  12,\n",
       "  10,\n",
       "  9,\n",
       "  13,\n",
       "  10,\n",
       "  12,\n",
       "  11,\n",
       "  11,\n",
       "  10,\n",
       "  9,\n",
       "  9,\n",
       "  13,\n",
       "  12,\n",
       "  11,\n",
       "  11,\n",
       "  10,\n",
       "  13,\n",
       "  9,\n",
       "  8,\n",
       "  9,\n",
       "  8,\n",
       "  6,\n",
       "  9,\n",
       "  11,\n",
       "  11,\n",
       "  12,\n",
       "  9,\n",
       "  9,\n",
       "  8,\n",
       "  10,\n",
       "  11,\n",
       "  10,\n",
       "  10,\n",
       "  11,\n",
       "  10,\n",
       "  8,\n",
       "  6,\n",
       "  8,\n",
       "  10,\n",
       "  9,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  9,\n",
       "  10,\n",
       "  8,\n",
       "  10,\n",
       "  11,\n",
       "  1,\n",
       "  8,\n",
       "  13,\n",
       "  9,\n",
       "  13,\n",
       "  9,\n",
       "  11,\n",
       "  11,\n",
       "  10,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  9,\n",
       "  7,\n",
       "  9,\n",
       "  10,\n",
       "  9,\n",
       "  9,\n",
       "  11,\n",
       "  9,\n",
       "  12,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  9,\n",
       "  6,\n",
       "  10,\n",
       "  8,\n",
       "  12,\n",
       "  12,\n",
       "  10,\n",
       "  14,\n",
       "  11,\n",
       "  10,\n",
       "  9,\n",
       "  8,\n",
       "  8,\n",
       "  9,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  9,\n",
       "  12,\n",
       "  8,\n",
       "  8,\n",
       "  9,\n",
       "  11,\n",
       "  8,\n",
       "  10,\n",
       "  7,\n",
       "  11,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  8,\n",
       "  11,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  11,\n",
       "  9,\n",
       "  11,\n",
       "  11,\n",
       "  9,\n",
       "  13,\n",
       "  10,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  8,\n",
       "  9,\n",
       "  11,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  10,\n",
       "  8,\n",
       "  7,\n",
       "  7,\n",
       "  9,\n",
       "  12,\n",
       "  11,\n",
       "  9,\n",
       "  13,\n",
       "  8,\n",
       "  8,\n",
       "  10,\n",
       "  12,\n",
       "  14,\n",
       "  8,\n",
       "  11,\n",
       "  9,\n",
       "  11,\n",
       "  10,\n",
       "  9,\n",
       "  11,\n",
       "  12,\n",
       "  9,\n",
       "  8,\n",
       "  8,\n",
       "  9,\n",
       "  8,\n",
       "  9,\n",
       "  7,\n",
       "  9,\n",
       "  9,\n",
       "  15,\n",
       "  14,\n",
       "  10,\n",
       "  12,\n",
       "  10,\n",
       "  10,\n",
       "  9,\n",
       "  10,\n",
       "  7,\n",
       "  9,\n",
       "  10,\n",
       "  7,\n",
       "  11,\n",
       "  8,\n",
       "  11,\n",
       "  12,\n",
       "  11,\n",
       "  8,\n",
       "  9,\n",
       "  11,\n",
       "  8,\n",
       "  8,\n",
       "  6,\n",
       "  8,\n",
       "  9,\n",
       "  8,\n",
       "  9,\n",
       "  12,\n",
       "  13,\n",
       "  11,\n",
       "  10,\n",
       "  14,\n",
       "  10,\n",
       "  10,\n",
       "  8,\n",
       "  9,\n",
       "  6,\n",
       "  9,\n",
       "  9,\n",
       "  11,\n",
       "  9,\n",
       "  8,\n",
       "  11,\n",
       "  11,\n",
       "  10,\n",
       "  10,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  11,\n",
       "  9,\n",
       "  9,\n",
       "  11,\n",
       "  8,\n",
       "  11,\n",
       "  12,\n",
       "  10,\n",
       "  8,\n",
       "  10,\n",
       "  13,\n",
       "  9,\n",
       "  13,\n",
       "  8,\n",
       "  12,\n",
       "  9,\n",
       "  10,\n",
       "  12,\n",
       "  8,\n",
       "  10,\n",
       "  7,\n",
       "  9,\n",
       "  7,\n",
       "  12,\n",
       "  10,\n",
       "  10,\n",
       "  8,\n",
       "  10,\n",
       "  9,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  12,\n",
       "  10,\n",
       "  11,\n",
       "  9,\n",
       "  9,\n",
       "  11,\n",
       "  9,\n",
       "  12,\n",
       "  10,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  9,\n",
       "  10,\n",
       "  9,\n",
       "  8,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  9,\n",
       "  10,\n",
       "  8,\n",
       "  5,\n",
       "  12,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  8,\n",
       "  11,\n",
       "  10,\n",
       "  10,\n",
       "  11,\n",
       "  11,\n",
       "  10,\n",
       "  12,\n",
       "  8,\n",
       "  9,\n",
       "  11,\n",
       "  6,\n",
       "  8,\n",
       "  10,\n",
       "  10,\n",
       "  11,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  8,\n",
       "  8,\n",
       "  9,\n",
       "  11,\n",
       "  8,\n",
       "  8,\n",
       "  9,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  9,\n",
       "  11,\n",
       "  11,\n",
       "  8,\n",
       "  9,\n",
       "  13,\n",
       "  12,\n",
       "  11,\n",
       "  10,\n",
       "  11,\n",
       "  10,\n",
       "  9,\n",
       "  12,\n",
       "  9,\n",
       "  8,\n",
       "  12,\n",
       "  10,\n",
       "  9,\n",
       "  9,\n",
       "  8,\n",
       "  10,\n",
       "  9,\n",
       "  9,\n",
       "  8,\n",
       "  11,\n",
       "  8,\n",
       "  14,\n",
       "  10,\n",
       "  9,\n",
       "  13,\n",
       "  10,\n",
       "  9,\n",
       "  11,\n",
       "  10,\n",
       "  12,\n",
       "  10,\n",
       "  14,\n",
       "  10,\n",
       "  6,\n",
       "  11,\n",
       "  9,\n",
       "  8,\n",
       "  8,\n",
       "  10,\n",
       "  9,\n",
       "  8,\n",
       "  10,\n",
       "  10,\n",
       "  8,\n",
       "  10,\n",
       "  15,\n",
       "  12,\n",
       "  11,\n",
       "  8,\n",
       "  10,\n",
       "  10,\n",
       "  12,\n",
       "  12,\n",
       "  10,\n",
       "  14,\n",
       "  9,\n",
       "  14,\n",
       "  10,\n",
       "  9,\n",
       "  8,\n",
       "  6,\n",
       "  11,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  9,\n",
       "  8,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  8,\n",
       "  6,\n",
       "  10,\n",
       "  12,\n",
       "  12,\n",
       "  9,\n",
       "  9,\n",
       "  11,\n",
       "  10,\n",
       "  11,\n",
       "  8,\n",
       "  10,\n",
       "  12,\n",
       "  10,\n",
       "  7,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  12,\n",
       "  11,\n",
       "  10,\n",
       "  9,\n",
       "  8,\n",
       "  10,\n",
       "  9,\n",
       "  10,\n",
       "  13,\n",
       "  10,\n",
       "  9,\n",
       "  9,\n",
       "  8,\n",
       "  10,\n",
       "  8,\n",
       "  12,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  12,\n",
       "  8,\n",
       "  8,\n",
       "  7,\n",
       "  10,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  8,\n",
       "  12,\n",
       "  8,\n",
       "  10,\n",
       "  10,\n",
       "  6,\n",
       "  8,\n",
       "  11,\n",
       "  12,\n",
       "  6,\n",
       "  9,\n",
       "  11,\n",
       "  10,\n",
       "  11,\n",
       "  11,\n",
       "  10,\n",
       "  10,\n",
       "  12,\n",
       "  12,\n",
       "  11,\n",
       "  9,\n",
       "  9,\n",
       "  11,\n",
       "  9,\n",
       "  11,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  6,\n",
       "  9,\n",
       "  12,\n",
       "  11,\n",
       "  13,\n",
       "  9,\n",
       "  11,\n",
       "  9,\n",
       "  13,\n",
       "  10,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  9,\n",
       "  9,\n",
       "  11,\n",
       "  12,\n",
       "  8,\n",
       "  11,\n",
       "  9,\n",
       "  11,\n",
       "  9,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  8,\n",
       "  10,\n",
       "  10,\n",
       "  11,\n",
       "  13,\n",
       "  8,\n",
       "  12,\n",
       "  10,\n",
       "  11,\n",
       "  8,\n",
       "  9,\n",
       "  13,\n",
       "  10,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  9,\n",
       "  9,\n",
       "  8,\n",
       "  10,\n",
       "  8,\n",
       "  9,\n",
       "  11,\n",
       "  9,\n",
       "  9,\n",
       "  8,\n",
       "  9,\n",
       "  11,\n",
       "  9,\n",
       "  13,\n",
       "  10,\n",
       "  12,\n",
       "  10,\n",
       "  12,\n",
       "  11,\n",
       "  11,\n",
       "  13,\n",
       "  10,\n",
       "  8,\n",
       "  10,\n",
       "  10,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  11,\n",
       "  11,\n",
       "  7,\n",
       "  8,\n",
       "  8,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  10,\n",
       "  11,\n",
       "  13,\n",
       "  10,\n",
       "  12,\n",
       "  10,\n",
       "  9,\n",
       "  12,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  10,\n",
       "  11,\n",
       "  13,\n",
       "  10,\n",
       "  11,\n",
       "  11,\n",
       "  10,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  7,\n",
       "  6,\n",
       "  10,\n",
       "  7,\n",
       "  11,\n",
       "  11,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  10,\n",
       "  8,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  14,\n",
       "  11,\n",
       "  10,\n",
       "  8,\n",
       "  10,\n",
       "  12,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  9,\n",
       "  11,\n",
       "  11,\n",
       "  12,\n",
       "  12,\n",
       "  10,\n",
       "  11,\n",
       "  10,\n",
       "  9,\n",
       "  11,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  9,\n",
       "  7,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  8,\n",
       "  9,\n",
       "  11,\n",
       "  8,\n",
       "  9,\n",
       "  11,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  9,\n",
       "  10,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  9,\n",
       "  9,\n",
       "  11,\n",
       "  8,\n",
       "  10,\n",
       "  10,\n",
       "  9,\n",
       "  8,\n",
       "  11,\n",
       "  7,\n",
       "  10,\n",
       "  9,\n",
       "  10,\n",
       "  7,\n",
       "  10,\n",
       "  9,\n",
       "  8,\n",
       "  10,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  8,\n",
       "  10,\n",
       "  11,\n",
       "  10,\n",
       "  11,\n",
       "  9,\n",
       "  8,\n",
       "  13,\n",
       "  8,\n",
       "  11,\n",
       "  7,\n",
       "  9,\n",
       "  10,\n",
       "  14,\n",
       "  9,\n",
       "  9,\n",
       "  11,\n",
       "  10,\n",
       "  11,\n",
       "  8,\n",
       "  9,\n",
       "  13,\n",
       "  10,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  10,\n",
       "  9,\n",
       "  7,\n",
       "  10,\n",
       "  9,\n",
       "  11,\n",
       "  8,\n",
       "  11,\n",
       "  8,\n",
       "  10,\n",
       "  8,\n",
       "  9,\n",
       "  7,\n",
       "  8,\n",
       "  10,\n",
       "  9,\n",
       "  8,\n",
       "  8,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  8,\n",
       "  12,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  11,\n",
       "  9,\n",
       "  8,\n",
       "  10,\n",
       "  9,\n",
       "  12,\n",
       "  7,\n",
       "  11,\n",
       "  12,\n",
       "  8,\n",
       "  10,\n",
       "  7,\n",
       "  9,\n",
       "  11,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  11,\n",
       "  8,\n",
       "  10,\n",
       "  12,\n",
       "  11,\n",
       "  10,\n",
       "  9,\n",
       "  10,\n",
       "  7,\n",
       "  11,\n",
       "  3,\n",
       "  9,\n",
       "  12,\n",
       "  11,\n",
       "  9,\n",
       "  11,\n",
       "  7,\n",
       "  7,\n",
       "  11,\n",
       "  8,\n",
       "  13,\n",
       "  9,\n",
       "  12,\n",
       "  11,\n",
       "  8,\n",
       "  10,\n",
       "  8,\n",
       "  11,\n",
       "  10,\n",
       "  11,\n",
       "  7,\n",
       "  10,\n",
       "  9,\n",
       "  10,\n",
       "  8,\n",
       "  9,\n",
       "  11,\n",
       "  7,\n",
       "  11,\n",
       "  11,\n",
       "  10,\n",
       "  10,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  11,\n",
       "  10,\n",
       "  10,\n",
       "  9,\n",
       "  8,\n",
       "  10,\n",
       "  9,\n",
       "  10,\n",
       "  6,\n",
       "  10,\n",
       "  7,\n",
       "  10,\n",
       "  12,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  8,\n",
       "  11,\n",
       "  11,\n",
       "  10,\n",
       "  13,\n",
       "  11,\n",
       "  11,\n",
       "  8,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  12,\n",
       "  9,\n",
       "  8,\n",
       "  8,\n",
       "  10,\n",
       "  9,\n",
       "  9,\n",
       "  7,\n",
       "  11,\n",
       "  8,\n",
       "  8,\n",
       "  12,\n",
       "  11,\n",
       "  9,\n",
       "  12,\n",
       "  11,\n",
       "  9,\n",
       "  13,\n",
       "  13,\n",
       "  8,\n",
       "  9,\n",
       "  12,\n",
       "  11,\n",
       "  11,\n",
       "  10,\n",
       "  12,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  8,\n",
       "  10,\n",
       "  10,\n",
       "  9,\n",
       "  14,\n",
       "  8,\n",
       "  11,\n",
       "  9,\n",
       "  7,\n",
       "  11,\n",
       "  12,\n",
       "  10,\n",
       "  12,\n",
       "  11,\n",
       "  11,\n",
       "  10,\n",
       "  9,\n",
       "  7,\n",
       "  9,\n",
       "  8,\n",
       "  11,\n",
       "  8,\n",
       "  9,\n",
       "  8,\n",
       "  12,\n",
       "  10,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  12,\n",
       "  10,\n",
       "  12,\n",
       "  13,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  9,\n",
       "  13,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  8,\n",
       "  8,\n",
       "  10,\n",
       "  9,\n",
       "  9,\n",
       "  7,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  11,\n",
       "  13,\n",
       "  9,\n",
       "  11,\n",
       "  11,\n",
       "  12,\n",
       "  6,\n",
       "  10,\n",
       "  12,\n",
       "  9,\n",
       "  8,\n",
       "  7,\n",
       "  9,\n",
       "  8,\n",
       "  10,\n",
       "  9,\n",
       "  8,\n",
       "  8,\n",
       "  7,\n",
       "  7,\n",
       "  9,\n",
       "  10,\n",
       "  9,\n",
       "  8,\n",
       "  9,\n",
       "  13,\n",
       "  12,\n",
       "  8,\n",
       "  11,\n",
       "  13,\n",
       "  11,\n",
       "  10,\n",
       "  11,\n",
       "  11,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  7,\n",
       "  10,\n",
       "  13,\n",
       "  10,\n",
       "  7,\n",
       "  10,\n",
       "  10,\n",
       "  9,\n",
       "  11,\n",
       "  9,\n",
       "  10,\n",
       "  9,\n",
       "  8,\n",
       "  7,\n",
       "  7,\n",
       "  9,\n",
       "  11,\n",
       "  10,\n",
       "  10,\n",
       "  11,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  11,\n",
       "  8,\n",
       "  13,\n",
       "  10,\n",
       "  12,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  11,\n",
       "  10,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  10,\n",
       "  10,\n",
       "  12,\n",
       "  11,\n",
       "  11,\n",
       "  12,\n",
       "  7,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  13,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  9,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  6,\n",
       "  10,\n",
       "  10,\n",
       "  11,\n",
       "  9,\n",
       "  10,\n",
       "  8,\n",
       "  10,\n",
       "  7,\n",
       "  11,\n",
       "  10,\n",
       "  12,\n",
       "  11,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  9,\n",
       "  9,\n",
       "  ...])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text_len, headlines_len 확인\n",
    "text_len, headlines_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cad5fba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98360"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "176f1af5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_113/3701299234.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcheck_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_113/3701299234.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcheck_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'str'"
     ]
    }
   ],
   "source": [
    "check_len = [len(s.str.split()) for s in data['text']]\n",
    "len(text_len), len(check_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad39577",
   "metadata": {},
   "source": [
    "- 여기에서 사용한건 **python의 split 함수**다!\n",
    "- 다시 코드를 진행한다:)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f3ac103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    saurav kant alumnus upgrad iiit pg program mac...\n",
       "1    kunal shah credit card bill payment platform c...\n",
       "2    new zealand defeated india wickets fourth odi ...\n",
       "3    aegon life iterm insurance plan customers enjo...\n",
       "4    speaking sexual harassment allegations rajkuma...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 형태 확인\n",
    "data['text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e78bb6",
   "metadata": {},
   "source": [
    "- 각 row에 있는 데이터의 길이가 text_len, headlines_len에 담겨있다.\n",
    "- 노드에서 진행했던 kaggle의 데이터는 샘플별로 길이 차이가 커서 위 그래프 결과를 참고로 `max_len`를 설정하고 이 값을 기준으로 데이터를 제외시키고 정수 인코딩을 진행했다. 따라서 진행해본다.<br>\n",
    "    (*사실 이 길이를 조정하는 작업을 왜 하는지 정확한 이해가 부족한데 찬찬히 이후 NLP프로젝트도 진행하면서 공부를 쌓아가보려고한다*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "312305dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set max length\n",
    "text_max_len = 45       # text 평균길이: 35,최대길이: 60\n",
    "headlines_max_len = 15  # head 평균길이: 9, 최대길이: 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae719b86",
   "metadata": {},
   "source": [
    "### `below_threshold_len` : max length 로 데이터 몇 %가 해당하는지 확인하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3cad3017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max length 로 데이터 몇 %가 해당하는지 확인하는 함수\n",
    "def below_threshold_len(max_len, nested_list):\n",
    "    cnt=0\n",
    "    for s in nested_list:\n",
    "        if(len(s.split()) <= max_len):\n",
    "            cnt = cnt + 1\n",
    "    print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83bd4ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 45 이하인 샘플의 비율: 0.9967771451809678\n",
      "전체 샘플 중 길이가 15 이하인 샘플의 비율: 0.9999694997966653\n"
     ]
    }
   ],
   "source": [
    "# check percentage\n",
    "below_threshold_len(text_max_len, data['text'])\n",
    "below_threshold_len(headlines_max_len, data['headlines'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10960f8d",
   "metadata": {},
   "source": [
    "- max length 기준으로 데이터 99% 이상이 해당한다.\n",
    "- 추가 작업을 진행하지 않아도 될것 같아서 max length를 기준으로 초과 데이터를 삭제하는 부분은 패스해도 될것같다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17edd5a8",
   "metadata": {},
   "source": [
    "## 5) Add SOS start token & EOS end token\n",
    "- decoder에 SOS, EOS token 추가\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### 💡 Start token , End token\n",
    "<a href='https://arxiv.org/pdf/1812.02303.pdf'><img src='./img/seq2seq_token.png' width=40% height=40%></a>\n",
    "- 훈련데이터의 예측 대상 시퀀스의 앞, 뒤에는 시작토큰, 종료 토큰을 넣어주는 전처리를 통해 어디에서 멈춰야하는지 지정해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce4125a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upgrad learner switches to career in ml al wit...</td>\n",
       "      <td>saurav kant alumnus upgrad iiit pg program mac...</td>\n",
       "      <td>sostoken upgrad learner switches to career in ...</td>\n",
       "      <td>upgrad learner switches to career in ml al wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>delhi techie wins free food from swiggy for on...</td>\n",
       "      <td>kunal shah credit card bill payment platform c...</td>\n",
       "      <td>sostoken delhi techie wins free food from swig...</td>\n",
       "      <td>delhi techie wins free food from swiggy for on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "      <td>new zealand defeated india wickets fourth odi ...</td>\n",
       "      <td>sostoken new zealand end rohit sharma led indi...</td>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "      <td>aegon life iterm insurance plan customers enjo...</td>\n",
       "      <td>sostoken aegon life iterm insurance plan helps...</td>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>have known hirani for yrs what if metoo claims...</td>\n",
       "      <td>speaking sexual harassment allegations rajkuma...</td>\n",
       "      <td>sostoken have known hirani for yrs what if met...</td>\n",
       "      <td>have known hirani for yrs what if metoo claims...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upgrad learner switches to career in ml al wit...   \n",
       "1  delhi techie wins free food from swiggy for on...   \n",
       "2  new zealand end rohit sharma led india match w...   \n",
       "3  aegon life iterm insurance plan helps customer...   \n",
       "4  have known hirani for yrs what if metoo claims...   \n",
       "\n",
       "                                                text  \\\n",
       "0  saurav kant alumnus upgrad iiit pg program mac...   \n",
       "1  kunal shah credit card bill payment platform c...   \n",
       "2  new zealand defeated india wickets fourth odi ...   \n",
       "3  aegon life iterm insurance plan customers enjo...   \n",
       "4  speaking sexual harassment allegations rajkuma...   \n",
       "\n",
       "                                       decoder_input  \\\n",
       "0  sostoken upgrad learner switches to career in ...   \n",
       "1  sostoken delhi techie wins free food from swig...   \n",
       "2  sostoken new zealand end rohit sharma led indi...   \n",
       "3  sostoken aegon life iterm insurance plan helps...   \n",
       "4  sostoken have known hirani for yrs what if met...   \n",
       "\n",
       "                                      decoder_target  \n",
       "0  upgrad learner switches to career in ml al wit...  \n",
       "1  delhi techie wins free food from swiggy for on...  \n",
       "2  new zealand end rohit sharma led india match w...  \n",
       "3  aegon life iterm insurance plan helps customer...  \n",
       "4  have known hirani for yrs what if metoo claims...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add SOS, EOS at headlines data - 새로운 열로 추가한다\n",
    "data['decoder_input'] = data['headlines'].apply(lambda x: 'sostoken ' + x)\n",
    "data['decoder_target'] = data['headlines'].apply(lambda x: x + ' eostoken')\n",
    "\n",
    "# check data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32655c6",
   "metadata": {},
   "source": [
    "# Step 3. Seperate data\n",
    "- numpy array로 변환해서 numpy slicing 기능 사용 [참고-텍스트 데이터 분리방법](https://wikidocs.net/33274)\n",
    "- train:test를 8:2 비율로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a6d45653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98360,)\n",
      "(98360,)\n",
      "(98360,)\n"
     ]
    }
   ],
   "source": [
    "# change dataframe to numpy array \n",
    "encoder_input = np.array(data['text']) # input data of encoder\n",
    "decoder_input = np.array(data['decoder_input']) # input data of decoder\n",
    "decoder_target = np.array(data['decoder_target']) # label data of decoder\n",
    "\n",
    "# shape 확인\n",
    "print(encoder_input.shape)\n",
    "print(decoder_input.shape)\n",
    "print(decoder_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "195d815b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32539 92635 71821 ... 62569 58637 40158]\n"
     ]
    }
   ],
   "source": [
    "# encoder_input 과 1)크기, 형태가 같은 , 2)순서가 섞인 정수 시퀀스 생성\n",
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "23aa850c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['saurav kant alumnus upgrad iiit pg program machine learning artificial intelligence sr systems engineer infosys almost years work experience program upgrad degree career support helped transition data scientist tech mahindra salary hike upgrad online power learning powered lakh careers',\n",
       "        'kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year pranav kaushik delhi techie bagged reward spending cred coins users get one cred coin per rupee bill paid used avail rewards brands like ixigo bookmyshow ubereats cult fit',\n",
       "        'new zealand defeated india wickets fourth odi hamilton thursday win first match five match odi series india lost international match rohit sharma captaincy consecutive victories dating back march match witnessed india getting seventh lowest total odi cricket history',\n",
       "        'aegon life iterm insurance plan customers enjoy tax benefits premiums paid save taxes plan provides life cover age years also customers options insure critical illnesses disability accidental death benefit rider life cover age years'],\n",
       "       dtype=object),\n",
       " array(['sostoken upgrad learner switches to career in ml al with salary hike',\n",
       "        'sostoken delhi techie wins free food from swiggy for one year on cred',\n",
       "        'sostoken new zealand end rohit sharma led india match winning streak',\n",
       "        'sostoken aegon life iterm insurance plan helps customers save tax'],\n",
       "       dtype=object),\n",
       " array(['upgrad learner switches to career in ml al with salary hike eostoken',\n",
       "        'delhi techie wins free food from swiggy for one year on cred eostoken',\n",
       "        'new zealand end rohit sharma led india match winning streak eostoken',\n",
       "        'aegon life iterm insurance plan helps customers save tax eostoken'],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원래 데이터 확인\n",
    "encoder_input[:4], decoder_input[:4], decoder_target[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f6c7b5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*\n"
     ]
    }
   ],
   "source": [
    "# 위의 정수 시퀀스를 이용해서 데이터 샘플 순서를 정의해줌\n",
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "print(\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9ef2e352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*\n"
     ]
    }
   ],
   "source": [
    "decoder_target = decoder_target[indices]\n",
    "print(\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2490ce0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['us navy veteran sentenced life imprisonment killing indian engineer srinivas kuchibhotla hate crime kansas city bar february last year veteran also sentenced months imprisonment attempted murder two others heard shouting get country shooting kuchibhotla',\n",
       "        'many lakh teaching positions vacant government run schools across uttar pradesh rti query revealed state lakh teaching positions primary upper primary government schools lakh positions yet filled notably primary upper primary schools run state one teacher',\n",
       "        'customary inauguration letter former us president barack obama left successor donald trump revealed obama left four pieces advice trump letter urging trump sustain international order build ladders success hard working people obama advised trump protect democratic institutions traditions',\n",
       "        'bjp mla mithilesh kumar tiwari monday called congress president rahul gandhi rjd leader tejashwi yadav bunty babli remark purportedly refers movie bunty aur babli wherein abhishek bachchan rani mukerji played role fraudsters gandhi yadav recently seen together several occasions amidst opposition parties attempts forge alliance'],\n",
       "       dtype=object),\n",
       " array(['sostoken us navy veteran who murdered indian techie sentenced to life',\n",
       "        'sostoken lakh teaching positions vacant in up govt run schools',\n",
       "        'sostoken obama inauguration letter to trump revealed',\n",
       "        'sostoken bjp mla dubs rahul and tejashwi as bunty and babli'],\n",
       "       dtype=object),\n",
       " array(['us navy veteran who murdered indian techie sentenced to life eostoken',\n",
       "        'lakh teaching positions vacant in up govt run schools eostoken',\n",
       "        'obama inauguration letter to trump revealed eostoken',\n",
       "        'bjp mla dubs rahul and tejashwi as bunty and babli eostoken'],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 바뀐 데이터 확인\n",
    "encoder_input[:4], decoder_input[:4], decoder_target[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f689ff6a",
   "metadata": {},
   "source": [
    "- indexing을 한다고 생각하면 될것같다. 해당 순서의 index를 가진 df 를 만들어내는거라고 이해했다.\n",
    "\n",
    "\n",
    "- 말이 안되는 단어들이 꽤 보여서 찾아봤더니 약어표현들이다\n",
    "    - `bjp`: The Bharatiya Janata Party is a political party in India\n",
    "    - `mla`, `dubs` ..\n",
    "    - [인도 정치 관련 뉴스](https://indianexpress.com/article/political-pulse/bjp-dubs-arrest-1992-riot-case-karnataka-witch-hunt-against-hindus-links-ram-temple-event-9092233/)에서 사용되는 단어이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b466e2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of test data: 19672\n"
     ]
    }
   ],
   "source": [
    "# [전체 데이터 크기 * 0.2]로 테스트 데이터 크기 정의 (20%)\n",
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "print('# of test data:', n_of_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9279db",
   "metadata": {},
   "source": [
    "- 전체 데이터의 20%인 **19672개**가 test 데이터 개수가 된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "104f236d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 78688\n",
      "훈련 레이블의 개수 : 78688\n",
      "테스트 데이터의 개수 : 19672\n",
      "테스트 레이블의 개수 : 19672\n"
     ]
    }
   ],
   "source": [
    "# separate data\n",
    "\n",
    "# 거꾸로 indexing\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc39434",
   "metadata": {},
   "source": [
    "# Step 4. 단어 집합(vocabulary)만들기 & 정수 인코딩\n",
    "\n",
    "- 데이터의 단어를 모두 '정수'로 바꿔야 컴퓨터가 인식할수 있다\n",
    "- **각 단어에 고유한 정수**를 매핑 => `단어 집합(vocabulary)`을 만드는 과정\n",
    "\n",
    "**[참고]**\n",
    "- [위키독스](https://wikidocs.net/31766)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1a5d8b",
   "metadata": {},
   "source": [
    "## 1) 단어집합 vocabulary 생성\n",
    "- keras의 `tokenizer` 사용\n",
    "\n",
    "\n",
    "**[참고]**\n",
    "- [keras doc](https://keras.io/api/keras_nlp/tokenizers/tokenizer/)\n",
    "- [위키독스](https://wikidocs.net/182469)\n",
    "\n",
    "### text data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6318db05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make vocabulary with keras tokenizer\n",
    "src_tokenizer = Tokenizer()\n",
    "\n",
    "# encoder input train -> vocab\n",
    "src_tokenizer.fit_on_texts(encoder_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4791d4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Tokenizer in module keras_preprocessing.text object:\n",
      "\n",
      "class Tokenizer(builtins.object)\n",
      " |  Tokenizer(num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ', char_level=False, oov_token=None, document_count=0, **kwargs)\n",
      " |  \n",
      " |  Text tokenization utility class.\n",
      " |  \n",
      " |  This class allows to vectorize a text corpus, by turning each\n",
      " |  text into either a sequence of integers (each integer being the index\n",
      " |  of a token in a dictionary) or into a vector where the coefficient\n",
      " |  for each token could be binary, based on word count, based on tf-idf...\n",
      " |  \n",
      " |  # Arguments\n",
      " |      num_words: the maximum number of words to keep, based\n",
      " |          on word frequency. Only the most common `num_words-1` words will\n",
      " |          be kept.\n",
      " |      filters: a string where each element is a character that will be\n",
      " |          filtered from the texts. The default is all punctuation, plus\n",
      " |          tabs and line breaks, minus the `'` character.\n",
      " |      lower: boolean. Whether to convert the texts to lowercase.\n",
      " |      split: str. Separator for word splitting.\n",
      " |      char_level: if True, every character will be treated as a token.\n",
      " |      oov_token: if given, it will be added to word_index and used to\n",
      " |          replace out-of-vocabulary words during text_to_sequence calls\n",
      " |  \n",
      " |  By default, all punctuation is removed, turning the texts into\n",
      " |  space-separated sequences of words\n",
      " |  (words maybe include the `'` character). These sequences are then\n",
      " |  split into lists of tokens. They will then be indexed or vectorized.\n",
      " |  \n",
      " |  `0` is a reserved index that won't be assigned to any word.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ', char_level=False, oov_token=None, document_count=0, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit_on_sequences(self, sequences)\n",
      " |      Updates internal vocabulary based on a list of sequences.\n",
      " |      \n",
      " |      Required before using `sequences_to_matrix`\n",
      " |      (if `fit_on_texts` was never called).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          sequences: A list of sequence.\n",
      " |              A \"sequence\" is a list of integer word indices.\n",
      " |  \n",
      " |  fit_on_texts(self, texts)\n",
      " |      Updates internal vocabulary based on a list of texts.\n",
      " |      \n",
      " |      In the case where texts contains lists,\n",
      " |      we assume each entry of the lists to be a token.\n",
      " |      \n",
      " |      Required before using `texts_to_sequences` or `texts_to_matrix`.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          texts: can be a list of strings,\n",
      " |              a generator of strings (for memory-efficiency),\n",
      " |              or a list of list of strings.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the tokenizer configuration as Python dictionary.\n",
      " |      The word count dictionaries used by the tokenizer get serialized\n",
      " |      into plain JSON, so that the configuration can be read by other\n",
      " |      projects.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A Python dictionary with the tokenizer configuration.\n",
      " |  \n",
      " |  sequences_to_matrix(self, sequences, mode='binary')\n",
      " |      Converts a list of sequences into a Numpy matrix.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          sequences: list of sequences\n",
      " |              (a sequence is a list of integer word indices).\n",
      " |          mode: one of \"binary\", \"count\", \"tfidf\", \"freq\"\n",
      " |      \n",
      " |      # Returns\n",
      " |          A Numpy matrix.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: In case of invalid `mode` argument,\n",
      " |              or if the Tokenizer requires to be fit to sample data.\n",
      " |  \n",
      " |  sequences_to_texts(self, sequences)\n",
      " |      Transforms each sequence into a list of text.\n",
      " |      \n",
      " |      Only top `num_words-1` most frequent words will be taken into account.\n",
      " |      Only words known by the tokenizer will be taken into account.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          sequences: A list of sequences (list of integers).\n",
      " |      \n",
      " |      # Returns\n",
      " |          A list of texts (strings)\n",
      " |  \n",
      " |  sequences_to_texts_generator(self, sequences)\n",
      " |      Transforms each sequence in `sequences` to a list of texts(strings).\n",
      " |      \n",
      " |      Each sequence has to a list of integers.\n",
      " |      In other words, sequences should be a list of sequences\n",
      " |      \n",
      " |      Only top `num_words-1` most frequent words will be taken into account.\n",
      " |      Only words known by the tokenizer will be taken into account.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          sequences: A list of sequences.\n",
      " |      \n",
      " |      # Yields\n",
      " |          Yields individual texts.\n",
      " |  \n",
      " |  texts_to_matrix(self, texts, mode='binary')\n",
      " |      Convert a list of texts to a Numpy matrix.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          texts: list of strings.\n",
      " |          mode: one of \"binary\", \"count\", \"tfidf\", \"freq\".\n",
      " |      \n",
      " |      # Returns\n",
      " |          A Numpy matrix.\n",
      " |  \n",
      " |  texts_to_sequences(self, texts)\n",
      " |      Transforms each text in texts to a sequence of integers.\n",
      " |      \n",
      " |      Only top `num_words-1` most frequent words will be taken into account.\n",
      " |      Only words known by the tokenizer will be taken into account.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          texts: A list of texts (strings).\n",
      " |      \n",
      " |      # Returns\n",
      " |          A list of sequences.\n",
      " |  \n",
      " |  texts_to_sequences_generator(self, texts)\n",
      " |      Transforms each text in `texts` to a sequence of integers.\n",
      " |      \n",
      " |      Each item in texts can also be a list,\n",
      " |      in which case we assume each item of that list to be a token.\n",
      " |      \n",
      " |      Only top `num_words-1` most frequent words will be taken into account.\n",
      " |      Only words known by the tokenizer will be taken into account.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          texts: A list of texts (strings).\n",
      " |      \n",
      " |      # Yields\n",
      " |          Yields individual sequences.\n",
      " |  \n",
      " |  to_json(self, **kwargs)\n",
      " |      Returns a JSON string containing the tokenizer configuration.\n",
      " |      To load a tokenizer from a JSON string, use\n",
      " |      `keras.preprocessing.text.tokenizer_from_json(json_string)`.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `json.dumps()`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A JSON string containing the tokenizer configuration.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check data vocab\n",
    "help(src_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00be6ef",
   "metadata": {},
   "source": [
    "- 출력해서 보려고했는데 쉽지 않다. 일단 노드를 마친후에 추가공부를 해봐야겠다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c782353",
   "metadata": {},
   "source": [
    "- 생성된 vocabulary는 `src_tokenizer.word_index`에 저장되어 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "90be611c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'said': 1,\n",
       " 'india': 2,\n",
       " 'year': 3,\n",
       " 'added': 4,\n",
       " 'us': 5,\n",
       " 'also': 6,\n",
       " 'first': 7,\n",
       " 'government': 8,\n",
       " 'police': 9,\n",
       " 'people': 10,\n",
       " 'indian': 11,\n",
       " 'two': 12,\n",
       " 'old': 13,\n",
       " 'minister': 14,\n",
       " 'film': 15,\n",
       " 'president': 16,\n",
       " 'one': 17,\n",
       " 'world': 18,\n",
       " 'crore': 19,\n",
       " 'court': 20,\n",
       " 'state': 21,\n",
       " 'would': 22,\n",
       " 'reportedly': 23,\n",
       " 'years': 24,\n",
       " 'new': 25,\n",
       " 'time': 26,\n",
       " 'former': 27,\n",
       " 'delhi': 28,\n",
       " 'last': 29,\n",
       " 'three': 30,\n",
       " 'reports': 31,\n",
       " 'company': 32,\n",
       " 'like': 33,\n",
       " 'based': 34,\n",
       " 'earlier': 35,\n",
       " 'congress': 36,\n",
       " 'man': 37,\n",
       " 'bjp': 38,\n",
       " 'country': 39,\n",
       " 'team': 40,\n",
       " 'trump': 41,\n",
       " 'claimed': 42,\n",
       " 'day': 43,\n",
       " 'modi': 44,\n",
       " 'chief': 45,\n",
       " 'pakistan': 46,\n",
       " 'accused': 47,\n",
       " 'singh': 48,\n",
       " 'pm': 49,\n",
       " 'actor': 50,\n",
       " 'women': 51,\n",
       " 'million': 52,\n",
       " 'according': 53,\n",
       " 'allegedly': 54,\n",
       " 'made': 55,\n",
       " 'friday': 56,\n",
       " 'wednesday': 57,\n",
       " 'pradesh': 58,\n",
       " 'tuesday': 59,\n",
       " 'party': 60,\n",
       " 'comes': 61,\n",
       " 'monday': 62,\n",
       " 'lakh': 63,\n",
       " 'called': 64,\n",
       " 'woman': 65,\n",
       " 'video': 66,\n",
       " 'around': 67,\n",
       " 'asked': 68,\n",
       " 'billion': 69,\n",
       " 'thursday': 70,\n",
       " 'khan': 71,\n",
       " 'tweeted': 72,\n",
       " 'including': 73,\n",
       " 'took': 74,\n",
       " 'test': 75,\n",
       " 'cm': 76,\n",
       " 'mumbai': 77,\n",
       " 'case': 78,\n",
       " 'actress': 79,\n",
       " 'found': 80,\n",
       " 'revealed': 81,\n",
       " 'national': 82,\n",
       " 'could': 83,\n",
       " 'saturday': 84,\n",
       " 'four': 85,\n",
       " 'five': 86,\n",
       " 'sunday': 87,\n",
       " 'officials': 88,\n",
       " 'leader': 89,\n",
       " 'second': 90,\n",
       " 'arrested': 91,\n",
       " 'match': 92,\n",
       " 'wrote': 93,\n",
       " 'announced': 94,\n",
       " 'high': 95,\n",
       " 'following': 96,\n",
       " 'group': 97,\n",
       " 'used': 98,\n",
       " 'captain': 99,\n",
       " 'however': 100,\n",
       " 'china': 101,\n",
       " 'since': 102,\n",
       " 'startup': 103,\n",
       " 'take': 104,\n",
       " 'notably': 105,\n",
       " 'cricket': 106,\n",
       " 'users': 107,\n",
       " 'alleged': 108,\n",
       " 'part': 109,\n",
       " 'media': 110,\n",
       " 'due': 111,\n",
       " 'narendra': 112,\n",
       " 'killed': 113,\n",
       " 'family': 114,\n",
       " 'may': 115,\n",
       " 'bank': 116,\n",
       " 'get': 117,\n",
       " 'international': 118,\n",
       " 'make': 119,\n",
       " 'th': 120,\n",
       " 'ceo': 121,\n",
       " 'led': 122,\n",
       " 'adding': 123,\n",
       " 'per': 124,\n",
       " 'donald': 125,\n",
       " 'days': 126,\n",
       " 'security': 127,\n",
       " 'air': 128,\n",
       " 'gandhi': 129,\n",
       " 'twitter': 130,\n",
       " 'set': 131,\n",
       " 'six': 132,\n",
       " 'month': 133,\n",
       " 'facebook': 134,\n",
       " 'home': 135,\n",
       " 'south': 136,\n",
       " 'life': 137,\n",
       " 'house': 138,\n",
       " 'work': 139,\n",
       " 'saying': 140,\n",
       " 'series': 141,\n",
       " 'kapoor': 142,\n",
       " 'picture': 143,\n",
       " 'data': 144,\n",
       " 'number': 145,\n",
       " 'help': 146,\n",
       " 'incident': 147,\n",
       " 'report': 148,\n",
       " 'another': 149,\n",
       " 'north': 150,\n",
       " 'prime': 151,\n",
       " 'official': 152,\n",
       " 'using': 153,\n",
       " 'several': 154,\n",
       " 'social': 155,\n",
       " 'car': 156,\n",
       " 'wife': 157,\n",
       " 'girl': 158,\n",
       " 'later': 159,\n",
       " 'uttar': 160,\n",
       " 'post': 161,\n",
       " 'seen': 162,\n",
       " 'back': 163,\n",
       " 'board': 164,\n",
       " 'australia': 165,\n",
       " 'released': 166,\n",
       " 'show': 167,\n",
       " 'public': 168,\n",
       " 'kumar': 169,\n",
       " 'next': 170,\n",
       " 'least': 171,\n",
       " 'talking': 172,\n",
       " 'supreme': 173,\n",
       " 'week': 174,\n",
       " 'city': 175,\n",
       " 'hospital': 176,\n",
       " 'students': 177,\n",
       " 'rahul': 178,\n",
       " 'upcoming': 179,\n",
       " 'google': 180,\n",
       " 'elections': 181,\n",
       " 'among': 182,\n",
       " 'become': 183,\n",
       " 'recently': 184,\n",
       " 'launched': 185,\n",
       " 'death': 186,\n",
       " 'money': 187,\n",
       " 'user': 188,\n",
       " 'union': 189,\n",
       " 'third': 190,\n",
       " 'school': 191,\n",
       " 'nearly': 192,\n",
       " 'got': 193,\n",
       " 'filed': 194,\n",
       " 'without': 195,\n",
       " 'months': 196,\n",
       " 'kohli': 197,\n",
       " 'children': 198,\n",
       " 'son': 199,\n",
       " 'cup': 200,\n",
       " 'men': 201,\n",
       " 'technology': 202,\n",
       " 'taken': 203,\n",
       " 'even': 204,\n",
       " 'shared': 205,\n",
       " 'many': 206,\n",
       " 'centre': 207,\n",
       " 'record': 208,\n",
       " 'attack': 209,\n",
       " 'times': 210,\n",
       " 'uk': 211,\n",
       " 'run': 212,\n",
       " 'away': 213,\n",
       " 'co': 214,\n",
       " 'director': 215,\n",
       " 'worth': 216,\n",
       " 'ever': 217,\n",
       " 'named': 218,\n",
       " 'others': 219,\n",
       " 'online': 220,\n",
       " 'win': 221,\n",
       " 'hit': 222,\n",
       " 'father': 223,\n",
       " 'held': 224,\n",
       " 'ministry': 225,\n",
       " 'release': 226,\n",
       " 'district': 227,\n",
       " 'researchers': 228,\n",
       " 'deal': 229,\n",
       " 'law': 230,\n",
       " 'place': 231,\n",
       " 'use': 232,\n",
       " 'sharma': 233,\n",
       " 'shah': 234,\n",
       " 'making': 235,\n",
       " 'came': 236,\n",
       " 'cannot': 237,\n",
       " 'korea': 238,\n",
       " 'across': 239,\n",
       " 'england': 240,\n",
       " 'long': 241,\n",
       " 'final': 242,\n",
       " 'founder': 243,\n",
       " 'order': 244,\n",
       " 'given': 245,\n",
       " 'body': 246,\n",
       " 'reported': 247,\n",
       " 'died': 248,\n",
       " 'system': 249,\n",
       " 'told': 250,\n",
       " 'directed': 251,\n",
       " 'open': 252,\n",
       " 'water': 253,\n",
       " 'capital': 254,\n",
       " 'received': 255,\n",
       " 'general': 256,\n",
       " 'army': 257,\n",
       " 'every': 258,\n",
       " 'best': 259,\n",
       " 'working': 260,\n",
       " 'event': 261,\n",
       " 'taking': 262,\n",
       " 'flight': 263,\n",
       " 'american': 264,\n",
       " 'chinese': 265,\n",
       " 'daughter': 266,\n",
       " 'way': 267,\n",
       " 'started': 268,\n",
       " 'along': 269,\n",
       " 'pay': 270,\n",
       " 'members': 271,\n",
       " 'come': 272,\n",
       " 'hours': 273,\n",
       " 'karnataka': 274,\n",
       " 'want': 275,\n",
       " 'department': 276,\n",
       " 'lost': 277,\n",
       " 'top': 278,\n",
       " 'person': 279,\n",
       " 'assembly': 280,\n",
       " 'tax': 281,\n",
       " 'left': 282,\n",
       " 'mother': 283,\n",
       " 'united': 284,\n",
       " 'play': 285,\n",
       " 'app': 286,\n",
       " 'go': 287,\n",
       " 'firm': 288,\n",
       " 'fire': 289,\n",
       " 'space': 290,\n",
       " 'raised': 291,\n",
       " 'never': 292,\n",
       " 'seven': 293,\n",
       " 'runs': 294,\n",
       " 'today': 295,\n",
       " 'decision': 296,\n",
       " 'apple': 297,\n",
       " 'kashmir': 298,\n",
       " 'university': 299,\n",
       " 'services': 300,\n",
       " 'name': 301,\n",
       " 'cricketer': 302,\n",
       " 'went': 303,\n",
       " 'odi': 304,\n",
       " 'within': 305,\n",
       " 'became': 306,\n",
       " 'human': 307,\n",
       " 'highest': 308,\n",
       " 'service': 309,\n",
       " 'right': 310,\n",
       " 'injured': 311,\n",
       " 'largest': 312,\n",
       " 'good': 313,\n",
       " 'star': 314,\n",
       " 'end': 315,\n",
       " 'australian': 316,\n",
       " 'well': 317,\n",
       " 'officer': 318,\n",
       " 'airport': 319,\n",
       " 'employees': 320,\n",
       " 'power': 321,\n",
       " 'authorities': 322,\n",
       " 'read': 323,\n",
       " 'speaking': 324,\n",
       " 'issued': 325,\n",
       " 'player': 326,\n",
       " 'chairman': 327,\n",
       " 'action': 328,\n",
       " 'food': 329,\n",
       " 'gold': 330,\n",
       " 'playing': 331,\n",
       " 'countries': 332,\n",
       " 'states': 333,\n",
       " 'films': 334,\n",
       " 'bengaluru': 335,\n",
       " 'kerala': 336,\n",
       " 'league': 337,\n",
       " 'maharashtra': 338,\n",
       " 'business': 339,\n",
       " 'known': 340,\n",
       " 'sexual': 341,\n",
       " 'total': 342,\n",
       " 'ram': 343,\n",
       " 'companies': 344,\n",
       " 'give': 345,\n",
       " 'russia': 346,\n",
       " 'december': 347,\n",
       " 'round': 348,\n",
       " 'meeting': 349,\n",
       " 'meanwhile': 350,\n",
       " 'posted': 351,\n",
       " 'gujarat': 352,\n",
       " 'eight': 353,\n",
       " 'office': 354,\n",
       " 'foreign': 355,\n",
       " 'march': 356,\n",
       " 'central': 357,\n",
       " 'russian': 358,\n",
       " 'move': 359,\n",
       " 'information': 360,\n",
       " 'slammed': 361,\n",
       " 'private': 362,\n",
       " 'currently': 363,\n",
       " 'support': 364,\n",
       " 'face': 365,\n",
       " 'virat': 366,\n",
       " 'free': 367,\n",
       " 'sent': 368,\n",
       " 'role': 369,\n",
       " 'share': 370,\n",
       " 'special': 371,\n",
       " 'tweet': 372,\n",
       " 'near': 373,\n",
       " 'june': 374,\n",
       " 'election': 375,\n",
       " 'cases': 376,\n",
       " 'head': 377,\n",
       " 'going': 378,\n",
       " 'child': 379,\n",
       " 'visit': 380,\n",
       " 'amid': 381,\n",
       " 'ahead': 382,\n",
       " 'salman': 383,\n",
       " 'issue': 384,\n",
       " 'list': 385,\n",
       " 'ball': 386,\n",
       " 'tamil': 387,\n",
       " 'registered': 388,\n",
       " 'think': 389,\n",
       " 'instagram': 390,\n",
       " 'passengers': 391,\n",
       " 'claiming': 392,\n",
       " 'un': 393,\n",
       " 'non': 394,\n",
       " 'ban': 395,\n",
       " 'song': 396,\n",
       " 'april': 397,\n",
       " 'statement': 398,\n",
       " 'market': 399,\n",
       " 'scored': 400,\n",
       " 'war': 401,\n",
       " 'love': 402,\n",
       " 'husband': 403,\n",
       " 'scheduled': 404,\n",
       " 'need': 405,\n",
       " 'investigation': 406,\n",
       " 'ipl': 407,\n",
       " 'sabha': 408,\n",
       " 'boy': 409,\n",
       " 'commission': 410,\n",
       " 'ago': 411,\n",
       " 'know': 412,\n",
       " 'september': 413,\n",
       " 'played': 414,\n",
       " 'january': 415,\n",
       " 'ex': 416,\n",
       " 'west': 417,\n",
       " 'real': 418,\n",
       " 'much': 419,\n",
       " 'bihar': 420,\n",
       " 'secretary': 421,\n",
       " 'class': 422,\n",
       " 'nuclear': 423,\n",
       " 'health': 424,\n",
       " 'global': 425,\n",
       " 'uber': 426,\n",
       " 'senior': 427,\n",
       " 'anti': 428,\n",
       " 'funding': 429,\n",
       " 'august': 430,\n",
       " 'shows': 431,\n",
       " 'shot': 432,\n",
       " 'development': 433,\n",
       " 'singer': 434,\n",
       " 'passed': 435,\n",
       " 'punjab': 436,\n",
       " 'defence': 437,\n",
       " 'leaders': 438,\n",
       " 'military': 439,\n",
       " 'train': 440,\n",
       " 'platform': 441,\n",
       " 'sri': 442,\n",
       " 'finance': 443,\n",
       " 'news': 444,\n",
       " 'inside': 445,\n",
       " 'see': 446,\n",
       " 'put': 447,\n",
       " 'age': 448,\n",
       " 'wedding': 449,\n",
       " 'political': 450,\n",
       " 'major': 451,\n",
       " 'area': 452,\n",
       " 'late': 453,\n",
       " 'student': 454,\n",
       " 'pakistani': 455,\n",
       " 'dead': 456,\n",
       " 'recent': 457,\n",
       " 'players': 458,\n",
       " 'station': 459,\n",
       " 'feature': 460,\n",
       " 'project': 461,\n",
       " 'launch': 462,\n",
       " 'act': 463,\n",
       " 'failed': 464,\n",
       " 'yadav': 465,\n",
       " 'allegations': 466,\n",
       " 'member': 467,\n",
       " 'trying': 468,\n",
       " 'rape': 469,\n",
       " 'force': 470,\n",
       " 'dhoni': 471,\n",
       " 'suicide': 472,\n",
       " 'bollywood': 473,\n",
       " 'still': 474,\n",
       " 'ordered': 475,\n",
       " 'different': 476,\n",
       " 'towards': 477,\n",
       " 'cbi': 478,\n",
       " 'couple': 479,\n",
       " 'july': 480,\n",
       " 'game': 481,\n",
       " 'november': 482,\n",
       " 'mp': 483,\n",
       " 'expected': 484,\n",
       " 'bill': 485,\n",
       " 'getting': 486,\n",
       " 'award': 487,\n",
       " 'financial': 488,\n",
       " 'female': 489,\n",
       " 'claims': 490,\n",
       " 'lead': 491,\n",
       " 'giant': 492,\n",
       " 'complaint': 493,\n",
       " 'denied': 494,\n",
       " 'amazon': 495,\n",
       " 'birthday': 496,\n",
       " 'side': 497,\n",
       " 'wanted': 498,\n",
       " 'decided': 499,\n",
       " 'fake': 500,\n",
       " 'medical': 501,\n",
       " 'batsman': 502,\n",
       " 'agency': 503,\n",
       " 'jail': 504,\n",
       " 'allowed': 505,\n",
       " 'october': 506,\n",
       " 'stated': 507,\n",
       " 'road': 508,\n",
       " 'local': 509,\n",
       " 'plans': 510,\n",
       " 'sachin': 511,\n",
       " 'stop': 512,\n",
       " 'korean': 513,\n",
       " 'study': 514,\n",
       " 'phone': 515,\n",
       " 'paid': 516,\n",
       " 'together': 517,\n",
       " 'past': 518,\n",
       " 'campaign': 519,\n",
       " 'minutes': 520,\n",
       " 'change': 521,\n",
       " 'earth': 522,\n",
       " 'british': 523,\n",
       " 'reacting': 524,\n",
       " 'building': 525,\n",
       " 'forces': 526,\n",
       " 'calling': 527,\n",
       " 'white': 528,\n",
       " 'history': 529,\n",
       " 'rajasthan': 530,\n",
       " 'married': 531,\n",
       " 'founded': 532,\n",
       " 'workers': 533,\n",
       " 'driver': 534,\n",
       " 'jammu': 535,\n",
       " 'nadu': 536,\n",
       " 'priyanka': 537,\n",
       " 'iran': 538,\n",
       " 'vice': 539,\n",
       " 'rights': 540,\n",
       " 'mark': 541,\n",
       " 'scientists': 542,\n",
       " 'victim': 543,\n",
       " 'outside': 544,\n",
       " 'look': 545,\n",
       " 'games': 546,\n",
       " 'temple': 547,\n",
       " 'despite': 548,\n",
       " 'control': 549,\n",
       " 'musk': 550,\n",
       " 'committee': 551,\n",
       " 'railway': 552,\n",
       " 'account': 553,\n",
       " 'quarter': 554,\n",
       " 'ali': 555,\n",
       " 'saudi': 556,\n",
       " 'debut': 557,\n",
       " 'winning': 558,\n",
       " 'football': 559,\n",
       " 'nation': 560,\n",
       " 'parents': 561,\n",
       " 'till': 562,\n",
       " 'great': 563,\n",
       " 'always': 564,\n",
       " 'big': 565,\n",
       " 'gst': 566,\n",
       " 'half': 567,\n",
       " 'starrer': 568,\n",
       " 'refused': 569,\n",
       " 'coach': 570,\n",
       " 'seeking': 571,\n",
       " 'live': 572,\n",
       " 'cost': 573,\n",
       " 'madhya': 574,\n",
       " 'planning': 575,\n",
       " 'letter': 576,\n",
       " 'sharing': 577,\n",
       " 'single': 578,\n",
       " 'pictures': 579,\n",
       " 'nasa': 580,\n",
       " 'behind': 581,\n",
       " 'instead': 582,\n",
       " 'matches': 583,\n",
       " 'call': 584,\n",
       " 'nine': 585,\n",
       " 'banned': 586,\n",
       " 'haryana': 587,\n",
       " 'provide': 588,\n",
       " 'affairs': 589,\n",
       " 'fell': 590,\n",
       " 'night': 591,\n",
       " 'africa': 592,\n",
       " 'violence': 593,\n",
       " 'london': 594,\n",
       " 'filmmaker': 595,\n",
       " 'black': 596,\n",
       " 'met': 597,\n",
       " 'border': 598,\n",
       " 'mobile': 599,\n",
       " 'french': 600,\n",
       " 'fourth': 601,\n",
       " 'muslim': 602,\n",
       " 'developed': 603,\n",
       " 'tesla': 604,\n",
       " 'light': 605,\n",
       " 'leave': 606,\n",
       " 'declared': 607,\n",
       " 'career': 608,\n",
       " 'cash': 609,\n",
       " 'amount': 610,\n",
       " 'protest': 611,\n",
       " 'previous': 612,\n",
       " 'biggest': 613,\n",
       " 'bachchan': 614,\n",
       " 'gave': 615,\n",
       " 'aircraft': 616,\n",
       " 'justice': 617,\n",
       " 'murder': 618,\n",
       " 'start': 619,\n",
       " 'fund': 620,\n",
       " 'season': 621,\n",
       " 'better': 622,\n",
       " 'charges': 623,\n",
       " 'offered': 624,\n",
       " 'parliament': 625,\n",
       " 'brother': 626,\n",
       " 'turned': 627,\n",
       " 'personal': 628,\n",
       " 'probe': 629,\n",
       " 'yet': 630,\n",
       " 'loss': 631,\n",
       " 'intelligence': 632,\n",
       " 'matter': 633,\n",
       " 'harassment': 634,\n",
       " 'investors': 635,\n",
       " 'say': 636,\n",
       " 'self': 637,\n",
       " 'club': 638,\n",
       " 'lok': 639,\n",
       " 'model': 640,\n",
       " 'innings': 641,\n",
       " 'suspended': 642,\n",
       " 'staff': 643,\n",
       " 'tournament': 644,\n",
       " 'written': 645,\n",
       " 'must': 646,\n",
       " 'far': 647,\n",
       " 'tried': 648,\n",
       " 'hotel': 649,\n",
       " 'bengal': 650,\n",
       " 'land': 651,\n",
       " 'showed': 652,\n",
       " 'industry': 653,\n",
       " 'level': 654,\n",
       " 'hyderabad': 655,\n",
       " 'already': 656,\n",
       " 'let': 657,\n",
       " 'happy': 658,\n",
       " 'km': 659,\n",
       " 'stating': 660,\n",
       " 'confirmed': 661,\n",
       " 'aadhaar': 662,\n",
       " 'rukh': 663,\n",
       " 'education': 664,\n",
       " 'sale': 665,\n",
       " 'february': 666,\n",
       " 'cut': 667,\n",
       " 'admitted': 668,\n",
       " 'indians': 669,\n",
       " 'current': 670,\n",
       " 'price': 671,\n",
       " 'spokesperson': 672,\n",
       " 'opposition': 673,\n",
       " 'champions': 674,\n",
       " 'flipkart': 675,\n",
       " 'character': 676,\n",
       " 'banks': 677,\n",
       " 'customers': 678,\n",
       " 'issues': 679,\n",
       " 'nations': 680,\n",
       " 'chopra': 681,\n",
       " 'caused': 682,\n",
       " 'done': 683,\n",
       " 'vehicles': 684,\n",
       " 'return': 685,\n",
       " 'owned': 686,\n",
       " 'create': 687,\n",
       " 'baby': 688,\n",
       " 'meet': 689,\n",
       " 'driving': 690,\n",
       " 'japan': 691,\n",
       " 'shares': 692,\n",
       " 'able': 693,\n",
       " 'wearing': 694,\n",
       " 'farmers': 695,\n",
       " 'created': 696,\n",
       " 'photo': 697,\n",
       " 'gone': 698,\n",
       " 'include': 699,\n",
       " 'operations': 700,\n",
       " 'tv': 701,\n",
       " 'period': 702,\n",
       " 'fight': 703,\n",
       " 'keep': 704,\n",
       " 'policy': 705,\n",
       " 'carrying': 706,\n",
       " 'stake': 707,\n",
       " 'allow': 708,\n",
       " 'forced': 709,\n",
       " 'proposed': 710,\n",
       " 'demanded': 711,\n",
       " 'village': 712,\n",
       " 'officers': 713,\n",
       " 'afghanistan': 714,\n",
       " 'commerce': 715,\n",
       " 'appointed': 716,\n",
       " 'reach': 717,\n",
       " 'full': 718,\n",
       " 'girls': 719,\n",
       " 'vehicle': 720,\n",
       " 'hand': 721,\n",
       " 'treatment': 722,\n",
       " 'income': 723,\n",
       " 'organisation': 724,\n",
       " 'job': 725,\n",
       " 'things': 726,\n",
       " 'adityanath': 727,\n",
       " 'missing': 728,\n",
       " 'accounts': 729,\n",
       " 'term': 730,\n",
       " 'increase': 731,\n",
       " 'rbi': 732,\n",
       " 'lot': 733,\n",
       " 'trade': 734,\n",
       " 'reliance': 735,\n",
       " 'suggested': 736,\n",
       " 'economic': 737,\n",
       " 'room': 738,\n",
       " 'wickets': 739,\n",
       " 'response': 740,\n",
       " 'passenger': 741,\n",
       " 'investment': 742,\n",
       " 'process': 743,\n",
       " 'mla': 744,\n",
       " 'defeated': 745,\n",
       " 'showing': 746,\n",
       " 'sold': 747,\n",
       " 'reached': 748,\n",
       " 'oil': 749,\n",
       " 'continue': 750,\n",
       " 'warned': 751,\n",
       " 'plan': 752,\n",
       " 'attacks': 753,\n",
       " 'illegal': 754,\n",
       " 'ongoing': 755,\n",
       " 'talks': 756,\n",
       " 'broke': 757,\n",
       " 'hindu': 758,\n",
       " 'yogi': 759,\n",
       " 'region': 760,\n",
       " 'various': 761,\n",
       " 'feel': 762,\n",
       " 'less': 763,\n",
       " 'form': 764,\n",
       " 'find': 765,\n",
       " 'governor': 766,\n",
       " 'lanka': 767,\n",
       " 'score': 768,\n",
       " 'involved': 769,\n",
       " 'features': 770,\n",
       " 'sought': 771,\n",
       " 'sanjay': 772,\n",
       " 'products': 773,\n",
       " 'zealand': 774,\n",
       " 'hearing': 775,\n",
       " 'ensure': 776,\n",
       " 'airline': 777,\n",
       " 'born': 778,\n",
       " 'council': 779,\n",
       " 'rao': 780,\n",
       " 'caught': 781,\n",
       " 'cars': 782,\n",
       " 'related': 783,\n",
       " 'story': 784,\n",
       " 'bus': 785,\n",
       " 'spot': 786,\n",
       " 'marriage': 787,\n",
       " 'deepika': 788,\n",
       " 'addressing': 789,\n",
       " 'travel': 790,\n",
       " 'friend': 791,\n",
       " 'forward': 792,\n",
       " 'giving': 793,\n",
       " 'committed': 794,\n",
       " 'karan': 795,\n",
       " 'sex': 796,\n",
       " 'personnel': 797,\n",
       " 'research': 798,\n",
       " 'asking': 799,\n",
       " 'anil': 800,\n",
       " 'seats': 801,\n",
       " 'signed': 802,\n",
       " 'threatened': 803,\n",
       " 'andhra': 804,\n",
       " 'safety': 805,\n",
       " 'compared': 806,\n",
       " 'terror': 807,\n",
       " 'community': 808,\n",
       " 'friends': 809,\n",
       " 'title': 810,\n",
       " 'electric': 811,\n",
       " 'jaitley': 812,\n",
       " 'doctors': 813,\n",
       " 'corporation': 814,\n",
       " 'college': 815,\n",
       " 'built': 816,\n",
       " 'date': 817,\n",
       " 'looking': 818,\n",
       " 'whose': 819,\n",
       " 'saw': 820,\n",
       " 'rohit': 821,\n",
       " 'legal': 822,\n",
       " 'red': 823,\n",
       " 'line': 824,\n",
       " 'viral': 825,\n",
       " 'future': 826,\n",
       " 'deputy': 827,\n",
       " 'revenue': 828,\n",
       " 'york': 829,\n",
       " 'kg': 830,\n",
       " 'offer': 831,\n",
       " 'fans': 832,\n",
       " 'protests': 833,\n",
       " 'ended': 834,\n",
       " 'notice': 835,\n",
       " 'value': 836,\n",
       " 'bcci': 837,\n",
       " 'vijay': 838,\n",
       " 'almost': 839,\n",
       " 'hour': 840,\n",
       " 'schools': 841,\n",
       " 'television': 842,\n",
       " 'someone': 843,\n",
       " 'bangladesh': 844,\n",
       " 'website': 845,\n",
       " 'discovered': 846,\n",
       " 'conducted': 847,\n",
       " 'net': 848,\n",
       " 'access': 849,\n",
       " 'removed': 850,\n",
       " 'airlines': 851,\n",
       " 'corruption': 852,\n",
       " 'helped': 853,\n",
       " 'internet': 854,\n",
       " 'increased': 855,\n",
       " 'ceremony': 856,\n",
       " 'tendulkar': 857,\n",
       " 'really': 858,\n",
       " 'small': 859,\n",
       " 'kejriwal': 860,\n",
       " 'actors': 861,\n",
       " 'aged': 862,\n",
       " 'ranveer': 863,\n",
       " 'traffic': 864,\n",
       " 'management': 865,\n",
       " 'strike': 866,\n",
       " 'pacer': 867,\n",
       " 'hai': 868,\n",
       " 'weeks': 869,\n",
       " 'stars': 870,\n",
       " 'al': 871,\n",
       " 'points': 872,\n",
       " 'ambani': 873,\n",
       " 'citizens': 874,\n",
       " 'similar': 875,\n",
       " 'dismissed': 876,\n",
       " 'asian': 877,\n",
       " 'english': 878,\n",
       " 'administration': 879,\n",
       " 'birth': 880,\n",
       " 'festival': 881,\n",
       " 'shooting': 882,\n",
       " 'suffered': 883,\n",
       " 'opened': 884,\n",
       " 'digital': 885,\n",
       " 'victims': 886,\n",
       " 'ms': 887,\n",
       " 'aimed': 888,\n",
       " 'germany': 889,\n",
       " 'militants': 890,\n",
       " 'front': 891,\n",
       " 'agreed': 892,\n",
       " 'parties': 893,\n",
       " 'buy': 894,\n",
       " 'akshay': 895,\n",
       " 'victory': 896,\n",
       " 'rejected': 897,\n",
       " 'whether': 898,\n",
       " 'delivery': 899,\n",
       " 'music': 900,\n",
       " 'medal': 901,\n",
       " 'german': 902,\n",
       " 'wants': 903,\n",
       " 'available': 904,\n",
       " 'close': 905,\n",
       " 'position': 906,\n",
       " 'judge': 907,\n",
       " 'affected': 908,\n",
       " 'began': 909,\n",
       " 'trophy': 910,\n",
       " 'kolkata': 911,\n",
       " 'approved': 912,\n",
       " 'injuries': 913,\n",
       " 'soon': 914,\n",
       " 'accident': 915,\n",
       " 'killing': 916,\n",
       " 'chennai': 917,\n",
       " 'kapil': 918,\n",
       " 'areas': 919,\n",
       " 'jobs': 920,\n",
       " 'low': 921,\n",
       " 'islamic': 922,\n",
       " 'tests': 923,\n",
       " 'joined': 924,\n",
       " 'association': 925,\n",
       " 'ground': 926,\n",
       " 'rate': 927,\n",
       " 'fashion': 928,\n",
       " 'whatsapp': 929,\n",
       " 'annual': 930,\n",
       " 'worked': 931,\n",
       " 'growth': 932,\n",
       " 'site': 933,\n",
       " 'spinner': 934,\n",
       " 'kim': 935,\n",
       " 'charge': 936,\n",
       " 'elon': 937,\n",
       " 'arrest': 938,\n",
       " 'sena': 939,\n",
       " 'imposed': 940,\n",
       " 'scheme': 941,\n",
       " 'search': 942,\n",
       " 'tata': 943,\n",
       " 'claim': 944,\n",
       " 'followed': 945,\n",
       " 'something': 946,\n",
       " 'included': 947,\n",
       " 'interview': 948,\n",
       " 'kangana': 949,\n",
       " 'owner': 950,\n",
       " 'urged': 951,\n",
       " 'early': 952,\n",
       " 'production': 953,\n",
       " 'emergency': 954,\n",
       " 'message': 955,\n",
       " 'leading': 956,\n",
       " 'fine': 957,\n",
       " 'amit': 958,\n",
       " 'fast': 959,\n",
       " 'asia': 960,\n",
       " 'anyone': 961,\n",
       " 'de': 962,\n",
       " 'brought': 963,\n",
       " 'cover': 964,\n",
       " 'charged': 965,\n",
       " 'goal': 966,\n",
       " 'wrong': 967,\n",
       " 'rules': 968,\n",
       " 'happened': 969,\n",
       " 'image': 970,\n",
       " 'plane': 971,\n",
       " 'prasad': 972,\n",
       " 'france': 973,\n",
       " 'metro': 974,\n",
       " 'joint': 975,\n",
       " 'funds': 976,\n",
       " 'connection': 977,\n",
       " 'energy': 978,\n",
       " 'grand': 979,\n",
       " 'surfaced': 980,\n",
       " 'executive': 981,\n",
       " 'cause': 982,\n",
       " 'sanctions': 983,\n",
       " 'details': 984,\n",
       " 'thought': 985,\n",
       " 'book': 986,\n",
       " 'served': 987,\n",
       " 'century': 988,\n",
       " 'brand': 989,\n",
       " 'prices': 990,\n",
       " 'champion': 991,\n",
       " 'payments': 992,\n",
       " 'programme': 993,\n",
       " 'fifa': 994,\n",
       " 'attempt': 995,\n",
       " 'terrorists': 996,\n",
       " 'featured': 997,\n",
       " 'aap': 998,\n",
       " 'facing': 999,\n",
       " 'lives': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b305d6",
   "metadata": {},
   "source": [
    "- dictionary 형태로 저장되어있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5a3b288f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said', 1), ('india', 2), ('year', 3), ('added', 4)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(src_tokenizer.word_index.items())[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d80278",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "💡\n",
    "`src_tokenizer.word_counts.items()`\n",
    "- **단어와 각 단어의 등장 빈도수**가 저장되어있다.\n",
    "\n",
    "---\n",
    "\n",
    "- **빈도수가 낮은 단어는 훈련 데이터에서 제외**하고 진행\n",
    "    - 등장 빈도가 낮은 단어는 자연어 처리에서 의미를 가지지 않을 가능성이 높기 때문\n",
    "- **등장 빈도수를 threshold**로 지정하고 해당 값 미만인 단어가 차지하는 비중 확인\n",
    "- threshold를 4\\~8로 설정하고 비중을 비교해본다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ec482fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 4\n",
      "단어 집합(vocabulary)의 크기(총 개수) : 69702\n",
      "등장 빈도가 3번 이하인 희귀 단어의 수: 40031\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 29671\n",
      "단어 집합에서 희귀 단어의 비율: 57.4316375426817\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 2.1801242640781817\n",
      "\n",
      "==============================\n",
      "\n",
      "Threshold: 5\n",
      "단어 집합(vocabulary)의 크기(총 개수) : 69702\n",
      "등장 빈도가 4번 이하인 희귀 단어의 수: 43366\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 26336\n",
      "단어 집합에서 희귀 단어의 비율: 62.21629221543141\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 2.6630757857375076\n",
      "\n",
      "==============================\n",
      "\n",
      "Threshold: 6\n",
      "단어 집합(vocabulary)의 크기(총 개수) : 69702\n",
      "등장 빈도가 5번 이하인 희귀 단어의 수: 45713\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 23989\n",
      "단어 집합에서 희귀 단어의 비율: 65.58348397463487\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.087921071095243\n",
      "\n",
      "==============================\n",
      "\n",
      "Threshold: 7\n",
      "단어 집합(vocabulary)의 크기(총 개수) : 69702\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 47505\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 22197\n",
      "단어 집합에서 희귀 단어의 비율: 68.1544288542653\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.47717854942216\n",
      "\n",
      "==============================\n",
      "\n",
      "Threshold: 8\n",
      "단어 집합(vocabulary)의 크기(총 개수) : 69702\n",
      "등장 빈도가 7번 이하인 희귀 단어의 수: 49008\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 20694\n",
      "단어 집합에서 희귀 단어의 비율: 70.31075148489283\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.858073074113147\n",
      "\n",
      "==============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# threshold 4~8까지 비교\n",
    "thresholds = [4, 5, 6, 7, 8]\n",
    "\n",
    "for threshold in thresholds:\n",
    "    total_cnt = len(src_tokenizer.word_index) # 전체 단어의 수\n",
    "    rare_cnt = 0     # 등장 빈도수가 threshold보다 작은 단어 카운트\n",
    "    total_freq = 0   # 훈련 데이터의 전체 단어 빈도수의 총 합\n",
    "    rare_freq = 0    # 등장 빈도수가 threshold보다 작은 단어 빈도수의 총 합\n",
    "\n",
    "    # 단어, 빈도수 pair를 key, value로\n",
    "    for key, value in src_tokenizer.word_counts.items():\n",
    "        total_freq += value\n",
    "\n",
    "        # 단어 등장 빈도수가 threshold보다 작으면\n",
    "        if (value < threshold):\n",
    "            rare_cnt += 1\n",
    "            rare_freq += value\n",
    "\n",
    "    print('Threshold:', threshold)\n",
    "    print('단어 집합(vocabulary)의 크기(총 개수) :', total_cnt)\n",
    "    print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "    print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "    print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "    print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)\n",
    "    print(\"\\n\" + \"=\"*30 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376d5762",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**결과 분석** (GPT참고)\n",
    "1. Vocabulary size:\n",
    "     - threshold가 낮으면 vocabulary 사이즈가 커지고\n",
    "     - threshold가 높으면 vocabulary 사이즈가 작아진다\n",
    "2. Rare word exclusion:\n",
    "    - 일반적인 단어가 포함된 간결한 어휘를 뽑아내고 싶으면 높은 threshold값을 사용한다\n",
    "3. Rare word ratio:\n",
    "    - trade-off 관계다.\n",
    "    - 다양한 단어를 사용할지, 빈도수가 낮은 단어를 제외할지\n",
    "4. Frequency ratio:\n",
    "    - 비율이 낮을수록 희귀단어가 전체 빈도수에 미치는 영향이 적다\n",
    "    \n",
    "- 최대한 희귀단어를 많이 제외시켜서 간결한 어휘를 사용해보고 싶으면 `threshold 8`을 선택하는게 좋을것 같고\n",
    "- 어휘크기, 희귀단어 제외 사이의 적당한 균형을 이루고싶다면 `threshold 5`를 선택하는게 좋을것같다\n",
    "\n",
    "👉 **threshold 5**를 사용하기로 결정!\n",
    "\n",
    "---\n",
    "\n",
    "- **등장 빈도가 5이하**인 단어는 정수 인코딩 과정에서 제외, 훈련데이터에서 제거\n",
    "- 단어 집합의 크기는 어림잡아 26000으로 제한\n",
    "- Tokenizer를 정의할때 `num_words`값을 정하면 단어 집합의 크기를 제한할수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "994ebefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69702\n"
     ]
    }
   ],
   "source": [
    "# vocabulary size 지정해서 다시 토크나의저 정의\n",
    "src_vocab = 26000 # vocabulary size \n",
    "src_tokenizer = Tokenizer(num_words=src_vocab) # size limit 26000\n",
    "src_tokenizer.fit_on_texts(encoder_input_train)\n",
    "print(len(src_tokenizer.word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77902c95",
   "metadata": {},
   "source": [
    "- 이 단계에서는 단어 집합 크기 제한이 적용되는게 아닌가보다.. 일단 넘어간다\n",
    "\n",
    "\n",
    "- `texts_to_sequences()`는 생성된 단어 집합에 기반해서 입력으로 주어진 텍스트 데이터 단어를 정수로 변환(정수 인코딩)을 진행\n",
    "- 현재 단어 집합의 크기를 8000으로 제한했기 때문에 26000이 넘는 숫자는 정수 인코딩 이후에 데이터에 존재하지 않는다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "75e46e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5, 1400, 1773, 1051, 137, 2240, 916, 11, 2291, 10743, 16032, 2506, 1027, 8820, 175, 2001, 666, 29, 3, 1773, 6, 1051, 196, 2240, 2054, 618, 12, 219, 1302, 5138, 117, 39, 882, 16032], [206, 63, 3841, 3991, 4236, 8, 212, 841, 239, 160, 58, 2407, 4692, 81, 21, 63, 3841, 3991, 2626, 3266, 2626, 8, 841, 63, 3991, 630, 3392, 105, 2626, 3266, 2626, 841, 212, 21, 17, 1588], [15416, 4390, 576, 27, 5, 16, 3123, 1942, 282, 6733, 125, 41, 81, 1942, 282, 85, 3344, 3377, 41, 576, 2893, 41, 11007, 118, 244, 1032, 22198, 1839, 1286, 260, 10, 1942, 2408, 41, 1429, 2214, 2231, 7798]]\n"
     ]
    }
   ],
   "source": [
    "# text sequence -> integer sequence\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train)\n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "# check\n",
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3edade",
   "metadata": {},
   "source": [
    "### headlines data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7aab52b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make vocabulary of headlines data \n",
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5d05c6",
   "metadata": {},
   "source": [
    "- headlines data는 decoder input train 데이터로 맞춘 토크나이저를 만들어서 사용한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "54d75764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 4\n",
      "단어 집합(vocabulary)의 크기(총 개수) : 30140\n",
      "등장 빈도가 3번 이하인 희귀 단어의 수: 16990\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 13150\n",
      "단어 집합에서 희귀 단어의 비율: 56.37027206370272\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.1587571269758428\n",
      "\n",
      "==============================\n",
      "\n",
      "Threshold: 5\n",
      "단어 집합(vocabulary)의 크기(총 개수) : 30140\n",
      "등장 빈도가 4번 이하인 희귀 단어의 수: 18566\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 11574\n",
      "단어 집합에서 희귀 단어의 비율: 61.59920371599203\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.9365706861514886\n",
      "\n",
      "==============================\n",
      "\n",
      "Threshold: 6\n",
      "단어 집합(vocabulary)의 크기(총 개수) : 30140\n",
      "등장 빈도가 5번 이하인 희귀 단어의 수: 19731\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 10409\n",
      "단어 집합에서 희귀 단어의 비율: 65.46449900464499\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 4.655283246779366\n",
      "\n",
      "==============================\n",
      "\n",
      "Threshold: 7\n",
      "단어 집합(vocabulary)의 크기(총 개수) : 30140\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 20624\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 9516\n",
      "단어 집합에서 희귀 단어의 비율: 68.42733908427338\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 5.316375418426433\n",
      "\n",
      "==============================\n",
      "\n",
      "Threshold: 8\n",
      "단어 집합(vocabulary)의 크기(총 개수) : 30140\n",
      "등장 빈도가 7번 이하인 희귀 단어의 수: 21351\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 8789\n",
      "단어 집합에서 희귀 단어의 비율: 70.83941605839415\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 5.944277258947508\n",
      "\n",
      "==============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# threshold 4~8까지 비교\n",
    "thresholds = [4, 5, 6, 7, 8]\n",
    "\n",
    "for threshold in thresholds:\n",
    "    total_cnt = len(tar_tokenizer.word_index) # 전체 단어의 수\n",
    "    rare_cnt = 0     # 등장빈도수 < threshold 단어 개수 카운트\n",
    "    total_freq = 0   # 훈련 데이터의 전체 단어 빈도수의 총 합\n",
    "    rare_freq = 0    # 등장빈도수 < threshold 단어 등장 빈도수 총 합\n",
    "\n",
    "    # 단어, 빈도수 pair를 key, value로\n",
    "    for key, value in tar_tokenizer.word_counts.items():\n",
    "        total_freq += value\n",
    "\n",
    "        # 단어 등장 빈도수가 threshold보다 작으면\n",
    "        if (value < threshold):\n",
    "            rare_cnt += 1\n",
    "            rare_freq += value\n",
    "\n",
    "    print('Threshold:', threshold)\n",
    "    print('단어 집합(vocabulary)의 크기(총 개수) :', total_cnt)\n",
    "    print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "    print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "    print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "    print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)\n",
    "    print(\"\\n\" + \"=\"*30 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e97cb8",
   "metadata": {},
   "source": [
    "- headlines 데이터는 희귀단어를 최대한 많이 포함해서 진행해본다.\n",
    "\n",
    "👉 threshold 4를 사용하기로 결정!\n",
    "\n",
    "- 등장 빈도가 4이하인 단어는 정수 인코딩 과정에서 제외, 훈련데이터에서 제거\n",
    "- 단어 집합의 크기는 어림잡아 13000으로 제한\n",
    "- Tokenizer를 정의할때 num_words값을 정해서 단어 집합의 크기를 제한"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "622be8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "input  [[1, 13, 1010, 2439, 41, 2047, 29, 4395, 1545, 3, 180], [1, 68, 4849, 7251, 4262, 4, 25, 24, 209, 548], [1, 1165, 6480, 890, 3, 30, 2906], [1, 33, 288, 11576, 76, 48, 2087, 16, 48], [1, 1235, 165, 275, 10411, 429, 12, 2394, 51, 3897]]\n",
      "target\n",
      "decoder  [[13, 1010, 2439, 41, 2047, 29, 4395, 1545, 3, 180, 2], [68, 4849, 7251, 4262, 4, 25, 24, 209, 548, 2], [1165, 6480, 890, 3, 30, 2906, 2], [33, 288, 11576, 76, 48, 2087, 16, 48, 2], [1235, 165, 275, 10411, 429, 12, 2394, 51, 3897, 2]]\n"
     ]
    }
   ],
   "source": [
    "# vocabulary size 지정해서 다시 토크나의저 정의\n",
    "tar_vocab = 13000 # vocabulary size\n",
    "tar_tokenizer = Tokenizer(num_words=tar_vocab)  # size limit 13000\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# text sequence -> integer sequence\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "# 잘 변환되었는지 확인\n",
    "print('input')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target')\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b143e092",
   "metadata": {},
   "source": [
    "## 2) 추가 작업 - empty sample 삭제\n",
    "- 전체 데이터에서 빈도수가 낮은 단어는 삭제 되었다 => **empty sample**로 바뀌었다\n",
    "- headlines는 평균 길이가 9였기때문에 이런 샘플이 더 많을수 있다\n",
    "\n",
    "\n",
    "1. headlines에서 길이가 0이 된 샘플 인덱스를 추출하고\n",
    "    - `decoder_input` 에는 `sostoken`, `decoder_target`에는 `eostoken`가 모두 추가된 상황\n",
    "    - 모든 샘플에서 등장하기때문에 단어집합 제한이 있어도 삭제되지 않음\n",
    "    - 길이가 0이 된 summary의 실제 길이는 위의 단어만 남아있어서 `1`로 나올것!  \n",
    "2. train, test 데이터에서 summary 길이가 1인 경우 인덱스를 각각 `drop_train`과 `drop_test` 변수에 저장\n",
    "3. 이 인덱스의 column 샘플을 모두 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "96b842b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 0\n",
      "삭제할 테스트 데이터의 개수 : 0\n"
     ]
    }
   ],
   "source": [
    "# train, test 데이터에서 headlines 길이가 1인 인덱스 추출 - 'sostoken', 'eostoken'만 남아있는 상태\n",
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :', len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :', len(drop_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436b97e0",
   "metadata": {},
   "source": [
    "- 오! 삭제할 데이터가 없다! \n",
    "    - *왜 이렇게 되었는지 이해되지않지만 일단 pass*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "614108d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 78688\n",
      "훈련 레이블의 개수 : 78688\n",
      "테스트 데이터의 개수 : 19672\n",
      "테스트 레이블의 개수 : 19672\n"
     ]
    }
   ],
   "source": [
    "# 전체 데이터수 확인\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbd6e64",
   "metadata": {},
   "source": [
    "# Step 5. 패딩추가\n",
    "- 서로 다른 길이의 샘플을 병렬처리하기 위해 같은 길이로 맞춰야함\n",
    "    - 최대 길이보다 짧은 데이터엔 뒤에 숫자 0이 추가되어 길이가 맞춰짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "27ec1d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 15)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max length 확인\n",
    "text_max_len, headlines_max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "131daae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen=headlines_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen=headlines_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen=headlines_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen=headlines_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "612c3fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    5,  1400,  1773, ...,     0,     0,     0],\n",
       "       [  206,    63,  3841, ...,     0,     0,     0],\n",
       "       [15416,  4390,   576, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  523,    65,   184, ...,     0,     0,     0],\n",
       "       [  443,   225,    68, ...,     0,     0,     0],\n",
       "       [    5,    16,   125, ...,     0,     0,     0]], dtype=int32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# padding check\n",
    "encoder_input_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9062e560",
   "metadata": {},
   "source": [
    "# Step 6. index2word data\n",
    "- 테스트 단계에서 정수 인덱스 텍스트 데이터를 실제 데이터로 복원해야한다\n",
    "- 필요한 3개의 사전을 미리 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2ed4161f",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_index_to_word = src_tokenizer.index_word # text dataset : int -> word\n",
    "tar_word_to_index = tar_tokenizer.word_index # headlines dataset : word -> int\n",
    "tar_index_to_word = tar_tokenizer.index_word # headlines dataset : int -> word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ebaf68",
   "metadata": {},
   "source": [
    "- 잘 변환되었는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6f870b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sostoken', 1), ('eostoken', 2), ('to', 3)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tar_word_to_index.items())[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bb2ddf8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'sostoken'), (2, 'eostoken'), (3, 'to')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tar_index_to_word.items())[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5ed63655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'said'), (2, 'india'), (3, 'year')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(src_index_to_word.items())[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af056ebf",
   "metadata": {},
   "source": [
    "# Step 7. 모델 설계\n",
    "- functional API 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b842a5e7",
   "metadata": {},
   "source": [
    "## 1) Encoder\n",
    "\n",
    "**recurrent dropout**\n",
    "- layer가 아닌 time step마다 dropout을 적용하는 방식\n",
    "- time step의 입력을 랜덤으로 생성\n",
    "- 효과 : regularization, overfitting 방지\n",
    "\n",
    "<a href='https://arxiv.org/pdf/1512.05287.pdf'><img src='./img/recurrent_dropout.png' width=70% height=70%></a>\n",
    "\n",
    "    - left: only dropout / right: dropout + recurrent dropout(Variational Dropout)\n",
    "    - colored arrow : dropout\n",
    "    \n",
    "> 참고 - recurrent dropout을 사용하면 경고문이 뜬다<br>\n",
    "> ```WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU```\n",
    "=> recurrent dropout을 사용하면 cuDNNㅇ르 사용할수 없어서 학습시간이 더 오래걸림\n",
    "\n",
    "- [recurrent dropout 논문](https://arxiv.org/pdf/1603.05118v2.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "80e19b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "embedding_dim = 128 # vector dimension\n",
    "hidden_size = 256   # LSTM의 capacity에 해당(뉴런의 개수) - 크다고 항상 좋은건 아님\n",
    "\n",
    "# encoder\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# encoder - embedding layer\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# encoder - LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n",
    "# encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# encoder - LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# encoder - LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n",
    "encoder_output, state_h, state_c = encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f5e71a",
   "metadata": {},
   "source": [
    "- 모델 훈련 내용을 보고 시간이 되면 recurrent dropout도 시도해보기위해 코드를 남겨둔다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0400ab53",
   "metadata": {},
   "source": [
    "## 2) Decoder\n",
    "- LSTM의 입력에서 `initial_state`인자값으로 encoder의 `hidden state`, `cell state`를 넣어야함\n",
    "\n",
    "## 2-1) decoder input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5ba19ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# decoder - embedding layer\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# decoder - LSTM\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n",
    "# decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb69573d",
   "metadata": {},
   "source": [
    "## 2-2) decoder output layer\n",
    "- headlines 단어장 `tar_vocab`에서 하나의 단어를 선택하는 다중클래스 분류 작업을 하게된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a1c406ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 45)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 45, 128)      3328000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 45, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 45, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    1664000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 45, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 13000)  3341000     lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 10,172,104\n",
      "Trainable params: 10,172,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# decoder output layer\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "\n",
    "# define model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae1599d",
   "metadata": {},
   "source": [
    "- 여기까지가 인코더의 hidden_state와 cell state를 디코더의 initial state로 사용하는 가장 기본적인 seq2seq!\n",
    "- decoder의 output layer를 살짝 바꿔서 성능을 높일수 있는 방법이 `Attention` mechanism!\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "✔️ *이 부분에서 어텐션 메터니즘을 구축하는 걸 빠뜨리고 모델트레이닝을 진행했다..:) 아래에서 다시 어텐션구조를 추가한 모델학습을 진행한다*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62819b7d",
   "metadata": {},
   "source": [
    "# Step 8. Training model\n",
    "\n",
    "---\n",
    "\n",
    "💡\n",
    "## Evaluate metrics for Text summarization\n",
    "\n",
    "**ROUGE (Recall-Oriented Understudy for Gisting Evaluation)**\n",
    "- label(사람이 만든 요약문)과 summary(모델이 생성한 inference)을 비교해서 성능 계산\n",
    "- ROUGE-N, ROUGE-L, ROUGE-W, ROUGE-S 등 다양한 지표가 있음\n",
    "- 각각 지표별로 recall 및 precision을 둘 다 구하는 것이 도움이 됨(기반하여 F1 score로 측정 가능)\n",
    "\n",
    "**BLEU (Bilingual Evaluation Understudy)**\n",
    "- Measures the precision of n-grams (usually up to 4-grams) in the generated summary compared to the reference summary\n",
    "\n",
    "\n",
    "\n",
    "👉 `ROUGE metric`은 [라이브러리](https://github.com/pltrdy/rouge)로 사용할수 있어서 학습 이후에 이 방법을 이용해서 확인해봐야겠다.\n",
    "\n",
    "\n",
    "**[참고]** \n",
    "- [blog](https://arc.net/l/quote/egjdfsto)\n",
    "- [blog](https://medium.com/nlplanet/two-minutes-nlp-learn-the-rouge-metric-by-examples-f179cc285499)\n",
    "- [ROUGE: A Package for Automatic Evaluation of Summaries](https://aclanthology.org/W04-1013.pdf)\n",
    "- [github](https://github.com/pltrdy/rouge)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3a9f4eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from rouge) (1.16.0)\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-1.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# # install rough libarary\n",
    "# !pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dbd392e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROUGE library\n",
    "from rouge import Rouge\n",
    "\n",
    "# make rouge instance\n",
    "rouge = Rouge()\n",
    "\n",
    "# # check the scores - 혹시 모델에 바로 사용이 안되면 아래에서 이런 방식으로 스코어를 확인\n",
    "# rouge.get_scores(model_out, reference, avg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3f74b62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:835 run_step  **\n        outputs = model.train_step(data)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:792 train_step\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/compile_utils.py:436 update_state\n        self.build(y_pred, y_true)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/compile_utils.py:358 build\n        self._metrics = tf.__internal__.nest.map_structure_up_to(y_pred, self._get_metric_objects,\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py:1376 map_structure_up_to\n        return map_structure_with_tuple_paths_up_to(\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py:1474 map_structure_with_tuple_paths_up_to\n        results = [\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py:1475 <listcomp>\n        func(*args, **kwargs) for args in zip(flat_path_gen, *flat_value_gen)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py:1378 <lambda>\n        lambda _, *values: func(*values),  # Discards the path arg.\n    /opt/conda/lib/python3.9/site-packages/keras/engine/compile_utils.py:482 _get_metric_objects\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    /opt/conda/lib/python3.9/site-packages/keras/engine/compile_utils.py:482 <listcomp>\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    /opt/conda/lib/python3.9/site-packages/keras/engine/compile_utils.py:501 _get_metric_object\n        metric_obj = metrics_mod.get(metric)\n    /opt/conda/lib/python3.9/site-packages/keras/metrics.py:3717 get\n        raise ValueError(\n\n    ValueError: Could not interpret metric function identifier: <rouge.rouge.Rouge object at 0x7f96942d5d30>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_113/4055766550.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# gpu로 모델학습\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/GPU:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train,\n\u001b[0m\u001b[1;32m     19\u001b[0m                        \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder_input_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_target_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                         batch_size=256, callbacks=[es, checkpoint], epochs=50)\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 759\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    760\u001b[0m             *args, **kwds))\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3298\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:835 run_step  **\n        outputs = model.train_step(data)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:792 train_step\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/compile_utils.py:436 update_state\n        self.build(y_pred, y_true)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/compile_utils.py:358 build\n        self._metrics = tf.__internal__.nest.map_structure_up_to(y_pred, self._get_metric_objects,\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py:1376 map_structure_up_to\n        return map_structure_with_tuple_paths_up_to(\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py:1474 map_structure_with_tuple_paths_up_to\n        results = [\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py:1475 <listcomp>\n        func(*args, **kwargs) for args in zip(flat_path_gen, *flat_value_gen)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py:1378 <lambda>\n        lambda _, *values: func(*values),  # Discards the path arg.\n    /opt/conda/lib/python3.9/site-packages/keras/engine/compile_utils.py:482 _get_metric_objects\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    /opt/conda/lib/python3.9/site-packages/keras/engine/compile_utils.py:482 <listcomp>\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    /opt/conda/lib/python3.9/site-packages/keras/engine/compile_utils.py:501 _get_metric_object\n        metric_obj = metrics_mod.get(metric)\n    /opt/conda/lib/python3.9/site-packages/keras/metrics.py:3717 get\n        raise ValueError(\n\n    ValueError: Could not interpret metric function identifier: <rouge.rouge.Rouge object at 0x7f96942d5d30>\n"
     ]
    }
   ],
   "source": [
    "# compile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=[rouge])\n",
    "\n",
    "# early stop setting\n",
    "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "\n",
    "# checkpoint setting\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "checkpoint_filepath = 'abstract_summma_model.keras'\n",
    "checkpoint = ModelCheckpoint(filepath=checkpoint_filepath, \n",
    "                             save_best_only=True, # Save only the best model\n",
    "                             monitor='val_loss')  # Monitor validation loss\n",
    "\n",
    "# gpu로 모델학습\n",
    "with tf.device('/GPU:0'):\n",
    "    history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train,\n",
    "                       validation_data=([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "                        batch_size=256, callbacks=[es, checkpoint], epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f4fa55",
   "metadata": {},
   "source": [
    "- 에러를 해석하기 어렵다. 훈련 이후에 스코어를 확인해본다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "abc497d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "308/308 [==============================] - 61s 90ms/step - loss: 5.0482 - val_loss: 4.5299\n",
      "Epoch 2/50\n",
      "308/308 [==============================] - 27s 88ms/step - loss: 4.5057 - val_loss: 4.3862\n",
      "Epoch 3/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 4.3641 - val_loss: 4.2483\n",
      "Epoch 4/50\n",
      "308/308 [==============================] - 27s 88ms/step - loss: 4.1945 - val_loss: 4.0893\n",
      "Epoch 5/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 4.0358 - val_loss: 3.9705\n",
      "Epoch 6/50\n",
      "308/308 [==============================] - 27s 88ms/step - loss: 3.8881 - val_loss: 3.8349\n",
      "Epoch 7/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 3.7359 - val_loss: 3.7241\n",
      "Epoch 8/50\n",
      "308/308 [==============================] - 27s 88ms/step - loss: 3.6023 - val_loss: 3.6233\n",
      "Epoch 9/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 3.4814 - val_loss: 3.5366\n",
      "Epoch 10/50\n",
      "308/308 [==============================] - 27s 88ms/step - loss: 3.3712 - val_loss: 3.4651\n",
      "Epoch 11/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 3.2709 - val_loss: 3.4090\n",
      "Epoch 12/50\n",
      "308/308 [==============================] - 27s 88ms/step - loss: 3.1800 - val_loss: 3.3524\n",
      "Epoch 13/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 3.0968 - val_loss: 3.3122\n",
      "Epoch 14/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 3.0195 - val_loss: 3.2715\n",
      "Epoch 15/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 2.9482 - val_loss: 3.2372\n",
      "Epoch 16/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 2.8816 - val_loss: 3.2074\n",
      "Epoch 17/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 2.8184 - val_loss: 3.1823\n",
      "Epoch 18/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 2.7582 - val_loss: 3.1602\n",
      "Epoch 19/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 2.7013 - val_loss: 3.1406\n",
      "Epoch 20/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 2.6487 - val_loss: 3.1270\n",
      "Epoch 21/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 2.5985 - val_loss: 3.1131\n",
      "Epoch 22/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 2.5509 - val_loss: 3.1010\n",
      "Epoch 23/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 2.5048 - val_loss: 3.0915\n",
      "Epoch 24/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 2.4611 - val_loss: 3.0815\n",
      "Epoch 25/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 2.4188 - val_loss: 3.0779\n",
      "Epoch 26/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 2.3790 - val_loss: 3.0749\n",
      "Epoch 27/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 2.3413 - val_loss: 3.0678\n",
      "Epoch 28/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 2.3039 - val_loss: 3.0663\n",
      "Epoch 29/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 2.2704 - val_loss: 3.0635\n",
      "Epoch 30/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 2.2347 - val_loss: 3.0648\n",
      "Epoch 31/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 2.2035 - val_loss: 3.0661\n",
      "Epoch 00031: early stopping\n"
     ]
    }
   ],
   "source": [
    "# compile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy')\n",
    "\n",
    "# early stop setting\n",
    "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "\n",
    "# checkpoint setting\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "checkpoint_filepath = 'abstract_summma_model.keras'\n",
    "checkpoint = ModelCheckpoint(filepath=checkpoint_filepath, \n",
    "                             save_best_only=True, # Save only the best model\n",
    "                             monitor='val_loss')  # Monitor validation loss\n",
    "\n",
    "# gpu로 모델학습\n",
    "with tf.device('/GPU:0'):\n",
    "    history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train,\n",
    "                       validation_data=([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "                        batch_size=256, callbacks=[es, checkpoint], epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ddf58a",
   "metadata": {},
   "source": [
    "# Step 9. Visualize training result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "26a8dff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label = 'test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7575a9d3",
   "metadata": {},
   "source": [
    "- 테스트 손실값은 15에폭 부터는 거의 줄어들지않는다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98c8659",
   "metadata": {},
   "source": [
    "## 3) Attention mechanism\n",
    "- 새로운 layer을 설계\n",
    "- keras `AdditiveAttention` 사용\n",
    "- Bahdanau-style attention 이라고 부르기도 한다<br>\n",
    "[tensorflow doc](https://www.tensorflow.org/api_docs/python/tf/keras/layers/AdditiveAttention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a3312b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 45)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 45, 128)      3328000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 45, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 45, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    1664000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 45, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AdditiveAttent (None, None, 256)    256         lstm_3[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 512)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 13000)  6669000     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 13,500,360\n",
      "Trainable params: 13,500,360\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import AdditiveAttention\n",
    "\n",
    "# attention layer\n",
    "attn_layer = AdditiveAttention(name='attention_layer')\n",
    "\n",
    "# encoder & decoder's all hidden state of time steps -> attention layer\n",
    "attn_out = attn_layer([decoder_outputs, encoder_output])\n",
    "\n",
    "# connect attention output with decoder's hidden state\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out]) # 데이터의 가장 뒷차원에 붙인다\n",
    "\n",
    "# decoder output layer\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# define model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e069e7a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "💡\n",
    "**`Concatenate(axis=-1)`**\n",
    "- 뒤에서부터 인덱싱하는 방식과 동일하다\n",
    "- 만약 3차원이라면 2차원축 뒤에 붙이고, 만약 2차원이라면 1차원 축 뒤에 붙인다<br>\n",
    "[blog](https://supermemi.tistory.com/entry/Tensorflow-2-tfconcat-axis-1-0-1-2)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da9510b",
   "metadata": {},
   "source": [
    "- 아래 인퍼런스 모델을 구현하는 부분에서 어텐션 메커니즘을 만드는 부분을 빠뜨리고 모델학습을 진행한것을 확인했다!!!\n",
    "- 어텐션메커니즘을 포함시킨 모델로 다시 학습진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4500951a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "308/308 [==============================] - 44s 125ms/step - loss: 4.0229 - val_loss: 3.3382\n",
      "Epoch 2/50\n",
      "308/308 [==============================] - 38s 125ms/step - loss: 3.0377 - val_loss: 3.0849\n",
      "Epoch 3/50\n",
      "308/308 [==============================] - 38s 123ms/step - loss: 2.7410 - val_loss: 2.9856\n",
      "Epoch 4/50\n",
      "308/308 [==============================] - 38s 124ms/step - loss: 2.5587 - val_loss: 2.9372\n",
      "Epoch 5/50\n",
      "308/308 [==============================] - 38s 123ms/step - loss: 2.4247 - val_loss: 2.9098\n",
      "Epoch 6/50\n",
      "308/308 [==============================] - 38s 124ms/step - loss: 2.3183 - val_loss: 2.9000\n",
      "Epoch 7/50\n",
      "308/308 [==============================] - 38s 124ms/step - loss: 2.2277 - val_loss: 2.8926\n",
      "Epoch 8/50\n",
      "308/308 [==============================] - 38s 124ms/step - loss: 2.1480 - val_loss: 2.8892\n",
      "Epoch 9/50\n",
      "308/308 [==============================] - 38s 124ms/step - loss: 2.0788 - val_loss: 2.8916\n",
      "Epoch 10/50\n",
      "308/308 [==============================] - 38s 124ms/step - loss: 2.0153 - val_loss: 2.8962\n",
      "Epoch 00010: early stopping\n"
     ]
    }
   ],
   "source": [
    "# compile model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy')\n",
    "\n",
    "# early stop setting\n",
    "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "\n",
    "# checkpoint setting\n",
    "checkpoint_filepath = 'abstract_summma_model_attention.keras'\n",
    "checkpoint = ModelCheckpoint(filepath=checkpoint_filepath, \n",
    "                             save_best_only=True, # Save only the best model\n",
    "                             monitor='val_loss')  # Monitor validation loss\n",
    "\n",
    "# gpu로 모델학습\n",
    "with tf.device('/GPU:0'):\n",
    "    history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train,\n",
    "                       validation_data=([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "                        batch_size=256, callbacks=[es, checkpoint], epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d7b47c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label = 'test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4309db3b",
   "metadata": {},
   "source": [
    "- 어텐션 메커니즘을 포함한 모델은 train loss는 더 낮게 나오지만 test loss는 거의 비슷한 값을 보인다\n",
    "- 시간이 되면 recurrent dropout도 시도해봐야겠다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c08693b",
   "metadata": {},
   "source": [
    "# Step 10. Inference model\n",
    "\n",
    "---\n",
    "\n",
    "💡\n",
    "`Inference`\n",
    "- **학습을 마친 모델로 실제 과제를 수행하는 것 혹은 과정**을 말한다\n",
    "\n",
    "\n",
    "- seq2seq는 훈련할 때와 인퍼런스 단계의 방식이 다르다 => 모델 설계를 별도로 해줘야한다\n",
    "- inference 단계에서는 `target 정답데이터`가 없다\n",
    "- 만들어야할 문장의 길이만큼 디코더가 반복 구조로 동작해야함\n",
    "- encoder model과 decoder model을 분리해서 설계한다\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## 1) Inference - encoder layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3c70f7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_output, state_h, state_c])\n",
    "\n",
    "# 이전 시점의 상태를 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h,\n",
    "                                                                            decoder_state_input_c])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ee54a9",
   "metadata": {},
   "source": [
    "- 문장의 다음 단어를 예측하기 위해서 initial state를 이전 시점의 상태로 사용한다\n",
    "    - 뒤의 함수 decode_sequence()에서 구현\n",
    "- 훈련 과정과는 다르게 LSTM의 리턴하는 은닉상태와 셀 상태인 state_h, state_c를 버리지 않는다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81de4477",
   "metadata": {},
   "source": [
    "## 2) Inference - attention + decoder layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4288e22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf = attn_layer([decoder_outputs2, decoder_hidden_state_input])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# decoder output layer\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat)\n",
    "\n",
    "# decoder model\n",
    "decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input, decoder_state_input_h, decoder_state_input_c],\n",
    "                      [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf22bd2",
   "metadata": {},
   "source": [
    "## `decode_sequence() 인퍼런스 단계에서 단어 시퀀스를 완성하는 함수`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "811b3ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # get encoder state from input\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # generate SOS token\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0,0] = tar_word_to_index['sostoken']\n",
    "    \n",
    "    stop_condition=False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition=True 될때까지 loop\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "        \n",
    "        if (sampled_token != 'eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "            \n",
    "        # if 'reach eos' or 'over max length', stop\n",
    "        if (sampled_token == 'eostoken' or len(decoded_sentence.split()) >= (headlines_max_len - 1)):\n",
    "            stop_condition = True\n",
    "            \n",
    "        \n",
    "        # update target_seq - length 1\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0,0] = sampled_token_index\n",
    "        \n",
    "        # update states\n",
    "        e_h, e_c = h, c\n",
    "        \n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da048c8c",
   "metadata": {},
   "source": [
    "# Step 11. Test model\n",
    "- 정수 시퀀스를 텍스트 시퀀스로 변환해야 결과를 확인하는게 좋다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4506d7d",
   "metadata": {},
   "source": [
    "## `seq2text & seq2summary function`\n",
    "- Text int sequence : padding 숫자 0을 제외\n",
    "- Summary int seq : 숫자 0, sos & eos token index 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f5bf4602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 int seq -> text seq\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if (i != 0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 요약문의 int seq -> text seq\n",
    "def seq2summary(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if (i != 0 and i != tar_word_to_index['sostoken'] and i != tar_word_to_index['eostoken']):\n",
    "            temp = temp + tar_index_to_word[i]+ ' '\n",
    "    return temp\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c100910",
   "metadata": {},
   "source": [
    "## 2) 실제 요약 vs 예측 요약 비교 + ROGUE metric\n",
    "- 위에서 시도해봤던 ROGUE 지표를 사용해서 테스트 데이터 30개 샘플 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d9b2714f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: largest rome stretch kilometres open public seven years restoration laser technology named member roman family house tombs years old depict scenes saints martyrs \n",
      "Original Summary: rome largest with tombs to open after yrs \n",
      "Predicted Summary:  floating building opens in the world\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
      "\n",
      "\n",
      "Original Text: uttar pradesh cm yogi adityanath awarded two lucknow based sisters sharp memory honey singh associated beti bachao beti padhao campaign answer around general knowledge questions within minutes government keep helping sisters ensure well inspire others cm yogi said \n",
      "Original Summary: up cm yogi awards each to sisters for sharp memory \n",
      "Predicted Summary:  up cm yogi adityanath launches his own brain\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.3, 'p': 0.375, 'f': 0.33333332839506175}, 'rouge-2': {'r': 0.2222222222222222, 'p': 0.2857142857142857, 'f': 0.24999999507812506}, 'rouge-l': {'r': 0.3, 'p': 0.375, 'f': 0.33333332839506175}}\n",
      "\n",
      "\n",
      "Original Text: harsh goenka brother rising pune supergiant owner sanjiv goenka trolled twitter earlier criticism ms dhoni player hit sunrisers hyderabad ipl saturday moment silence dhoni apply vera burnt area oh also bother tweeted user \n",
      "Original Summary: rps co owner brother trolled after dhoni hits in ipl \n",
      "Predicted Summary:  stuart broad trolls fans over his tweet on twitter\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
      "\n",
      "\n",
      "Original Text: india muslim mahasangh president ali khan announced would give lakh cash publicly destroy posters mohammad ali jinnah people like khan added pakistan never displayed photos mahatma gandhi freedom fighters indian university display jinnah photo campus \n",
      "Original Summary: muslim org offers lakh for tearing down jinnah poster \n",
      "Predicted Summary:  india should not give free to honour nawaz sharif\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
      "\n",
      "\n",
      "Original Text: actor jim carrey late former girlfriend white accused giving newly discovered note wrote two years suicide note read introduced cocaine prostitutes mental abuse disease good things broke person nnn \n",
      "Original Summary: jim carrey late ex girlfriend accused him of giving \n",
      "Predicted Summary:  actor james bond actor james bond\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
      "\n",
      "\n",
      "Original Text: one first decisions amarinder singh led punjab government decided close liquor shops state government new excise policy also announced slash liquor quota ban sale alcohol within meters national state highways poll manifesto congress promised discourage liquor consumption \n",
      "Original Summary: amarinder singh govt shuts over liquor shops in punjab \n",
      "Predicted Summary:  punjab to impose liquor ban on highways in punjab\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.3333333333333333, 'p': 0.375, 'f': 0.35294117148788934}, 'rouge-2': {'r': 0.125, 'p': 0.125, 'f': 0.1249999950000002}, 'rouge-l': {'r': 0.3333333333333333, 'p': 0.375, 'f': 0.35294117148788934}}\n",
      "\n",
      "\n",
      "Original Text: indian shuttler saina nehwal wished carolina marin speedy recovery marin got injured midway title match indonesia masters sunday way wanted finals injuries worst players unfortunate see best player women badminton face tweeted saina \n",
      "Original Summary: not the way wanted it in the final saina on marin injury \n",
      "Predicted Summary:  saina nehwal shares picture with marin in indonesia\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.2727272727272727, 'p': 0.375, 'f': 0.3157894688088643}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.18181818181818182, 'p': 0.25, 'f': 0.21052631091412755}}\n",
      "\n",
      "\n",
      "Original Text: health ministry clarified mandatory beneficiaries submit aadhaar details seeking lakh health insurance ayushman bharat scheme dubbed use aadhaar authentication purposes added comes media reports claimed applicants submit aadhaar details undergo aadhaar authentication \n",
      "Original Summary: aadhaar not mandatory for lakh insurance under modicare \n",
      "Predicted Summary:  aadhaar mandatory for aadhaar mandatory for aadhaar uidai\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.375, 'p': 0.75, 'f': 0.49999999555555563}, 'rouge-2': {'r': 0.14285714285714285, 'p': 0.25, 'f': 0.18181817719008275}, 'rouge-l': {'r': 0.375, 'p': 0.75, 'f': 0.49999999555555563}}\n",
      "\n",
      "\n",
      "Original Text: pooja bhatt asked half sister alia bhatt relationship ranbir kapoor said let young girl enjoy life think job entertaining india world really well added pooja said alia personal life problem \n",
      "Original Summary: we should let her enjoy pooja on sister alia dating ranbir \n",
      "Predicted Summary:  alia is not to be alia bhatt on alia bhatt\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.18181818181818182, 'p': 0.2857142857142857, 'f': 0.2222222174691359}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.18181818181818182, 'p': 0.2857142857142857, 'f': 0.2222222174691359}}\n",
      "\n",
      "\n",
      "Original Text: least civilians killed saturday government troops allegedly dropped barrel bomb containing poisonous chemicals syria eastern ghouta syrian government denied allegations called reports chemical attack fabrication meanwhile us said would demand immediate response international community reports confirmed \n",
      "Original Summary: civilians killed in suspected chemical attack in syria \n",
      "Predicted Summary:  civilians killed in syria in syria amid avalanche\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.5714285714285714, 'p': 0.6666666666666666, 'f': 0.6153846104142012}, 'rouge-2': {'r': 0.42857142857142855, 'p': 0.5, 'f': 0.4615384565680473}, 'rouge-l': {'r': 0.5714285714285714, 'p': 0.6666666666666666, 'f': 0.6153846104142012}}\n",
      "\n",
      "\n",
      "Original Text: reserve bank india sought fresh applications eligible candidates post chief financial officer however candidates applied earlier may barred applying notably rbi created post cfo first time rank executive director \n",
      "Original Summary: rbi seeks fresh applicants for its new cfo post \n",
      "Predicted Summary:  rbi refuses to allow voluntary to pay for months\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.2222222222222222, 'p': 0.25, 'f': 0.23529411266435996}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.2222222222222222, 'p': 0.25, 'f': 0.23529411266435996}}\n",
      "\n",
      "\n",
      "Original Text: csk sharma saved shot kane williamson going third man boundary six fourth srh chase sunday year old pulled mid air catch flicked ball back falling outside boundary line williamson taking single csk went win match four runs \n",
      "Original Summary: jumps high to save six csk win match by runs \n",
      "Predicted Summary:  fielder sprints to pull off boundary to pull off boundary\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.1, 'p': 0.16666666666666666, 'f': 0.12499999531250018}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.1, 'p': 0.16666666666666666, 'f': 0.12499999531250018}}\n",
      "\n",
      "\n",
      "Original Text: former actress amrita arora took instagram share series pictures videos workout session actress kareena kapoor khan duo seen using bell among exercises videos gym together lose weight together read caption one pictures shared amrita \n",
      "Original Summary: amrita arora shares workout video with kareena kapoor \n",
      "Predicted Summary:  sushant shares pic of making his marriage with karan\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.25, 'p': 0.2222222222222222, 'f': 0.23529411266435996}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.25, 'p': 0.2222222222222222, 'f': 0.23529411266435996}}\n",
      "\n",
      "\n",
      "Original Text: twenty nine indian cities towns including delhi fall severe severe seismic zones according national centre different regions across country classified earthquake zones ii bureau indian standards zone active delhi northern uttar pradesh parts jammu kashmir fall zone iv \n",
      "Original Summary: delhi among cities towns highly vulnerable to quakes \n",
      "Predicted Summary:  thunderstorm warning issued in delhi\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.125, 'p': 0.2, 'f': 0.1538461491124262}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.125, 'p': 0.2, 'f': 0.1538461491124262}}\n",
      "\n",
      "\n",
      "Original Text: blanket plastic ban prevent choking rivers water bodies maharashtra government told bombay high court beaches rivers water bodies flooded plastic also choking drainage systems added court hearing petitions filed several plastic manufacturing associations opposing plastic ban imposed state \n",
      "Original Summary: only full plastic ban can stop choking of rivers maha to hc \n",
      "Predicted Summary:  plastic waste found in plastic water to avoid pollution\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.16666666666666666, 'p': 0.25, 'f': 0.1999999952000001}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.16666666666666666, 'p': 0.25, 'f': 0.1999999952000001}}\n",
      "\n",
      "\n",
      "Original Text: year old female trainee constable hanged death telangana state police academy saturday committed suicide receiving information friend police constable suicide police said colleagues admitting feeling depressed later found hanging noose room \n",
      "Original Summary: female trainee constable hangs herself at telangana academy \n",
      "Predicted Summary:  class student commits suicide in telangana\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.125, 'p': 0.16666666666666666, 'f': 0.14285713795918387}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.125, 'p': 0.16666666666666666, 'f': 0.14285713795918387}}\n",
      "\n",
      "\n",
      "Original Text: indian air force chief bs dhanoa sunday said cause concern rapid pace modernisation induction new equipment neighbourhood however iaf capable countering effectively iaf well equipped take threats occur border added iaf prepared threat said \n",
      "Original Summary: concerned by rate in iaf chief \n",
      "Predicted Summary:  new iaf chief may have been capable of war crimes\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.3333333333333333, 'p': 0.2, 'f': 0.24999999531250006}, 'rouge-2': {'r': 0.2, 'p': 0.1111111111111111, 'f': 0.14285713826530627}, 'rouge-l': {'r': 0.3333333333333333, 'p': 0.2, 'f': 0.24999999531250006}}\n",
      "\n",
      "\n",
      "Original Text: external affairs minister sushma swaraj tuesday announced rule requiring married couples present marriage certificate passports scrapped following complaints married men women divorced women complained required fill name ex husband children estranged father changed rule added \n",
      "Original Summary: marriage certificates no longer needed for passports swaraj \n",
      "Predicted Summary:  un marriage marriage marriage can be allowed to marriage\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.125, 'p': 0.16666666666666666, 'f': 0.14285713795918387}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.125, 'p': 0.16666666666666666, 'f': 0.14285713795918387}}\n",
      "\n",
      "\n",
      "Original Text: republican senator graham said us president donald trump told would rather go war destroy north korea allow develop nuclear armed missiles adding prefers diplomatic approach solve north korean threat graham claimed military option destroy north korea programme north korea \n",
      "Original Summary: donald trump ready for war with north korea us senator \n",
      "Predicted Summary:  us should not allow nukes if it is not doing nuclear war trump\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.3, 'p': 0.25, 'f': 0.27272726776859507}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.1, 'p': 0.08333333333333333, 'f': 0.09090908595041348}}\n",
      "\n",
      "\n",
      "Original Text: minister state water resources vijay goel monday apprised parliament water ganga unfit bathing parts haridwar notably haridwar hindu site pilgrims go wash away sins ganga ashes loved ones pm modi allotted crore namami gange programme \n",
      "Original Summary: ganga water unfit for bathing in parts of govt \n",
      "Predicted Summary:  ganga clean ganga river to be cleaned by\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.1111111111111111, 'p': 0.14285714285714285, 'f': 0.12499999507812519}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.1111111111111111, 'p': 0.14285714285714285, 'f': 0.12499999507812519}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop through the range \n",
    "for i in range(10, 30):\n",
    "    original_text = seq2text(encoder_input_test[i])\n",
    "    original_summary = seq2summary(decoder_input_test[i])\n",
    "    predicted_summary = decode_sequence(encoder_input_test[i].reshape(1, text_max_len))\n",
    "\n",
    "    # Calculate ROUGE scores\n",
    "    rouge_scores = rouge.get_scores(predicted_summary, original_summary, avg=True)\n",
    "\n",
    "    print('Original Text:', original_text)\n",
    "    print('Original Summary:', original_summary)\n",
    "    print('Predicted Summary:', predicted_summary)\n",
    "    print('ROUGE Scores:', rouge_scores)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d76f59",
   "metadata": {},
   "source": [
    "- 요약본을 봤을때 제대로 요약이 되지 못한것 같다 (사실 엉망인것 같다..?)\n",
    "- ROUGE score도 해석해보고싶은데 어떻게 해석해야하는지 모르겠다. \n",
    "- gpt 도움을 받아본다\n",
    "\n",
    "> - **rouge-1**: **The F1 score is relatively low (0.2727)**, indicating a moderate balance between precision and recall. Improvement in both precision and recall could enhance the model's performance.<br>\n",
    "> - **rouge-2**: The scores for bigrams are all zero, suggesting that **the model is not capturing two-word sequences well. This might be an area for improvement**.<br>\n",
    "> - **rouge-l**: **The F1 score is relatively low (0.0909)**. It measures **the longest common subsequence, and a higher score indicates a better match**. Improvement in both precision and recall for this metric could be beneficial.\n",
    "\n",
    "\n",
    "- 아주 더 성능개선이 필요하다!\n",
    "- 시간이 된다면 트랜스포머를 사용해보고싶다!\n",
    "\n",
    "\n",
    "**참고**\n",
    "- [blog](https://huffon.github.io/2019/12/07/rouge/)\n",
    "- [blog](https://sooftware.io/metric/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817a2ba4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "💡\n",
    "# 성능개선을 하려면!\n",
    "- seq2seq + attention 조합을 더 좋게 수정\n",
    "- beam search 빔서치\n",
    "- pre-trained word embedding\n",
    "- transformer : encoder + decoder 자체 구조를 새롭게 함\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d287b08",
   "metadata": {},
   "source": [
    "# `추출적 요약`\n",
    "- 이미 본문에서 존재하는 단어구, 문장을 뽑아서 요약\n",
    "- 패키지 [`Summa`](https://summanlp.github.io/textrank/)의 `summarize` 모듈을 활용해서 실습<br>\n",
    "[참고] [Summa NLP](https://github.com/summanlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7c7ec5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summa                             1.2.0\r\n"
     ]
    }
   ],
   "source": [
    "# summa install check \n",
    "!pip list | grep summa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a60409d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from summa.summarizer import summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7111a24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data - 추출적요약을 위한 데이터를 다시 만든다\n",
    "data_for_summa = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cf5fbce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3377</th>\n",
       "      <td>Threat to Goa CM's life due to Rafale files: C...</td>\n",
       "      <td>Goa Congress on Saturday wrote to President Ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83123</th>\n",
       "      <td>Adnan Sami to make Bollywood acting debut</td>\n",
       "      <td>Singer Adnan Sami is set to make his acting de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75241</th>\n",
       "      <td>Virus-free pigs cloned for safer transplants f...</td>\n",
       "      <td>US-based scientists aiming to make pig organs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5321</th>\n",
       "      <td>Rahul plays chess with differently abled child...</td>\n",
       "      <td>Congress President Rahul Gandhi played chess w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58298</th>\n",
       "      <td>300 engineering colleges to be shut down over ...</td>\n",
       "      <td>Around 300 private engineering colleges which ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57592</th>\n",
       "      <td>Scientists unveil duck dinosaur that could run...</td>\n",
       "      <td>The study of a 75-million-year-old fossil smug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43212</th>\n",
       "      <td>Vidarbha win Irani Cup after posting 800 in 1s...</td>\n",
       "      <td>Vidarbha claimed the Irani Cup trophy after po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64548</th>\n",
       "      <td>Which were the most polluted cities in India o...</td>\n",
       "      <td>Rajasthan's Bhiwadi was the most polluted city...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24377</th>\n",
       "      <td>Body of newborn with paper stuffed in mouth fo...</td>\n",
       "      <td>The body of a newborn was found with toilet pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53909</th>\n",
       "      <td>Redditor makes joke on Trump claiming credit, ...</td>\n",
       "      <td>A Redditor made a joke crediting Trump for com...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headlines  \\\n",
       "3377   Threat to Goa CM's life due to Rafale files: C...   \n",
       "83123          Adnan Sami to make Bollywood acting debut   \n",
       "75241  Virus-free pigs cloned for safer transplants f...   \n",
       "5321   Rahul plays chess with differently abled child...   \n",
       "58298  300 engineering colleges to be shut down over ...   \n",
       "57592  Scientists unveil duck dinosaur that could run...   \n",
       "43212  Vidarbha win Irani Cup after posting 800 in 1s...   \n",
       "64548  Which were the most polluted cities in India o...   \n",
       "24377  Body of newborn with paper stuffed in mouth fo...   \n",
       "53909  Redditor makes joke on Trump claiming credit, ...   \n",
       "\n",
       "                                                    text  \n",
       "3377   Goa Congress on Saturday wrote to President Ra...  \n",
       "83123  Singer Adnan Sami is set to make his acting de...  \n",
       "75241  US-based scientists aiming to make pig organs ...  \n",
       "5321   Congress President Rahul Gandhi played chess w...  \n",
       "58298  Around 300 private engineering colleges which ...  \n",
       "57592  The study of a 75-million-year-old fossil smug...  \n",
       "43212  Vidarbha claimed the Irani Cup trophy after po...  \n",
       "64548  Rajasthan's Bhiwadi was the most polluted city...  \n",
       "24377  The body of a newborn was found with toilet pa...  \n",
       "53909  A Redditor made a joke crediting Trump for com...  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data\n",
    "data_for_summa.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3003ff8",
   "metadata": {},
   "source": [
    "- text 데이터만 활용해서 추출적요약을 진행한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58733bbb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "💡\n",
    "\n",
    "## `summarize()`\n",
    "\n",
    "**Summa 의 summarize() 인자들**\n",
    "> text (str) : 요약할 테스트<br>\n",
    "ratio (float, optional) – 요약문에서 원본에서 선택되는 문장 비율. 0~1 사이값<br>\n",
    "words (int or None, optional) – 출력에 포함할 단어 수<br>\n",
    "만약, ratio와 함께 두 파라미터가 모두 제공되는 경우 ratio는 무시한다<br>\n",
    "split (bool, optional) – True면 문장 list / False는 조인(join)된 문자열을 반환<br>\n",
    "\n",
    "\n",
    "- 문장 토큰화를 별도로 하지 않아도 내부적으로 문장토큰화를 수행\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4eabd2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for row 32572:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 35185:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 59998:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 64666:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 15344:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 52899:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 95150:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 76916:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 49399:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 74037:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 87659:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 73015:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 73027:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 37832:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 23956:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 81908:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 4625:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 70369:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 23375:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 87882:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 20748:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 25890:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 59976:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 93365:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 97870:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 1802:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 81625:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 29700:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 9925:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 62050:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 46057:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 93064:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 19879:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 85994:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 71002:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 25803:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 75312:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 53944:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 68956:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 17567:\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Randomly select 40 texts\n",
    "random_sample = data_for_summa.sample(n=40, random_state=42)\n",
    "\n",
    "# iterate through the rows and print the summarized text\n",
    "for index, row in random_sample.iterrows():\n",
    "    text_to_summarize = row['text']  # text \n",
    "    \n",
    "    # check if the text is not empty\n",
    "    if isinstance(text_to_summarize, str) and len(text_to_summarize.strip()) > 0:\n",
    "        summarized_text = summarize(text_to_summarize, ratio=0.005) # 원문을 바로 넣고, 요약문으로 선택하는 문장개수는 원문의 0.005%로 설정\n",
    "        \n",
    "        # Print the summary for each text\n",
    "        print(f'Summary for row {index + 1}:')\n",
    "        print(summarized_text)\n",
    "        print('\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44298eb3",
   "metadata": {},
   "source": [
    "- 요약된 데이터가 출력되지않는다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "dbf9366c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Saurav Kant, an alumnus of upGrad and IIIT-B's...\n",
       "1    Kunal Shah's credit card bill payment platform...\n",
       "2    New Zealand defeated India by 8 wickets in the...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text data\n",
    "text_data = data_for_summa['text']\n",
    "\n",
    "# check data\n",
    "text_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fa5dec08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# summarize 1 row data\n",
    "print('Summary:')\n",
    "print(summarize(text_data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73fe56f",
   "metadata": {},
   "source": [
    "- 아! 지금 데이터는 object 타입이라서 안되는걸지도 모르겠다\n",
    "- str 타입으로 변환시도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fc77574f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Saurav Kant, an alumnus of upGrad and IIIT-B's...\n",
       "1    Kunal Shah's credit card bill payment platform...\n",
       "2    New Zealand defeated India by 8 wickets in the...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text data which dtype is str\n",
    "text_data = data_for_summa['text'].astype(str)\n",
    "\n",
    "# check data\n",
    "text_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8cd42d7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_113/3688227157.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "example = text_data[0].astype(str)\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf2a40c",
   "metadata": {},
   "source": [
    "- 강훈님 도움을 받아서 코드를 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "738f49f7",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32571</th>\n",
       "      <td>K'taka students to get extra marks if parents ...</td>\n",
       "      <td>Students in Karnataka will get extra marks if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35184</th>\n",
       "      <td>Syria shoots down missiles fired at two air bases</td>\n",
       "      <td>Syrian anti-aircraft defences on Monday shot d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>Dinosaur-like animal's fossil found in Uttarak...</td>\n",
       "      <td>A Dinosaur-like creature's fossil was found du...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64665</th>\n",
       "      <td>UP may merge Shia, Sunni Waqf boards to preven...</td>\n",
       "      <td>The Uttar Pradesh government is planning to fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15343</th>\n",
       "      <td>Egypt actress gets 2 yrs jail for 'fake news' ...</td>\n",
       "      <td>Egyptian activist-actress Amal Fathy has been ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52898</th>\n",
       "      <td>Jeff Bezos added more wealth in 2017 than GDP ...</td>\n",
       "      <td>World's richest person and Amazon CEO Jeff Bez...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95149</th>\n",
       "      <td>Bangladeshi captain Mortaza announces retireme...</td>\n",
       "      <td>Bangladesh cricket team's limited overs captai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76915</th>\n",
       "      <td>Mexican drug lord El Chapo questions US extrad...</td>\n",
       "      <td>Mexican drug lord Joaquin 'El Chapo' Guzman ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49398</th>\n",
       "      <td>N Korea supplies ballistic missiles to Myanmar...</td>\n",
       "      <td>Independent United Nations (UN) monitors have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74036</th>\n",
       "      <td>Thenga mila hamme: Harbhajan responds to home ...</td>\n",
       "      <td>After reports of three Amrapali Group companie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headlines  \\\n",
       "32571  K'taka students to get extra marks if parents ...   \n",
       "35184  Syria shoots down missiles fired at two air bases   \n",
       "59997  Dinosaur-like animal's fossil found in Uttarak...   \n",
       "64665  UP may merge Shia, Sunni Waqf boards to preven...   \n",
       "15343  Egypt actress gets 2 yrs jail for 'fake news' ...   \n",
       "52898  Jeff Bezos added more wealth in 2017 than GDP ...   \n",
       "95149  Bangladeshi captain Mortaza announces retireme...   \n",
       "76915  Mexican drug lord El Chapo questions US extrad...   \n",
       "49398  N Korea supplies ballistic missiles to Myanmar...   \n",
       "74036  Thenga mila hamme: Harbhajan responds to home ...   \n",
       "\n",
       "                                                    text  \n",
       "32571  Students in Karnataka will get extra marks if ...  \n",
       "35184  Syrian anti-aircraft defences on Monday shot d...  \n",
       "59997  A Dinosaur-like creature's fossil was found du...  \n",
       "64665  The Uttar Pradesh government is planning to fo...  \n",
       "15343  Egyptian activist-actress Amal Fathy has been ...  \n",
       "52898  World's richest person and Amazon CEO Jeff Bez...  \n",
       "95149  Bangladesh cricket team's limited overs captai...  \n",
       "76915  Mexican drug lord Joaquin 'El Chapo' Guzman ha...  \n",
       "49398  Independent United Nations (UN) monitors have ...  \n",
       "74036  After reports of three Amrapali Group companie...  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly select 40 texts\n",
    "random_sample = data_for_summa.sample(n=40, random_state=42)\n",
    "random_sample[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9dc40f81",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'iterrows'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_113/549980538.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# index 얻기 시도\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrandom_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Index: {index}, Values: {row}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'iterrows'"
     ]
    }
   ],
   "source": [
    "# index 얻기 시도\n",
    "for index, row in random_sample['text'].iterrows():\n",
    "    print(f'Index: {index}, Values: {row}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "886573c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([32571, 35184, 59997, 64665, 15343, 52898, 95149, 76915, 49398,\n",
       "            74036, 87658, 73014, 73026, 37831, 23955, 81907,  4624, 70368,\n",
       "            23374, 87881, 20747, 25889, 59975, 93364, 97869,  1801, 81624,\n",
       "            29699,  9924, 62049, 46056, 93063, 19878, 85993, 71001, 25802,\n",
       "            75311, 53943, 68955, 17566],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index 얻기 시도 2\n",
    "random_sample_idx = random_sample['text'].index\n",
    "random_sample_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3c9165b8",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 13370\n",
      "Original Text: Sushmita Sen is dating model Rohman Shawl whom she had met at a fashion event in August, as per reports. Rohman was spotted cheering for Sushmita at Neeta Lulla's fashion show a few days ago where he was also seen interacting with Sushmita's daughters Renee and Alisah, reports suggested. Sushmita was earlier said to be dating hotelier Ritik Bhasin. \n",
      "Predicted Summary: Sushmita Sen is dating model Rohman Shawl whom she had met at a fashion event in August, as per reports.\n",
      "ROUGE F1 Score: 0.5714285673469389\n",
      "\n",
      "\n",
      "index: 24057\n",
      "Original Text: Micro-blogging site Twitter on Friday revealed its earnings for the second quarter of 2018 where it stated that its monthly active users dropped from 336 million in Q1 to 335 million in Q2. The company saw revenue of $711 million, up from $665 million in the last quarter. Twitter reported a net income of $100 million, its third-straight profitable quarter.\n",
      "Predicted Summary: Twitter reported a net income of $100 million, its third-straight profitable quarter.\n",
      "ROUGE F1 Score: 0.41379310016646853\n",
      "\n",
      "\n",
      "index: 42500\n",
      "Original Text: The Centre on Wednesday cleared a plan to set up an Indian Air Force (IAF) base close to Gujarat's Deesa near India's border with Pakistan. Reportedly, the PM Narendra Modi-led Cabinet Committee on Security (CCS) cleared the plan to extend the runway, build fighter-pens, and administrative facilities, with an initial investment of around Ã¢ÂÂ¹1,000 crore.\n",
      "Predicted Summary: The Centre on Wednesday cleared a plan to set up an Indian Air Force (IAF) base close to Gujarat's Deesa near India's border with Pakistan.\n",
      "ROUGE F1 Score: 0.6857142812081632\n",
      "\n",
      "\n",
      "index: 67384\n",
      "Original Text: A Chandigarh court has rejected a surrender plea of former Punjab minister Sucha Langah, who is accused of raping a woman for nearly a decade. The court directed him to go to Punjab's Gurdaspur town where the rape and cheating cases were registered against him. The Punjab Police has been conducting raids across the state to arrest him.  \n",
      "Predicted Summary: The court directed him to go to Punjab's Gurdaspur town where the rape and cheating cases were registered against him.\n",
      "ROUGE F1 Score: 0.5538461498414202\n",
      "\n",
      "\n",
      "index: 9404\n",
      "Original Text: A selfie has saved a US man from a possible prison sentence of 99 years. Cristopher Precopia's ex-girlfriend had accused him of breaking into her home on September 20, 2017, and carving an \"X\" below her neck using a box cutter. However, the selfie taken by Precopia's mother proved he was at a hotel, 70 miles from the accuser's home.\n",
      "Predicted Summary: However, the selfie taken by Precopia's mother proved he was at a hotel, 70 miles from the accuser's home.\n",
      "ROUGE F1 Score: 0.5294117608131489\n",
      "\n",
      "\n",
      "index: 81670\n",
      "Original Text: Yale researchers have identified 60 potential new \"hot Jupiters\", a class of Jupiter-like giant gas planets which complete an orbit around host star within a week due to their proximity. The discovery was made by studying reflected signals in observations of over 1,40,000 stars by NASA's Kepler spacecraft. Reflected light signals hold rich information about planets' atmospheres, researchers said.\n",
      "Predicted Summary: Reflected light signals hold rich information about planets' atmospheres, researchers said.\n",
      "ROUGE F1 Score: 0.33846153564970416\n",
      "\n",
      "\n",
      "index: 96525\n",
      "Original Text: The government had reportedly rejected the proposal to felicitate cricketer MS Dhoni, journalist Arnab Goswami, spiritual leader Gurmeet Ram Rahim Singh, music composer Anu Malik and others with Padma awards. NCP leader Sharad Pawar and BJP leader Murli Manohar Joshi were awarded Padma Vibhushan under the \"public affairs\" category, which falls under the government's discretion, a report said.\n",
      "Predicted Summary: The government had reportedly rejected the proposal to felicitate cricketer MS Dhoni, journalist Arnab Goswami, spiritual leader Gurmeet Ram Rahim Singh, music composer Anu Malik and others with Padma awards.\n",
      "ROUGE F1 Score: 0.7407407360768176\n",
      "\n",
      "\n",
      "index: 30846\n",
      "Original Text: A 10-year-old girl was allegedly raped and murdered during a wedding last week in Madhya Pradesh's Umaria district, the police said on Wednesday. The minor, who was visiting her grandmother's house for a wedding, disappeared after falling off to sleep on May 13. Her body was later found strangled to death with her scarf. \n",
      "Predicted Summary: A 10-year-old girl was allegedly raped and murdered during a wedding last week in Madhya Pradesh's Umaria district, the police said on Wednesday.\n",
      "ROUGE F1 Score: 0.6388888845408951\n",
      "\n",
      "\n",
      "index: 73029\n",
      "Original Text: US-based cab-hailing startup Uber launched in-app messaging feature along with multi-destination rides for users in India. The feature aims to help riders and drivers get in touch without incurring call charges or sharing their contact numbers. The in-app chat for both iOS and Android has been updated and also supports a number of local languages. \n",
      "Predicted Summary: The in-app chat for both iOS and Android has been updated and also supports a number of local languages.\n",
      "ROUGE F1 Score: 0.5373134289062153\n",
      "\n",
      "\n",
      "index: 52230\n",
      "Original Text: The Unique Identification Authority of India (UIDAI) on Monday announced the introduction of face authentication feature for Aadhaar users by July 1, 2018. This feature will help all elderly or others facing issues with fingerprint authentication, the UIDAI said. The feature must be combined with either fingerprint, iris scan, or OTP for successful authentication of an Aadhaar number.\n",
      "Predicted Summary: This feature will help all elderly or others facing issues with fingerprint authentication, the UIDAI said.\n",
      "ROUGE F1 Score: 0.5079365041471403\n",
      "\n",
      "\n",
      "index: 9834\n",
      "Original Text: Myntra CEO Ananth Narayanan has said all of Jabong's functions will be integrated with the company and about 10% of the combined workforce would be cut. Myntra and Jabong will operate as distinct brands but will be run by one team. Following Binny Bansal's resignation as Flipkart Group CEO, Walmart said Narayanan will report to Flipkart CEO Kalyan Krishnamurthy.\n",
      "Predicted Summary: Myntra CEO Ananth Narayanan has said all of Jabong's functions will be integrated with the company and about 10% of the combined workforce would be cut.\n",
      "ROUGE F1 Score: 0.6764705837586505\n",
      "\n",
      "\n",
      "index: 22931\n",
      "Original Text: A woman in Gujarat has alleged her live-in partner forced her to remove two front teeth to avoid male attention. She added he suspected her of seeing someone else and made her sit beside him all day while he worked as an autorickshaw driver. This was discovered when she jumped out of the autorickshaw one day and passersby alerted authorities.\n",
      "Predicted Summary: She added he suspected her of seeing someone else and made her sit beside him all day while he worked as an autorickshaw driver.\n",
      "ROUGE F1 Score: 0.602739721816476\n",
      "\n",
      "\n",
      "index: 19631\n",
      "Original Text: French female tennis player Alize Cornet was punished by the on-court official at the US Open 2018 for taking her top off and exposing her black bra during her mid-match 10-minute heat break. After walking back to court following her break, Cornet realised that she had worn her top backwards before taking it off to wear it properly.\n",
      "Predicted Summary: French female tennis player Alize Cornet was punished by the on-court official at the US Open 2018 for taking her top off and exposing her black bra during her mid-match 10-minute heat break.\n",
      "ROUGE F1 Score: 0.7792207744644967\n",
      "\n",
      "\n",
      "index: 76864\n",
      "Original Text: A US-based study has found elements heavier than iron may have been formed by interactions between primordial black holes and neutron stars. A neutron-rich environment was needed to forge such elements, scientists said, which was formed by black holes devouring neutron stars. This finding is consistent with paucity of neutron stars in galactic centres with high black hole density.\n",
      "Predicted Summary: A US-based study has found elements heavier than iron may have been formed by interactions between primordial black holes and neutron stars.\n",
      "ROUGE F1 Score: 0.6376811550766647\n",
      "\n",
      "\n",
      "index: 92696\n",
      "Original Text: Three different coloured crater lakes at the summit of Mount Kelimutu volcano in Indonesia change their colour. It is believed that minerals in the water interact with volcanic gas to create different shades. According to a local belief, the lakes are a resting place for departed souls, and those who die are sent to different lakes depending on their merits.\n",
      "Predicted Summary: Three different coloured crater lakes at the summit of Mount Kelimutu volcano in Indonesia change their colour.\n",
      "ROUGE F1 Score: 0.5230769192142012\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Hypothesis is empty.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_113/2238828765.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 원문을 바로 넣고, 요약문으로 선택하는 문장개수는 원문의 50%로 설정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Calculate ROUGE scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mrouge_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrouge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Extract only the F1 score from the ROUGE scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/rouge/rouge.py\u001b[0m in \u001b[0;36mget_scores\u001b[0;34m(self, hyps, refs, avg, ignore_empty)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_avg_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/rouge/rouge.py\u001b[0m in \u001b[0;36m_get_avg_scores\u001b[0;34m(self, hyps, refs)\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRouge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAVAILABLE_METRICS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m                 \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclusive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexclusive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m                 \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/rouge/rouge.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(hyp, ref, **k)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mDEFAULT_METRICS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"rouge-1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rouge-2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rouge-l\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     AVAILABLE_METRICS = {\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0;34m\"rouge-1\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mhyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrouge_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrouge_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;34m\"rouge-2\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mhyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrouge_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrouge_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;34m\"rouge-3\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mhyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrouge_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrouge_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/rouge/rouge_score.py\u001b[0m in \u001b[0;36mrouge_n\u001b[0;34m(evaluated_sentences, reference_sentences, n, raw_results, exclusive)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \"\"\"\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluated_sentences\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hypothesis is empty.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference_sentences\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Reference is empty.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Hypothesis is empty."
     ]
    }
   ],
   "source": [
    "# iterate through the rows and print the summarized text\n",
    "for idx, text in enumerate(random_sample['text']):\n",
    "    summary = summarize(text, ratio=0.5) # 원문을 바로 넣고, 요약문으로 선택하는 문장개수는 원문의 50%로 설정\n",
    "    # Calculate ROUGE scores\n",
    "    rouge_scores = rouge.get_scores(summary, text, avg=True)\n",
    "    \n",
    "    # Extract only the F1 score from the ROUGE scores\n",
    "    f1_score = rouge_scores['rouge-1']['f']\n",
    "    \n",
    "    # Print the summary for each text\n",
    "    print('index:', random_sample_idx[idx])\n",
    "    print('Original Text:', text)\n",
    "    print('Predicted Summary:', summary)\n",
    "    print('ROUGE F1 Score:', f1_score)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404121a2",
   "metadata": {},
   "source": [
    "**formula for F1 score**\n",
    "$$F1 = \\frac{2⋅Precision⋅Recall}{Precision+Recall}$$\n",
    "\n",
    "\n",
    "- f1 score가 높을수록 과한 중복없이 요약이 많은 관련 정보를 캡처해서 좋은 요약을 만들었다는걸 의미한다고 한다.\n",
    "- 대체로 `0.5` 을 맴도는 점수를 보여준다.\n",
    "- 확실히 추출적요약이 추상적요약보다 더 좋은 결과를 보여준다\n",
    "\n",
    "\n",
    "- 회고를 미리 써두고 트랜스포머 사용을 시도해본다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355fb916",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# Summary\n",
    "\n",
    "- NLP 내용은 잊은지 오래된 시점에서 모델을 구현해서 결과값을 확인하고, 해석까지 하는 작업을 하니 굉장히 힘들고 어려웠다.\n",
    "- 최대한 어떤 플로우로 진행되는지 파악한다는 기분으로 진행했고, 어떤 개념을 공부해야할지 확인한다고 생각하니 마음이 한결 가벼워졌다.\n",
    "- CV도 데이터 전처리가 중요했지만 NLP는 훨씬 더 데이터전처리가 중요하다고 느껴졌고, 엔지니어의 역할이 중요한것처럼 느껴진다.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "# KPT\n",
    "\n",
    "**[KEEP]**\n",
    "- 초반에 수치값이 많이 나와서 스트레스르르 많이 받았고, 너무 생소한 내용들이라 어려웠는데 마인드컨트롤을 하며 학습했다.\n",
    "\n",
    "\n",
    "**[PROBLEM]**\n",
    "- 데이터프레임 활용하는 방법을 많이 잊어서 어떻게 데이터를 다뤄야하는지 좀 헤맸다. \n",
    "- 평가지표에 대한 정리가 안되어있어서 ROUGE 값이 크면 좋은건지, 작으면 좋은건지 해석하는게 어려웠다.\n",
    "- 숫자 데이터가 많이 나왔는데 CV와 다르게 제대로 나온건지 확인할수가 없어서 자신이 없었다.\n",
    "\n",
    "\n",
    "**[TRY]**\n",
    "- 틈틈이 판다스 데이터프레임 문제를 풀어본다.\n",
    "- 이후 노드에서 나오는 NLP부분에서는 관련 자료도 함께 읽어보고 더 꼼꼼하게 공부해본다\n",
    "- 평가지표 부분에서 찾아둔 블로그와 관련 자료를 읽어보며 내용을 정리한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16916c7c",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "💡\n",
    "# Transformer 모델 실험\n",
    "- 관련 지식 하나도 없어서 모델을 직접 구현하는건 어려울것 같고, 다행히 [위키독스 자료](https://wikidocs.net/31379)에서 트랜스포머 설명을 찾았다. 이를 바탕으로 테스트를 해본다\n",
    "- 해보려고했는데 너무 어려운 내용이라 [Hugging Face](https://icedhotchoco.tistory.com/entry/DAY-83)에서 트랜스포머 라이브러리를 가져와서 실습해보는 자료를 찾았다. 이를 바탕으로 실험\n",
    "    - [Hugging face - Transformer quicktour](https://huggingface.co/docs/transformers/quicktour)\n",
    "    - [SummarizationPipeline](https://huggingface.co/docs/transformers/v4.36.1/en/main_classes/pipelines#transformers.SummarizationPipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "09b712d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load transformer pipeline \n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d0a471a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13370    Sushmita Sen is dating model Rohman Shawl whom...\n",
       "24057    Micro-blogging site Twitter on Friday revealed...\n",
       "42500    The Centre on Wednesday cleared a plan to set ...\n",
       "67384    A Chandigarh court has rejected a surrender pl...\n",
       "9404     A selfie has saved a US man from a possible pr...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly select 40 texts\n",
    "random_sample = data_for_summa.sample(n=40, random_state=1004)\n",
    "\n",
    "random_sample['text'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3153128c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 (https://huggingface.co/sshleifer/distilbart-cnn-12-6)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "002b44927773426b982046794bccc85f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.76k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c98f510e6204c90addd8d86b23d94b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.14G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6081b69183644fb1aa9211c0c907055c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5d3a8be7ab04e3789df86f85a3e82f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17d118a653864727a974c2a2f9c3f8dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make summarization pipeline\n",
    "summarizer = pipeline('summarization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "484d06ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([13370, 24057, 42500, 67384,  9404, 81670, 96525, 30846, 73029,\n",
       "            52230,  9834, 22931, 19631, 76864, 92696, 46321, 23420, 39753,\n",
       "            48225, 92872, 28942, 94481, 44515, 77671, 69310,  1877,  5656,\n",
       "            43402, 91277, 33170, 81495, 15288, 95623, 95814, 73421, 95798,\n",
       "            17371,  8258, 66810, 70001],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original index 얻기\n",
    "random_sample_idx = random_sample['text'].index\n",
    "random_sample_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9bfe6c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- original_text: The text you want to summarize\n",
    "- max_length: Maximum number of words in the generated summary\n",
    "- min_length: Minimum number of words in the generated summary\n",
    "- length_penalty: A factor influencing the length of the summary\n",
    "- num_beams: The number of different ways to explore possible summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "756820a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 13370\n",
      "Original Text: Sushmita Sen is dating model Rohman Shawl whom she had met at a fashion event in August, as per reports. Rohman was spotted cheering for Sushmita at Neeta Lulla's fashion show a few days ago where he was also seen interacting with Sushmita's daughters Renee and Alisah, reports suggested. Sushmita was earlier said to be dating hotelier Ritik Bhasin. \n",
      "Predicted Summary:  Rohman Shawl was spotted cheering for Sushmita at Neeta Lulla\n",
      "ROUGE F1 Score: 0.29999999722222226\n",
      "\n",
      "\n",
      "index: 24057\n",
      "Original Text: Micro-blogging site Twitter on Friday revealed its earnings for the second quarter of 2018 where it stated that its monthly active users dropped from 336 million in Q1 to 335 million in Q2. The company saw revenue of $711 million, up from $665 million in the last quarter. Twitter reported a net income of $100 million, its third-straight profitable quarter.\n",
      "Predicted Summary:  Twitter reported a net income of $100 million, its third-straight profitable quarter .\n",
      "ROUGE F1 Score: 0.41379310016646853\n",
      "\n",
      "\n",
      "index: 42500\n",
      "Original Text: The Centre on Wednesday cleared a plan to set up an Indian Air Force (IAF) base close to Gujarat's Deesa near India's border with Pakistan. Reportedly, the PM Narendra Modi-led Cabinet Committee on Security (CCS) cleared the plan to extend the runway, build fighter-pens, and administrative facilities, with an initial investment of around Ã¢ÂÂ¹1,000 crore.\n",
      "Predicted Summary:  PM Narendra Modi-led Cabinet Committee on Security (CCS) cleared the plan to\n",
      "ROUGE F1 Score: 0.41379310016646853\n",
      "\n",
      "\n",
      "index: 67384\n",
      "Original Text: A Chandigarh court has rejected a surrender plea of former Punjab minister Sucha Langah, who is accused of raping a woman for nearly a decade. The court directed him to go to Punjab's Gurdaspur town where the rape and cheating cases were registered against him. The Punjab Police has been conducting raids across the state to arrest him.  \n",
      "Predicted Summary:  Former Punjab minister Sucha Langah is accused of raping a woman for nearly a decade\n",
      "ROUGE F1 Score: 0.393442619414136\n",
      "\n",
      "\n",
      "index: 9404\n",
      "Original Text: A selfie has saved a US man from a possible prison sentence of 99 years. Cristopher Precopia's ex-girlfriend had accused him of breaking into her home on September 20, 2017, and carving an \"X\" below her neck using a box cutter. However, the selfie taken by Precopia's mother proved he was at a hotel, 70 miles from the accuser's home.\n",
      "Predicted Summary:  Cristopher Precopia's ex-girlfriend had accused him of breaking into her home\n",
      "ROUGE F1 Score: 0.36065573474872353\n",
      "\n",
      "\n",
      "index: 81670\n",
      "Original Text: Yale researchers have identified 60 potential new \"hot Jupiters\", a class of Jupiter-like giant gas planets which complete an orbit around host star within a week due to their proximity. The discovery was made by studying reflected signals in observations of over 1,40,000 stars by NASA's Kepler spacecraft. Reflected light signals hold rich information about planets' atmospheres, researchers said.\n",
      "Predicted Summary:  Yale researchers identify 60 potential new 'hot Jupiters' class of Jupiter-\n",
      "ROUGE F1 Score: 0.21538461257278108\n",
      "\n",
      "\n",
      "index: 96525\n",
      "Original Text: The government had reportedly rejected the proposal to felicitate cricketer MS Dhoni, journalist Arnab Goswami, spiritual leader Gurmeet Ram Rahim Singh, music composer Anu Malik and others with Padma awards. NCP leader Sharad Pawar and BJP leader Murli Manohar Joshi were awarded Padma Vibhushan under the \"public affairs\" category, which falls under the government's discretion, a report said.\n",
      "Predicted Summary:  Sharad Pawar and Murli Manohar Joshi were awarded Padma V\n",
      "ROUGE F1 Score: 0.29508196447191626\n",
      "\n",
      "\n",
      "index: 30846\n",
      "Original Text: A 10-year-old girl was allegedly raped and murdered during a wedding last week in Madhya Pradesh's Umaria district, the police said on Wednesday. The minor, who was visiting her grandmother's house for a wedding, disappeared after falling off to sleep on May 13. Her body was later found strangled to death with her scarf. \n",
      "Predicted Summary:  10-year-old girl allegedly raped and murdered during a wedding in Madhya Pradesh\n",
      "ROUGE F1 Score: 0.36065573454447736\n",
      "\n",
      "\n",
      "index: 73029\n",
      "Original Text: US-based cab-hailing startup Uber launched in-app messaging feature along with multi-destination rides for users in India. The feature aims to help riders and drivers get in touch without incurring call charges or sharing their contact numbers. The in-app chat for both iOS and Android has been updated and also supports a number of local languages. \n",
      "Predicted Summary:  US-based cab-hailing startup Uber launched in-app messaging feature along with\n",
      "ROUGE F1 Score: 0.3389830480321747\n",
      "\n",
      "\n",
      "index: 52230\n",
      "Original Text: The Unique Identification Authority of India (UIDAI) on Monday announced the introduction of face authentication feature for Aadhaar users by July 1, 2018. This feature will help all elderly or others facing issues with fingerprint authentication, the UIDAI said. The feature must be combined with either fingerprint, iris scan, or OTP for successful authentication of an Aadhaar number.\n",
      "Predicted Summary:  The Unique Identification Authority of India (UIDAI) announced the introduction of face authentication feature\n",
      "ROUGE F1 Score: 0.43333332993888896\n",
      "\n",
      "\n",
      "index: 9834\n",
      "Original Text: Myntra CEO Ananth Narayanan has said all of Jabong's functions will be integrated with the company and about 10% of the combined workforce would be cut. Myntra and Jabong will operate as distinct brands but will be run by one team. Following Binny Bansal's resignation as Flipkart Group CEO, Walmart said Narayanan will report to Flipkart CEO Kalyan Krishnamurthy.\n",
      "Predicted Summary:  Myntra CEO Ananth Narayanan has said all of Jabong's functions\n",
      "ROUGE F1 Score: 0.363636360661157\n",
      "\n",
      "\n",
      "index: 22931\n",
      "Original Text: A woman in Gujarat has alleged her live-in partner forced her to remove two front teeth to avoid male attention. She added he suspected her of seeing someone else and made her sit beside him all day while he worked as an autorickshaw driver. This was discovered when she jumped out of the autorickshaw one day and passersby alerted authorities.\n",
      "Predicted Summary:  Woman claims live-in partner forced her to remove two front teeth to avoid male attention\n",
      "ROUGE F1 Score: 0.3692307658508876\n",
      "\n",
      "\n",
      "index: 19631\n",
      "Original Text: French female tennis player Alize Cornet was punished by the on-court official at the US Open 2018 for taking her top off and exposing her black bra during her mid-match 10-minute heat break. After walking back to court following her break, Cornet realised that she had worn her top backwards before taking it off to wear it properly.\n",
      "Predicted Summary:  Alize Cornet was punished by the on-court official for taking her top off\n",
      "ROUGE F1 Score: 0.43333332993888896\n",
      "\n",
      "\n",
      "index: 76864\n",
      "Original Text: A US-based study has found elements heavier than iron may have been formed by interactions between primordial black holes and neutron stars. A neutron-rich environment was needed to forge such elements, scientists said, which was formed by black holes devouring neutron stars. This finding is consistent with paucity of neutron stars in galactic centres with high black hole density.\n",
      "Predicted Summary:  Elements heavier than iron may have been formed by interactions between primordial black holes and neutron\n",
      "ROUGE F1 Score: 0.47619047240110873\n",
      "\n",
      "\n",
      "index: 92696\n",
      "Original Text: Three different coloured crater lakes at the summit of Mount Kelimutu volcano in Indonesia change their colour. It is believed that minerals in the water interact with volcanic gas to create different shades. According to a local belief, the lakes are a resting place for departed souls, and those who die are sent to different lakes depending on their merits.\n",
      "Predicted Summary:  Three different coloured crater lakes at the summit of Mount Kelimutu volcano in Indonesia\n",
      "ROUGE F1 Score: 0.45161289972944857\n",
      "\n",
      "\n",
      "index: 46321\n",
      "Original Text: In an open letter to Pakistani singer Rahat Fateh Ali Khan, Union Minister Babul Supriyo wrote, \"Maybe the time has come when...powerful...individuals like you (should) put pressure on your government to refrain from such support to terrorism.\" Supriyo added that the effort to solve tensions between India and Pakistan through art and music is a \"failed doctrine\".\n",
      "Predicted Summary:  Union Minister Babul Supriyo wrote an open letter to Pakistani singer Rahat Fate\n",
      "ROUGE F1 Score: 0.3283582058275786\n",
      "\n",
      "\n",
      "index: 23420\n",
      "Original Text: A 20-year-old 'grieving' orca whale has been continuously carrying her dead calf off the Canadian coast since it died last Tuesday shortly after birth. Scientists tracking the mother have expressed concerns over her well-being as she is now falling behind her group. The calf was the first born to its group in 3 years, of which only 75 are left.\n",
      "Predicted Summary:  A 20-year-old whale has been continuously carrying her dead calf off the Canadian\n",
      "ROUGE F1 Score: 0.388059698364892\n",
      "\n",
      "\n",
      "index: 39753\n",
      "Original Text: Assam Congress MLA Rupjyoti Kurmi recently paid for a funeral of a poor man and carried his body till the cremation site. \"As a human being and responsible for the people I represent, it's the least I could do,\" Kurmi said. Last year, Kurmi also carried 50 kg rice bag on his back and delivered it to flood relief camps.\n",
      "Predicted Summary:  Assam Congress MLA Rupjyoti Kurmi recently paid for a funeral of\n",
      "ROUGE F1 Score: 0.37288135289859237\n",
      "\n",
      "\n",
      "index: 48225\n",
      "Original Text: Congress President Rahul Gandhi was gifted a gold-coated Valmiki statue worth Ã¢ÂÂ¹60 lakh by an independent MLA who joined the party at a rally in Karnataka on Saturday. A BJP MLA from Vijayanagar also formally joined the party during the rally. Meanwhile, the BJP criticised Gandhi and CM Siddaramaiah for inducting the MLAs, who are facing charges of illegal mining. \n",
      "Predicted Summary:  Congress President Rahul Gandhi gifted a gold-coated Valmiki statue worth Ã\n",
      "ROUGE F1 Score: 0.33333333033888896\n",
      "\n",
      "\n",
      "index: 92872\n",
      "Original Text: Cristiano Ronaldo scored a hat-trick to help Real Madrid reach Champions League semi-finals for the seventh straight year, after claiming a 6-3 aggregate victory over Bayern Munich in the quarter-finals on Tuesday. Coming into the match with a 2-1 lead from the first leg, Real finished regulation time losing 1-2, but scored three goals in extra time to claim victory.\n",
      "Predicted Summary:  Cristiano Ronaldo scored a hat-trick to help Real Madrid reach Champions League semi\n",
      "ROUGE F1 Score: 0.38709677087929245\n",
      "\n",
      "\n",
      "index: 28942\n",
      "Original Text: Indian Air Force has joined the operation to douse a massive fire raging for 17 hours in a rubber godown in Delhi's Malviya Nagar after fire tenders failed to contain the blaze. An Mi-17 helicopter was seen pouring water on the fire, while 15 fire tenders were at the spot. The fire also spread to nearby buildings, including a school.\n",
      "Predicted Summary:  Indian Air Force has joined the operation to douse a massive fire raging for 17 hours\n",
      "ROUGE F1 Score: 0.4999999962500001\n",
      "\n",
      "\n",
      "index: 94481\n",
      "Original Text: Technology major Apple has received a patent for an anti-shock device that will protect smartphones from falls and float if the phone contacts a water surface. The patent details a spring-loaded bumper system that deploys when it detects that the phone is in free-fall. The 'bumper cushions' may also be coloured to better the appearance of smartphones, Apple added.\n",
      "Predicted Summary:  Patent details a spring-loaded bumper system that deploys when it detects that the phone\n",
      "ROUGE F1 Score: 0.38709677087929245\n",
      "\n",
      "\n",
      "index: 44515\n",
      "Original Text: While honouring late actress Madhubala, US daily The New York Times has compared her life to late American actress Marilyn Monroe. The newspaper wrote that there was a remarkable similarity in the \"soft vulnerability of their faces\", \"laughter\" and the \"incandescent glow\". In their special obituary section 'Overlooked', the newspaper paid homage to 14 other remarkable women across the world.\n",
      "Predicted Summary:  The New York Times compared Madhubala's life to late American actress Marilyn Monroe .\n",
      "ROUGE F1 Score: 0.38095237767699675\n",
      "\n",
      "\n",
      "index: 77671\n",
      "Original Text: Canada is investigating reports that Saudi Arabia has been using Canadian-made armoured vehicles against its citizens in the violence-hit Eastern Province. Videos and photos posted on social media show Saudi Arabia using Canadian equipment on Shia dissidents. Canada warned it would take action if \"it is found that Canadian exports have been used to commit serious violations of human rights\".\n",
      "Predicted Summary:  Videos and photos posted on social media show Saudi Arabia using Canadian equipment on Shia dissidents .\n",
      "ROUGE F1 Score: 0.4545454510330579\n",
      "\n",
      "\n",
      "index: 69310\n",
      "Original Text: US President Donald Trump on Tuesday called the 2015 Iran nuclear deal an \"embarrassment\" and \"a one-sided transaction\" for the US. Adding that the deal must be changed for the US to remain in it, US State Secretary Rex Tillerson said, \"Unfortunately, this is what (US) in the past did with North Korea...entered into agreements that were easily cheated on.\"\n",
      "Predicted Summary:  US President Donald Trump called the 2015 Iran nuclear deal an \"embarrassment\" and\n",
      "ROUGE F1 Score: 0.41269840942302854\n",
      "\n",
      "\n",
      "index: 1877\n",
      "Original Text: Two incidents were reported from Jammu and Kashmir in which patients had to be carried to the hospital on shoulders amid heavy snow due to lack of connectivity of roads. A video shows attendants of hospitals in Ganderbal and Uri carrying patients on their shoulders for several kilometres. One of the patients, from Uri, had suffered a stroke.\n",
      "Predicted Summary:  Two incidents were reported from Jammu and Kashmir in which patients had to be carried to\n",
      "ROUGE F1 Score: 0.4999999962500001\n",
      "\n",
      "\n",
      "index: 5656\n",
      "Original Text: A Nigerian professor has been jailed for demanding sex for marks from a student. Richard Akindele was convicted after pleading guilty to four criminal charges, including demanding gratification from a student and sexual coercion of a student. A student had come forward with a recording of Akindele demanding that she either sleep with him or fail the course.\n",
      "Predicted Summary:  Richard Akindele was convicted after pleading guilty to four criminal charges . The professor had\n",
      "ROUGE F1 Score: 0.4137930997859691\n",
      "\n",
      "\n",
      "index: 43402\n",
      "Original Text: Asserting that the BJP united the Bahujan Samaj Party and the Samajwadi Party, SP chief Akhilesh Yadav on Saturday said he will visit mandir, masjid and \"all religious places\" to maintain an alliance with BSP. In a jibe at BJP referring to its defeat in the recent Lok Sabha bypolls, he said the BJP's 'pakoda' politics was behind its loss.\n",
      "Predicted Summary:  SP chief Akhilesh Yadav says he will visit mandir, masj\n",
      "ROUGE F1 Score: 0.2666666638888889\n",
      "\n",
      "\n",
      "index: 91277\n",
      "Original Text: SS Rajamouli's Baahubali 2, the sequel to the 2015 film Baahubali, sold over 10 lakh tickets within 24 hours in advance bookings on the ticket booking platform BookMyShow. The tickets for the film were also said to be sold for as high as Ã¢ÂÂ¹2,400 in certain theatres. The film released on Friday on a record 6,500 screens in India.\n",
      "Predicted Summary:  SS Rajamouli's Baahubali 2 sold over 10 lakh tickets within\n",
      "ROUGE F1 Score: 0.3333333303155008\n",
      "\n",
      "\n",
      "index: 33170\n",
      "Original Text: A 24-year-old fashion blogger has shared a video of herself creating a dress using trash bags. Amber Scholl said she undertook the \"silly\" challenge as her fans often told her she \"could make wearing a trash bag look good.\" Scholl created roses using trash bags and stuck them on a bodysuit and skirt, with the entire process taking seven hours. \n",
      "Predicted Summary:  Amber Scholl created roses using trash bags and stuck them on a bodysuit and\n",
      "ROUGE F1 Score: 0.41269840942302854\n",
      "\n",
      "\n",
      "index: 81495\n",
      "Original Text: A man says he was fired from a US Home Depot store for violating safety policy by trying to stop a suspected kidnapping. Dillon Reagan was finishing his shift when a co-worker spotted a violent dispute in the parking lot with a woman screaming, \"HeÃ¢ÂÂs kidnapping my childÃ¢ÂÂ. Reagan called 911 and gave his statement for which he was fired.\n",
      "Predicted Summary:  Dillon Reagan was finishing his shift when a co-worker spotted a violent dispute in the\n",
      "ROUGE F1 Score: 0.45161289972944857\n",
      "\n",
      "\n",
      "index: 15288\n",
      "Original Text: The Delhi Police has arrested a man who posed as a DCP to extort money from truck drivers. Sunil Tyagi was caught red-handed from Delhi's Dhaula Kuan while he was extracting money from a truck driver. Tyagi said that working as a driver he had confronted several police officers and seeing their behaviour, he decided to act like one.\n",
      "Predicted Summary:  Sunil Tyagi was caught red-handed from Delhi's Dhaula Kuan\n",
      "ROUGE F1 Score: 0.33333333055555564\n",
      "\n",
      "\n",
      "index: 95623\n",
      "Original Text: A US woman has been ordered by a judge to pay Ã¢ÂÂ¹3.2 crore for a Facebook post that falsely accused an acquaintance of killing her own son. The complainant said that social media makes it \"easy\" for people to defame others. \"There are no filters to say whatever you think behind the safety of your screen,\" she said.\n",
      "Predicted Summary:  US woman ordered to pay Ã¢ÂÂ¹3.2\n",
      "ROUGE F1 Score: 0.2372881335018673\n",
      "\n",
      "\n",
      "index: 95814\n",
      "Original Text: Facebook-owned VR startup Oculus Co-founder Palmer Luckey has left the company. Last year, Luckey apologised for donating $10,000 to a group spreading anti-Hillary Clinton memes ahead of the US presidential election. Luckey was also involved in a lawsuit against Facebook by Zenimax which accused Oculus of twisting its origin story by giving Luckey complete credit for inventing the technology.\n",
      "Predicted Summary:  Oculus co-founder Palmer Luckey has left the company . Luckey was involved in\n",
      "ROUGE F1 Score: 0.33333333033888896\n",
      "\n",
      "\n",
      "index: 73421\n",
      "Original Text: The Islamic State has claimed responsibility for the attack at a Shia mosque on Friday in Afghanistan's capital Kabul. A suicide bombing followed by gunfire killed at least 30 people and left several others injured. This comes after ISIS issued a warning last month, saying it would attack Shia places of worship in Afghanistan.\n",
      "Predicted Summary:  ISIS has claimed responsibility for the attack at a Shia mosque in Afghanistan's capital Kabul .\n",
      "ROUGE F1 Score: 0.46874999641113285\n",
      "\n",
      "\n",
      "index: 95798\n",
      "Original Text: Actress Shilpa Shinde, who portrayed the character 'Angoori Bhabhi' on the television serial 'Bhabhiji Ghar Par Hai', has filed a complaint of criminal defamation against the heads of three industry associations. She alleged that the associations had imposed a 'ban' on her, though they have no such power, and had warned of action against any production house which employed her. \n",
      "Predicted Summary:  Actress Shilpa Shinde has filed a complaint of criminal defamation against the heads\n",
      "ROUGE F1 Score: 0.37499999676269535\n",
      "\n",
      "\n",
      "index: 17371\n",
      "Original Text: Pakistan cricketer Shoaib Malik came and talked to former Indian captain MS Dhoni during the sides' training session in Dubai ahead of the upcoming Asia Cup 2018 tournament. Malik came and shook hands with Dhoni before talking to him, with India's stand-in captain Rohit Sharma standing nearby. India and Pakistan are set to face each other on September 19.\n",
      "Predicted Summary:  Shoaib Malik came and shook hands with MS Dhoni during training session . India\n",
      "ROUGE F1 Score: 0.4262295048427842\n",
      "\n",
      "\n",
      "index: 8258\n",
      "Original Text: Reacting to the allegations levelled against her by India Women coach Ramesh Powar, Mithali Raj tweeted it was the darkest day of her life as her patriotism has been doubted. She added that all her hard work in last 20 years of playing for India went in vain. Powar had accused Mithali of chasing \"own milestones\" during Women's World T20.\n",
      "Predicted Summary:  Mithali Raj tweets it was the darkest day of her life as her patriotism has been\n",
      "ROUGE F1 Score: 0.4242424207300276\n",
      "\n",
      "\n",
      "index: 66810\n",
      "Original Text: The Andhra Pradesh government is exploring a proposal to allot five extra marks to students of Class 9 and above who participate in the Swachh Bharat initiative by helping identify households without toilets. Andhra Pradesh government has to build 21 lakh toilets, to achieve 100% open defecation free status by March 2019 and has been encouraging students to participate.\n",
      "Predicted Summary:  Andhra Pradesh government has to build 21 lakh toilets to achieve 100% open defec\n",
      "ROUGE F1 Score: 0.39999999660555563\n",
      "\n",
      "\n",
      "index: 70001\n",
      "Original Text: NASA on Friday crashed its $3.9-billion Cassini spacecraft into Saturn's atmosphere as it was running low on fuel after a 20-year mission. The spacecraft was destroyed to avoid a collision with Saturn's moons, to protect them from Earth-based contamination, thus preserving them for future missions. Cassini had discovered oceans and organic elements suitable for life on moons, Titan and Enceladus. \n",
      "Predicted Summary:  NASA crashed its $3.9-billion Cassini spacecraft into Saturn's atmosphere on\n",
      "ROUGE F1 Score: 0.36065573474872353\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# iterate through the rows and print the summarized text\n",
    "for idx, text in enumerate(random_sample['text']):\n",
    "    dict_summary = summarizer(text, min_length=5, max_length=20)\n",
    "    summary = dict_summary[0]['summary_text']\n",
    "    # Calculate ROUGE scores\n",
    "    rouge_scores = rouge.get_scores(summary, text, avg=True)\n",
    "    \n",
    "    # Extract only the F1 score from the ROUGE scores\n",
    "    f1_score = rouge_scores['rouge-1']['f']\n",
    "    \n",
    "    # Print the summary for each text\n",
    "    print('index:', random_sample_idx[idx])\n",
    "    print('Original Text:', text)\n",
    "    print('Predicted Summary:', summary)\n",
    "    print('ROUGE F1 Score:', f1_score)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a704c39d",
   "metadata": {},
   "source": [
    "- 생각해보니 이 요약에는 데이터 전처리를 하지 않아서 트랜스포머인데도 f1 score가 크게 좋지않은걸까 싶다.\n",
    "- 데이터 전처리도 완료한후 트랜스포머를 다시 사용해봐야겠다"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "343px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
